[
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/My-name-is-Aish/index.html",
    "href": "posts/My-name-is-Aish/index.html",
    "title": "My name is Aish K",
    "section": "",
    "text": "Hey there, I am Aish"
  },
  {
    "objectID": "posts/My-name-is-Aish/index.html#introduction",
    "href": "posts/My-name-is-Aish/index.html#introduction",
    "title": "My name is Aish K",
    "section": "",
    "text": "Hey there, I am Aish"
  },
  {
    "objectID": "posts/My-name-is-Aish/index.html#my-first-piece-of-r-code",
    "href": "posts/My-name-is-Aish/index.html#my-first-piece-of-r-code",
    "title": "My name is Aish K",
    "section": "My first piece of R code",
    "text": "My first piece of R code\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(babynames)\nlibrary(ggformula)\n\nLoading required package: scales\n\nAttaching package: 'scales'\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\nLoading required package: ggridges\n\nNew to ggformula?  Try the tutorials: \n    learnr::run_tutorial(\"introduction\", package = \"ggformula\")\n    learnr::run_tutorial(\"refining\", package = \"ggformula\")\n\n\n\nbabynames::babynames\n\n# A tibble: 1,924,665 × 5\n    year sex   name          n   prop\n   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;     &lt;int&gt;  &lt;dbl&gt;\n 1  1880 F     Mary       7065 0.0724\n 2  1880 F     Anna       2604 0.0267\n 3  1880 F     Emma       2003 0.0205\n 4  1880 F     Elizabeth  1939 0.0199\n 5  1880 F     Minnie     1746 0.0179\n 6  1880 F     Margaret   1578 0.0162\n 7  1880 F     Ida        1472 0.0151\n 8  1880 F     Alice      1414 0.0145\n 9  1880 F     Bertha     1320 0.0135\n10  1880 F     Sarah      1288 0.0132\n# ℹ 1,924,655 more rows\n\n\n\nbabynames %&gt;% filter(name == \"Aditi\")\n\n# A tibble: 40 × 5\n    year sex   name      n       prop\n   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt;      &lt;dbl&gt;\n 1  1977 F     Aditi     5 0.00000304\n 2  1978 F     Aditi     9 0.00000548\n 3  1979 F     Aditi     9 0.00000522\n 4  1980 F     Aditi     6 0.00000337\n 5  1982 F     Aditi    10 0.00000551\n 6  1983 F     Aditi    12 0.00000671\n 7  1984 F     Aditi    10 0.00000555\n 8  1985 F     Aditi    17 0.00000921\n 9  1986 F     Aditi    22 0.0000119 \n10  1987 F     Aditi    21 0.0000112 \n# ℹ 30 more rows\n\n\n\nbabynames %&gt;% filter(name == \"Shashank\") %&gt;% \n  gf_line(n ~ year)\n\n\n\n\n\n\n\n\nMy name is damn cool!"
  },
  {
    "objectID": "posts/blog-day-3/index.html",
    "href": "posts/blog-day-3/index.html",
    "title": "Day-3",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(ggformula)\nlibrary(skimr)\n\n\nAttaching package: 'skimr'\n\nThe following object is masked from 'package:mosaic':\n\n    n_missing\n\n\n\ntaxi &lt;- read_csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/modeldata/taxi.csv\")\n\nRows: 10000 Columns: 8\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): tip, company, local, dow, month\ndbl (3): rownames, distance, hour\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ntaxi\n\n# A tibble: 10,000 × 8\n   rownames tip   distance company                      local dow   month  hour\n      &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;                        &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;\n 1        1 yes      17.2  Chicago Independents         no    Thu   Feb      16\n 2        2 yes       0.88 City Service                 yes   Thu   Mar       8\n 3        3 yes      18.1  other                        no    Mon   Feb      18\n 4        4 yes      20.7  Chicago Independents         no    Mon   Apr       8\n 5        5 yes      12.2  Chicago Independents         no    Sun   Mar      21\n 6        6 yes       0.94 Sun Taxi                     yes   Sat   Apr      23\n 7        7 yes      17.5  Flash Cab                    no    Fri   Mar      12\n 8        8 yes      17.7  other                        no    Sun   Jan       6\n 9        9 yes       1.85 Taxicab Insurance Agency Llc no    Fri   Apr      12\n10       10 yes       1.47 City Service                 no    Tue   Mar      14\n# ℹ 9,990 more rows\n\n\n\nglimpse(taxi)\n\nRows: 10,000\nColumns: 8\n$ rownames &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18…\n$ tip      &lt;chr&gt; \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\"…\n$ distance &lt;dbl&gt; 17.19, 0.88, 18.11, 20.70, 12.23, 0.94, 17.47, 17.67, 1.85, 1…\n$ company  &lt;chr&gt; \"Chicago Independents\", \"City Service\", \"other\", \"Chicago Ind…\n$ local    &lt;chr&gt; \"no\", \"yes\", \"no\", \"no\", \"no\", \"yes\", \"no\", \"no\", \"no\", \"no\",…\n$ dow      &lt;chr&gt; \"Thu\", \"Thu\", \"Mon\", \"Mon\", \"Sun\", \"Sat\", \"Fri\", \"Sun\", \"Fri\"…\n$ month    &lt;chr&gt; \"Feb\", \"Mar\", \"Feb\", \"Apr\", \"Mar\", \"Apr\", \"Mar\", \"Jan\", \"Apr\"…\n$ hour     &lt;dbl&gt; 16, 8, 18, 8, 21, 23, 12, 6, 12, 14, 18, 11, 12, 19, 17, 13, …\n\n\n\nskim(taxi)\n\n\nData summary\n\n\nName\ntaxi\n\n\nNumber of rows\n10000\n\n\nNumber of columns\n8\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n5\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ntip\n0\n1\n2\n3\n0\n2\n0\n\n\ncompany\n0\n1\n5\n28\n0\n7\n0\n\n\nlocal\n0\n1\n2\n3\n0\n2\n0\n\n\ndow\n0\n1\n3\n3\n0\n7\n0\n\n\nmonth\n0\n1\n3\n3\n0\n4\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nrownames\n0\n1\n5000.50\n2886.90\n1\n2500.75\n5000.50\n7500.25\n10000.0\n▇▇▇▇▇\n\n\ndistance\n0\n1\n6.22\n7.38\n0\n0.94\n1.78\n15.56\n42.3\n▇▁▂▁▁\n\n\nhour\n0\n1\n14.18\n4.36\n0\n11.00\n15.00\n18.00\n23.0\n▁▃▅▇▃\n\n\n\n\n\n\ninspect(taxi)\n\n\ncategorical variables:  \n     name     class levels     n missing\n1     tip character      2 10000       0\n2 company character      7 10000       0\n3   local character      2 10000       0\n4     dow character      7 10000       0\n5   month character      4 10000       0\n                                   distribution\n1 yes (92.1%), no (7.9%)                       \n2 other (27.1%) ...                            \n3 no (81.2%), yes (18.8%)                      \n4 Thu (19.6%), Wed (17.5%), Tue (16.3%) ...    \n5 Apr (31.8%), Mar (31.4%), Feb (20.4%) ...    \n\nquantitative variables:  \n      name   class min      Q1  median        Q3     max        mean\n1 rownames numeric   1 2500.75 5000.50 7500.2500 10000.0 5000.500000\n2 distance numeric   0    0.94    1.78   15.5625    42.3    6.224144\n3     hour numeric   0   11.00   15.00   18.0000    23.0   14.177300\n           sd     n missing\n1 2886.895680 10000       0\n2    7.381397 10000       0\n3    4.359904 10000       0\n\n\n\ntaxi_modified &lt;- taxi %&gt;%\n  mutate(\n    dow = factor(dow,\n      levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"),\n      labels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"),\n      ordered = TRUE\n    ),\n    ##\n    local = factor(local,\n      levels = c(\"no\", \"yes\"),\n      labels = c(\"no\", \"yes\"),\n      ordered = TRUE\n    ),\n    ##\n    month = factor(month,\n      levels = c(\"Jan\", \"Feb\", \"Mar\", \"Apr\"),\n      labels = c(\"Jan\", \"Feb\", \"Mar\", \"Apr\"),\n      ordered = TRUE\n    )\n  )\ntaxi_modified %&gt;% glimpse()\n\nRows: 10,000\nColumns: 8\n$ rownames &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18…\n$ tip      &lt;chr&gt; \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\"…\n$ distance &lt;dbl&gt; 17.19, 0.88, 18.11, 20.70, 12.23, 0.94, 17.47, 17.67, 1.85, 1…\n$ company  &lt;chr&gt; \"Chicago Independents\", \"City Service\", \"other\", \"Chicago Ind…\n$ local    &lt;ord&gt; no, yes, no, no, no, yes, no, no, no, no, no, no, no, yes, no…\n$ dow      &lt;ord&gt; Thu, Thu, Mon, Mon, Sun, Sat, Fri, Sun, Fri, Tue, Tue, Sun, W…\n$ month    &lt;ord&gt; Feb, Mar, Feb, Apr, Mar, Apr, Mar, Jan, Apr, Mar, Mar, Apr, A…\n$ hour     &lt;dbl&gt; 16, 8, 18, 8, 21, 23, 12, 6, 12, 14, 18, 11, 12, 19, 17, 13, …\n\n\n\n## Set graph theme\n\ngf_bar(~tip, data = taxi_modified) %&gt;%\n  gf_labs(title = \"Plot 1A: Counts of Tips\")\n\n\n\n\n\n\n\n\n\ntaxi_modified %&gt;%\n  gf_bar(~tip,\n    fill = ~local,\n  ) %&gt;%\n  gf_labs(title = \"Plot 2A: Bar Chart\")\n\n\n\n\n\n\n\n\n\ntaxi_modified %&gt;%\n  gf_bar(~tip,\n    fill = ~local,\n    position = \"stack\"\n  ) %&gt;%\n  gf_labs(title = \"Plot 2A: Stacked Bar Chart\")\n\n\n\n\n\n\n\n\n\ntaxi_modified %&gt;%\n  gf_bar(~tip,\n    fill = ~local,\n    position = \"dodge\"\n  ) %&gt;%\n  gf_labs(title = \"Plot 2A: Dodged Bar Chart\")\n\n\n\n\n\n\n\n\n\ntaxi_modified %&gt;%\n  gf_bar(~tip,\n    fill = ~local,\n    position = \"fill\"\n  ) %&gt;%\n  gf_labs(title = \"Plot 2A: Dodged Bar Chart\")\n\n\n\n\n\n\n\n\n\ntaxi_modified %&gt;%\n  gf_bar(~company,\n    fill = ~tip,\n    position = \"fill\"\n  ) %&gt;%\n  gf_labs(\n    title = \"Plot 2D: Filled Bar Chart\",\n    subtitle = \"Shows Per group differences in Proportions!\"\n  )\n\n\n\n\n\n\n\n\n\ntaxi_modified %&gt;%\n  gf_bar(~hour,\n    fill = ~tip,\n  ) %&gt;%\n  gf_labs(\n    title = \"Plot B: Counts of Tips by Hour\"\n  )\n\n\n\n\n\n\n\n\n\ntaxi_modified %&gt;%\n  gf_bar(~dow,\n    fill = ~tip,\n  ) %&gt;%\n  gf_labs(\n    title = \"Plot C: Counts of Tips by Day of Week\"\n  )\n\n\n\n\n\n\n\n\n\ntaxi_modified %&gt;% \n  gf_bar(~month,\n    fill = ~tip\n  ) %&gt;% \n  gf_labs( title = \"Plot D: Counts of Tips by Month\")\n\n\n\n\n\n\n\n\n\ntaxi_modified %&gt;% \n  gf_bar(~month | dow,\n    fill = ~tip\n  ) %&gt;% \n  gf_labs( title = \"Plot D: Counts of Tips by day of week and month\")\n\n\n\n\n\n\n\n\n\ntaxi_modified %&gt;% \n  gf_bar(~dow | hour,\n    fill = ~tip\n  ) %&gt;% \n  gf_labs( \n    title = \"Plot F: Counts of Tips by Hour and Day of Week\",\n    subtitle = \"Is this plot arrangement easy to grasp?\"\n    )\n\n\n\n\n\n\n\n\n\ntaxi_modified %&gt;% \n  gf_bar(~dow | hour,\n    fill = ~tip,\n    position = \"fill\"\n  ) %&gt;% \n  gf_labs( \n    title = \"Plot F: Counts of Tips by Hour and Day of Week\",\n    subtitle = \"Is this plot arrangement easy to grasp?\"\n    )\n\n\n\n\n\n\n\n\n\ntaxi_modified %&gt;% \n  gf_bar(~hour | dow,\n    fill = ~tip,\n  ) %&gt;% \n  gf_labs( \n    title = \"Plot F: Counts of Tips by Hour and Day of Week\",\n    subtitle = \"Is this plot arrangement easy to grasp?\"\n    )\n\n\n\n\n\n\n\n\n\ntaxi_modified %&gt;% \n  gf_bar(~hour,\n    fill = ~tip,     \n    position = \"fill\"     \n  ) %&gt;% \n  gf_labs( \n    title = \"Plot F: Counts of Tips by Hour\"\n    )\n\n\n\n\n\n\n\n\n\n\n\n\napartments &lt;- read_csv(\"../../data/apartments.csv\")\n\nRows: 1460 Columns: 1\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): GrLivArea;SalePrice\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\napartments\n\n# A tibble: 1,460 × 1\n   `GrLivArea;SalePrice`\n   &lt;chr&gt;                \n 1 1710;208500          \n 2 1262;181500          \n 3 1786;223500          \n 4 1717;140000          \n 5 2198;250000          \n 6 1362;143000          \n 7 1694;307000          \n 8 2090;200000          \n 9 1774;129900          \n10 1077;118000          \n# ℹ 1,450 more rows\n\n\n\nglimpse(apartments)\n\nRows: 1,460\nColumns: 1\n$ `GrLivArea;SalePrice` &lt;chr&gt; \"1710;208500\", \"1262;181500\", \"1786;223500\", \"17…\n\n\n\n\n\napartments &lt;- read_delim(file = \"../../data/apartments.csv\",delim =\";\")\n\nRows: 1460 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\ndbl (2): GrLivArea, SalePrice\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nthe delimiter (delim) refers to the character that separates the columns of data in the file. In this case, the delimiter is specified as a semicolon (;). The delim = \";\" argument tells R that the columns in the CSV file are separated by semicolons.\n\nglimpse(apartments)\n\nRows: 1,460\nColumns: 2\n$ GrLivArea &lt;dbl&gt; 1710, 1262, 1786, 1717, 2198, 1362, 1694, 2090, 1774, 1077, …\n$ SalePrice &lt;dbl&gt; 208500, 181500, 223500, 140000, 250000, 143000, 307000, 2000…\n\n\n\nskim(apartments)\n\n\nData summary\n\n\nName\napartments\n\n\nNumber of rows\n1460\n\n\nNumber of columns\n2\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nGrLivArea\n0\n1\n1515.46\n525.48\n334\n1129.5\n1464\n1776.75\n5642\n▇▇▁▁▁\n\n\nSalePrice\n0\n1\n180921.20\n79442.50\n34900\n129975.0\n163000\n214000.00\n755000\n▇▅▁▁▁\n\n\n\n\n\n\ninspect(apartments)\n\n\nquantitative variables:  \n       name   class   min       Q1 median        Q3    max       mean\n1 GrLivArea numeric   334   1129.5   1464   1776.75   5642   1515.464\n2 SalePrice numeric 34900 129975.0 163000 214000.00 755000 180921.196\n          sd    n missing\n1   525.4804 1460       0\n2 79442.5029 1460       0\n\n\n\n\n\n\n\nFertility &lt;- read_csv(\"../../data/Fertility.csv\")\n\nRows: 254654 Columns: 9\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (6): morekids, gender1, gender2, afam, hispanic, other\ndbl (3): rownames, age, work\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nFertility\n\n# A tibble: 254,654 × 9\n   rownames morekids gender1 gender2   age afam  hispanic other  work\n      &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt; &lt;dbl&gt;\n 1        1 no       male    female     27 no    no       no        0\n 2        2 no       female  male       30 no    no       no       30\n 3        3 no       male    female     27 no    no       no        0\n 4        4 no       male    female     35 yes   no       no        0\n 5        5 no       female  female     30 no    no       no       22\n 6        6 no       male    female     26 no    no       no       40\n 7        7 no       female  male       29 no    no       no        0\n 8        8 no       male    male       33 no    no       no       52\n 9        9 no       female  male       29 no    no       no        0\n10       10 no       male    female     27 no    no       no        0\n# ℹ 254,644 more rows\n\n\n\nglimpse(Fertility)\n\nRows: 254,654\nColumns: 9\n$ rownames &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18…\n$ morekids &lt;chr&gt; \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"…\n$ gender1  &lt;chr&gt; \"male\", \"female\", \"male\", \"male\", \"female\", \"male\", \"female\",…\n$ gender2  &lt;chr&gt; \"female\", \"male\", \"female\", \"female\", \"female\", \"female\", \"ma…\n$ age      &lt;dbl&gt; 27, 30, 27, 35, 30, 26, 29, 33, 29, 27, 28, 28, 35, 34, 32, 2…\n$ afam     &lt;chr&gt; \"no\", \"no\", \"no\", \"yes\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", …\n$ hispanic &lt;chr&gt; \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"…\n$ other    &lt;chr&gt; \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"…\n$ work     &lt;dbl&gt; 0, 30, 0, 0, 22, 40, 0, 52, 0, 0, 0, 52, 52, 52, 8, 7, 0, 40,…\n\n\n\nskim(Fertility)\n\n\nData summary\n\n\nName\nFertility\n\n\nNumber of rows\n254654\n\n\nNumber of columns\n9\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n6\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nmorekids\n0\n1\n2\n3\n0\n2\n0\n\n\ngender1\n0\n1\n4\n6\n0\n2\n0\n\n\ngender2\n0\n1\n4\n6\n0\n2\n0\n\n\nafam\n0\n1\n2\n3\n0\n2\n0\n\n\nhispanic\n0\n1\n2\n3\n0\n2\n0\n\n\nother\n0\n1\n2\n3\n0\n2\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nrownames\n0\n1\n127327.50\n73512.42\n1\n63664.25\n127327.5\n190990.8\n254654\n▇▇▇▇▇\n\n\nage\n0\n1\n30.39\n3.39\n21\n28.00\n31.0\n33.0\n35\n▁▃▅▇▇\n\n\nwork\n0\n1\n19.02\n21.87\n0\n0.00\n5.0\n44.0\n52\n▇▁▁▁▃\n\n\n\n\n\n\ninspect(Fertility)\n\n\ncategorical variables:  \n      name     class levels      n missing\n1 morekids character      2 254654       0\n2  gender1 character      2 254654       0\n3  gender2 character      2 254654       0\n4     afam character      2 254654       0\n5 hispanic character      2 254654       0\n6    other character      2 254654       0\n                                   distribution\n1 no (61.9%), yes (38.1%)                      \n2 male (51.4%), female (48.6%)                 \n3 male (51.3%), female (48.7%)                 \n4 no (94.8%), yes (5.2%)                       \n5 no (92.6%), yes (7.4%)                       \n6 no (94.4%), yes (5.6%)                       \n\nquantitative variables:  \n      name   class min       Q1   median       Q3    max         mean\n1 rownames numeric   1 63664.25 127327.5 190990.8 254654 127327.50000\n2      age numeric  21    28.00     31.0     33.0     35     30.39327\n3     work numeric   0     0.00      5.0     44.0     52     19.01833\n            sd      n missing\n1 73512.422063 254654       0\n2     3.386447 254654       0\n3    21.867277 254654       0\n\n\nWe need to convert six of these variables into factors.\n\nFertility_modified &lt;- Fertility %&gt;% dplyr::mutate(\n  morekids = as_factor(morekids),\n  gender1 = as_factor(gender1),\n  gender2 = as_factor(gender2),\n  afam = as_factor(afam),\n  hispanic = as_factor(hispanic),\n  other = as_factor(other)\n)\n\nglimpse(Fertility_modified)\n\nRows: 254,654\nColumns: 9\n$ rownames &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18…\n$ morekids &lt;fct&gt; no, no, no, no, no, no, no, no, no, no, yes, no, no, no, no, …\n$ gender1  &lt;fct&gt; male, female, male, male, female, male, female, male, female,…\n$ gender2  &lt;fct&gt; female, male, female, female, female, female, male, male, mal…\n$ age      &lt;dbl&gt; 27, 30, 27, 35, 30, 26, 29, 33, 29, 27, 28, 28, 35, 34, 32, 2…\n$ afam     &lt;fct&gt; no, no, no, yes, no, no, no, no, no, no, no, no, no, no, no, …\n$ hispanic &lt;fct&gt; no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, n…\n$ other    &lt;fct&gt; no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, n…\n$ work     &lt;dbl&gt; 0, 30, 0, 0, 22, 40, 0, 52, 0, 0, 0, 52, 52, 52, 8, 7, 0, 40,…\n\n\n\nFertility_modified %&gt;%\n  gf_bar(~morekids,\n    fill = ~gender1,\n    position = \"dodge\",\n  ) %&gt;%\n  gf_labs(title = \"Distribution gender1 based on morekids\")\n\n\n\n\n\n\n\n\n\nthis graph shows that within gender1, there are more individuals that do not have another kid. Ratio of men:women is closer to equal, with men being more, for the ones that do have more kids.\nIt appears that more individuals under the category of gender1 have chosen not to have more than one little menaces in their lives.\n\nLet’s now see what’s the case with gender2.\n\nFertility_modified %&gt;%\n  gf_bar(~morekids,\n    fill = ~gender2,\n    position = \"dodge\",\n  ) %&gt;%\n  gf_labs(title = \"Distribution gender2 based on morekids\")\n\n\n\n\n\n\n\n\n\nHere, the ratio of women is more than men in both the cases.\n\n\nFertility_modified %&gt;%\n  gf_bar(~age | ~gender2,\n         fill = ~gender1,\n         position = \"dodge\"\n  ) %&gt;%\n  gf_labs(title = \"Distribution of Age by gender1 and gender2\")\n\n\n\n\n\n\n\n\n\nFertility_modified %&gt;%\n  gf_bar(~work,\n         fill = ~afam,\n  ) %&gt;%\n  gf_labs(title = \"Distribution of Work Hours by afam\")\n\n\n\n\n\n\n\n\n\nHere, the real problem is that I have terribly, horribly failed at understanding what ‘afam’ actually is. Is it short for -’ African American’, or is it - ‘Alliance for Action to Strengthen Marriages and Family’ (suggested by google)? The former obviously makes more sense.\n\n\nFertility_modified %&gt;%\n  gf_bar(~work,\n         fill = ~gender1,\n  ) %&gt;%\n  gf_labs(title = \"Distribution of Work Hours by gender1\")\n\n\n\n\n\n\n\n\n\nFertility_modified %&gt;%\n  gf_bar(~work,\n         fill = ~gender2,\n  ) %&gt;%\n  gf_labs(title = \"Distribution of Work Hours by gender2\")\n\n\n\n\n\n\n\n\n\nFertility_modified %&gt;%\n  gf_bar(~hispanic,\n  ) %&gt;%\n  gf_labs(title = \"Distribution of hispanic\")"
  },
  {
    "objectID": "posts/blog-day-3/index.html#we-are-examining-the-taxi-data-set",
    "href": "posts/blog-day-3/index.html#we-are-examining-the-taxi-data-set",
    "title": "Day-3",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(ggformula)\nlibrary(skimr)\n\n\nAttaching package: 'skimr'\n\nThe following object is masked from 'package:mosaic':\n\n    n_missing\n\n\n\ntaxi &lt;- read_csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/modeldata/taxi.csv\")\n\nRows: 10000 Columns: 8\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): tip, company, local, dow, month\ndbl (3): rownames, distance, hour\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ntaxi\n\n# A tibble: 10,000 × 8\n   rownames tip   distance company                      local dow   month  hour\n      &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;                        &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;\n 1        1 yes      17.2  Chicago Independents         no    Thu   Feb      16\n 2        2 yes       0.88 City Service                 yes   Thu   Mar       8\n 3        3 yes      18.1  other                        no    Mon   Feb      18\n 4        4 yes      20.7  Chicago Independents         no    Mon   Apr       8\n 5        5 yes      12.2  Chicago Independents         no    Sun   Mar      21\n 6        6 yes       0.94 Sun Taxi                     yes   Sat   Apr      23\n 7        7 yes      17.5  Flash Cab                    no    Fri   Mar      12\n 8        8 yes      17.7  other                        no    Sun   Jan       6\n 9        9 yes       1.85 Taxicab Insurance Agency Llc no    Fri   Apr      12\n10       10 yes       1.47 City Service                 no    Tue   Mar      14\n# ℹ 9,990 more rows\n\n\n\nglimpse(taxi)\n\nRows: 10,000\nColumns: 8\n$ rownames &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18…\n$ tip      &lt;chr&gt; \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\"…\n$ distance &lt;dbl&gt; 17.19, 0.88, 18.11, 20.70, 12.23, 0.94, 17.47, 17.67, 1.85, 1…\n$ company  &lt;chr&gt; \"Chicago Independents\", \"City Service\", \"other\", \"Chicago Ind…\n$ local    &lt;chr&gt; \"no\", \"yes\", \"no\", \"no\", \"no\", \"yes\", \"no\", \"no\", \"no\", \"no\",…\n$ dow      &lt;chr&gt; \"Thu\", \"Thu\", \"Mon\", \"Mon\", \"Sun\", \"Sat\", \"Fri\", \"Sun\", \"Fri\"…\n$ month    &lt;chr&gt; \"Feb\", \"Mar\", \"Feb\", \"Apr\", \"Mar\", \"Apr\", \"Mar\", \"Jan\", \"Apr\"…\n$ hour     &lt;dbl&gt; 16, 8, 18, 8, 21, 23, 12, 6, 12, 14, 18, 11, 12, 19, 17, 13, …\n\n\n\nskim(taxi)\n\n\nData summary\n\n\nName\ntaxi\n\n\nNumber of rows\n10000\n\n\nNumber of columns\n8\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n5\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ntip\n0\n1\n2\n3\n0\n2\n0\n\n\ncompany\n0\n1\n5\n28\n0\n7\n0\n\n\nlocal\n0\n1\n2\n3\n0\n2\n0\n\n\ndow\n0\n1\n3\n3\n0\n7\n0\n\n\nmonth\n0\n1\n3\n3\n0\n4\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nrownames\n0\n1\n5000.50\n2886.90\n1\n2500.75\n5000.50\n7500.25\n10000.0\n▇▇▇▇▇\n\n\ndistance\n0\n1\n6.22\n7.38\n0\n0.94\n1.78\n15.56\n42.3\n▇▁▂▁▁\n\n\nhour\n0\n1\n14.18\n4.36\n0\n11.00\n15.00\n18.00\n23.0\n▁▃▅▇▃\n\n\n\n\n\n\ninspect(taxi)\n\n\ncategorical variables:  \n     name     class levels     n missing\n1     tip character      2 10000       0\n2 company character      7 10000       0\n3   local character      2 10000       0\n4     dow character      7 10000       0\n5   month character      4 10000       0\n                                   distribution\n1 yes (92.1%), no (7.9%)                       \n2 other (27.1%) ...                            \n3 no (81.2%), yes (18.8%)                      \n4 Thu (19.6%), Wed (17.5%), Tue (16.3%) ...    \n5 Apr (31.8%), Mar (31.4%), Feb (20.4%) ...    \n\nquantitative variables:  \n      name   class min      Q1  median        Q3     max        mean\n1 rownames numeric   1 2500.75 5000.50 7500.2500 10000.0 5000.500000\n2 distance numeric   0    0.94    1.78   15.5625    42.3    6.224144\n3     hour numeric   0   11.00   15.00   18.0000    23.0   14.177300\n           sd     n missing\n1 2886.895680 10000       0\n2    7.381397 10000       0\n3    4.359904 10000       0\n\n\n\ntaxi_modified &lt;- taxi %&gt;%\n  mutate(\n    dow = factor(dow,\n      levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"),\n      labels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"),\n      ordered = TRUE\n    ),\n    ##\n    local = factor(local,\n      levels = c(\"no\", \"yes\"),\n      labels = c(\"no\", \"yes\"),\n      ordered = TRUE\n    ),\n    ##\n    month = factor(month,\n      levels = c(\"Jan\", \"Feb\", \"Mar\", \"Apr\"),\n      labels = c(\"Jan\", \"Feb\", \"Mar\", \"Apr\"),\n      ordered = TRUE\n    )\n  )\ntaxi_modified %&gt;% glimpse()\n\nRows: 10,000\nColumns: 8\n$ rownames &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18…\n$ tip      &lt;chr&gt; \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\"…\n$ distance &lt;dbl&gt; 17.19, 0.88, 18.11, 20.70, 12.23, 0.94, 17.47, 17.67, 1.85, 1…\n$ company  &lt;chr&gt; \"Chicago Independents\", \"City Service\", \"other\", \"Chicago Ind…\n$ local    &lt;ord&gt; no, yes, no, no, no, yes, no, no, no, no, no, no, no, yes, no…\n$ dow      &lt;ord&gt; Thu, Thu, Mon, Mon, Sun, Sat, Fri, Sun, Fri, Tue, Tue, Sun, W…\n$ month    &lt;ord&gt; Feb, Mar, Feb, Apr, Mar, Apr, Mar, Jan, Apr, Mar, Mar, Apr, A…\n$ hour     &lt;dbl&gt; 16, 8, 18, 8, 21, 23, 12, 6, 12, 14, 18, 11, 12, 19, 17, 13, …\n\n\n\n## Set graph theme\n\ngf_bar(~tip, data = taxi_modified) %&gt;%\n  gf_labs(title = \"Plot 1A: Counts of Tips\")\n\n\n\n\n\n\n\n\n\ntaxi_modified %&gt;%\n  gf_bar(~tip,\n    fill = ~local,\n  ) %&gt;%\n  gf_labs(title = \"Plot 2A: Bar Chart\")\n\n\n\n\n\n\n\n\n\ntaxi_modified %&gt;%\n  gf_bar(~tip,\n    fill = ~local,\n    position = \"stack\"\n  ) %&gt;%\n  gf_labs(title = \"Plot 2A: Stacked Bar Chart\")\n\n\n\n\n\n\n\n\n\ntaxi_modified %&gt;%\n  gf_bar(~tip,\n    fill = ~local,\n    position = \"dodge\"\n  ) %&gt;%\n  gf_labs(title = \"Plot 2A: Dodged Bar Chart\")\n\n\n\n\n\n\n\n\n\ntaxi_modified %&gt;%\n  gf_bar(~tip,\n    fill = ~local,\n    position = \"fill\"\n  ) %&gt;%\n  gf_labs(title = \"Plot 2A: Dodged Bar Chart\")\n\n\n\n\n\n\n\n\n\ntaxi_modified %&gt;%\n  gf_bar(~company,\n    fill = ~tip,\n    position = \"fill\"\n  ) %&gt;%\n  gf_labs(\n    title = \"Plot 2D: Filled Bar Chart\",\n    subtitle = \"Shows Per group differences in Proportions!\"\n  )\n\n\n\n\n\n\n\n\n\ntaxi_modified %&gt;%\n  gf_bar(~hour,\n    fill = ~tip,\n  ) %&gt;%\n  gf_labs(\n    title = \"Plot B: Counts of Tips by Hour\"\n  )\n\n\n\n\n\n\n\n\n\ntaxi_modified %&gt;%\n  gf_bar(~dow,\n    fill = ~tip,\n  ) %&gt;%\n  gf_labs(\n    title = \"Plot C: Counts of Tips by Day of Week\"\n  )\n\n\n\n\n\n\n\n\n\ntaxi_modified %&gt;% \n  gf_bar(~month,\n    fill = ~tip\n  ) %&gt;% \n  gf_labs( title = \"Plot D: Counts of Tips by Month\")\n\n\n\n\n\n\n\n\n\ntaxi_modified %&gt;% \n  gf_bar(~month | dow,\n    fill = ~tip\n  ) %&gt;% \n  gf_labs( title = \"Plot D: Counts of Tips by day of week and month\")\n\n\n\n\n\n\n\n\n\ntaxi_modified %&gt;% \n  gf_bar(~dow | hour,\n    fill = ~tip\n  ) %&gt;% \n  gf_labs( \n    title = \"Plot F: Counts of Tips by Hour and Day of Week\",\n    subtitle = \"Is this plot arrangement easy to grasp?\"\n    )\n\n\n\n\n\n\n\n\n\ntaxi_modified %&gt;% \n  gf_bar(~dow | hour,\n    fill = ~tip,\n    position = \"fill\"\n  ) %&gt;% \n  gf_labs( \n    title = \"Plot F: Counts of Tips by Hour and Day of Week\",\n    subtitle = \"Is this plot arrangement easy to grasp?\"\n    )\n\n\n\n\n\n\n\n\n\ntaxi_modified %&gt;% \n  gf_bar(~hour | dow,\n    fill = ~tip,\n  ) %&gt;% \n  gf_labs( \n    title = \"Plot F: Counts of Tips by Hour and Day of Week\",\n    subtitle = \"Is this plot arrangement easy to grasp?\"\n    )\n\n\n\n\n\n\n\n\n\ntaxi_modified %&gt;% \n  gf_bar(~hour,\n    fill = ~tip,     \n    position = \"fill\"     \n  ) %&gt;% \n  gf_labs( \n    title = \"Plot F: Counts of Tips by Hour\"\n    )"
  },
  {
    "objectID": "posts/blog-day-3/index.html#analysing-the-apartment-dataset-your-turn",
    "href": "posts/blog-day-3/index.html#analysing-the-apartment-dataset-your-turn",
    "title": "Day-3",
    "section": "",
    "text": "apartments &lt;- read_csv(\"../../data/apartments.csv\")\n\nRows: 1460 Columns: 1\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): GrLivArea;SalePrice\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\napartments\n\n# A tibble: 1,460 × 1\n   `GrLivArea;SalePrice`\n   &lt;chr&gt;                \n 1 1710;208500          \n 2 1262;181500          \n 3 1786;223500          \n 4 1717;140000          \n 5 2198;250000          \n 6 1362;143000          \n 7 1694;307000          \n 8 2090;200000          \n 9 1774;129900          \n10 1077;118000          \n# ℹ 1,450 more rows\n\n\n\nglimpse(apartments)\n\nRows: 1,460\nColumns: 1\n$ `GrLivArea;SalePrice` &lt;chr&gt; \"1710;208500\", \"1262;181500\", \"1786;223500\", \"17…\n\n\n\n\n\napartments &lt;- read_delim(file = \"../../data/apartments.csv\",delim =\";\")\n\nRows: 1460 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\ndbl (2): GrLivArea, SalePrice\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nthe delimiter (delim) refers to the character that separates the columns of data in the file. In this case, the delimiter is specified as a semicolon (;). The delim = \";\" argument tells R that the columns in the CSV file are separated by semicolons.\n\nglimpse(apartments)\n\nRows: 1,460\nColumns: 2\n$ GrLivArea &lt;dbl&gt; 1710, 1262, 1786, 1717, 2198, 1362, 1694, 2090, 1774, 1077, …\n$ SalePrice &lt;dbl&gt; 208500, 181500, 223500, 140000, 250000, 143000, 307000, 2000…\n\n\n\nskim(apartments)\n\n\nData summary\n\n\nName\napartments\n\n\nNumber of rows\n1460\n\n\nNumber of columns\n2\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nGrLivArea\n0\n1\n1515.46\n525.48\n334\n1129.5\n1464\n1776.75\n5642\n▇▇▁▁▁\n\n\nSalePrice\n0\n1\n180921.20\n79442.50\n34900\n129975.0\n163000\n214000.00\n755000\n▇▅▁▁▁\n\n\n\n\n\n\ninspect(apartments)\n\n\nquantitative variables:  \n       name   class   min       Q1 median        Q3    max       mean\n1 GrLivArea numeric   334   1129.5   1464   1776.75   5642   1515.464\n2 SalePrice numeric 34900 129975.0 163000 214000.00 755000 180921.196\n          sd    n missing\n1   525.4804 1460       0\n2 79442.5029 1460       0"
  },
  {
    "objectID": "posts/blog-day-3/index.html#fertility-dataset",
    "href": "posts/blog-day-3/index.html#fertility-dataset",
    "title": "Day-3",
    "section": "",
    "text": "Fertility &lt;- read_csv(\"../../data/Fertility.csv\")\n\nRows: 254654 Columns: 9\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (6): morekids, gender1, gender2, afam, hispanic, other\ndbl (3): rownames, age, work\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nFertility\n\n# A tibble: 254,654 × 9\n   rownames morekids gender1 gender2   age afam  hispanic other  work\n      &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt; &lt;dbl&gt;\n 1        1 no       male    female     27 no    no       no        0\n 2        2 no       female  male       30 no    no       no       30\n 3        3 no       male    female     27 no    no       no        0\n 4        4 no       male    female     35 yes   no       no        0\n 5        5 no       female  female     30 no    no       no       22\n 6        6 no       male    female     26 no    no       no       40\n 7        7 no       female  male       29 no    no       no        0\n 8        8 no       male    male       33 no    no       no       52\n 9        9 no       female  male       29 no    no       no        0\n10       10 no       male    female     27 no    no       no        0\n# ℹ 254,644 more rows\n\n\n\nglimpse(Fertility)\n\nRows: 254,654\nColumns: 9\n$ rownames &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18…\n$ morekids &lt;chr&gt; \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"…\n$ gender1  &lt;chr&gt; \"male\", \"female\", \"male\", \"male\", \"female\", \"male\", \"female\",…\n$ gender2  &lt;chr&gt; \"female\", \"male\", \"female\", \"female\", \"female\", \"female\", \"ma…\n$ age      &lt;dbl&gt; 27, 30, 27, 35, 30, 26, 29, 33, 29, 27, 28, 28, 35, 34, 32, 2…\n$ afam     &lt;chr&gt; \"no\", \"no\", \"no\", \"yes\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", …\n$ hispanic &lt;chr&gt; \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"…\n$ other    &lt;chr&gt; \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"…\n$ work     &lt;dbl&gt; 0, 30, 0, 0, 22, 40, 0, 52, 0, 0, 0, 52, 52, 52, 8, 7, 0, 40,…\n\n\n\nskim(Fertility)\n\n\nData summary\n\n\nName\nFertility\n\n\nNumber of rows\n254654\n\n\nNumber of columns\n9\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n6\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nmorekids\n0\n1\n2\n3\n0\n2\n0\n\n\ngender1\n0\n1\n4\n6\n0\n2\n0\n\n\ngender2\n0\n1\n4\n6\n0\n2\n0\n\n\nafam\n0\n1\n2\n3\n0\n2\n0\n\n\nhispanic\n0\n1\n2\n3\n0\n2\n0\n\n\nother\n0\n1\n2\n3\n0\n2\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nrownames\n0\n1\n127327.50\n73512.42\n1\n63664.25\n127327.5\n190990.8\n254654\n▇▇▇▇▇\n\n\nage\n0\n1\n30.39\n3.39\n21\n28.00\n31.0\n33.0\n35\n▁▃▅▇▇\n\n\nwork\n0\n1\n19.02\n21.87\n0\n0.00\n5.0\n44.0\n52\n▇▁▁▁▃\n\n\n\n\n\n\ninspect(Fertility)\n\n\ncategorical variables:  \n      name     class levels      n missing\n1 morekids character      2 254654       0\n2  gender1 character      2 254654       0\n3  gender2 character      2 254654       0\n4     afam character      2 254654       0\n5 hispanic character      2 254654       0\n6    other character      2 254654       0\n                                   distribution\n1 no (61.9%), yes (38.1%)                      \n2 male (51.4%), female (48.6%)                 \n3 male (51.3%), female (48.7%)                 \n4 no (94.8%), yes (5.2%)                       \n5 no (92.6%), yes (7.4%)                       \n6 no (94.4%), yes (5.6%)                       \n\nquantitative variables:  \n      name   class min       Q1   median       Q3    max         mean\n1 rownames numeric   1 63664.25 127327.5 190990.8 254654 127327.50000\n2      age numeric  21    28.00     31.0     33.0     35     30.39327\n3     work numeric   0     0.00      5.0     44.0     52     19.01833\n            sd      n missing\n1 73512.422063 254654       0\n2     3.386447 254654       0\n3    21.867277 254654       0\n\n\nWe need to convert six of these variables into factors.\n\nFertility_modified &lt;- Fertility %&gt;% dplyr::mutate(\n  morekids = as_factor(morekids),\n  gender1 = as_factor(gender1),\n  gender2 = as_factor(gender2),\n  afam = as_factor(afam),\n  hispanic = as_factor(hispanic),\n  other = as_factor(other)\n)\n\nglimpse(Fertility_modified)\n\nRows: 254,654\nColumns: 9\n$ rownames &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18…\n$ morekids &lt;fct&gt; no, no, no, no, no, no, no, no, no, no, yes, no, no, no, no, …\n$ gender1  &lt;fct&gt; male, female, male, male, female, male, female, male, female,…\n$ gender2  &lt;fct&gt; female, male, female, female, female, female, male, male, mal…\n$ age      &lt;dbl&gt; 27, 30, 27, 35, 30, 26, 29, 33, 29, 27, 28, 28, 35, 34, 32, 2…\n$ afam     &lt;fct&gt; no, no, no, yes, no, no, no, no, no, no, no, no, no, no, no, …\n$ hispanic &lt;fct&gt; no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, n…\n$ other    &lt;fct&gt; no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, n…\n$ work     &lt;dbl&gt; 0, 30, 0, 0, 22, 40, 0, 52, 0, 0, 0, 52, 52, 52, 8, 7, 0, 40,…\n\n\n\nFertility_modified %&gt;%\n  gf_bar(~morekids,\n    fill = ~gender1,\n    position = \"dodge\",\n  ) %&gt;%\n  gf_labs(title = \"Distribution gender1 based on morekids\")\n\n\n\n\n\n\n\n\n\nthis graph shows that within gender1, there are more individuals that do not have another kid. Ratio of men:women is closer to equal, with men being more, for the ones that do have more kids.\nIt appears that more individuals under the category of gender1 have chosen not to have more than one little menaces in their lives.\n\nLet’s now see what’s the case with gender2.\n\nFertility_modified %&gt;%\n  gf_bar(~morekids,\n    fill = ~gender2,\n    position = \"dodge\",\n  ) %&gt;%\n  gf_labs(title = \"Distribution gender2 based on morekids\")\n\n\n\n\n\n\n\n\n\nHere, the ratio of women is more than men in both the cases.\n\n\nFertility_modified %&gt;%\n  gf_bar(~age | ~gender2,\n         fill = ~gender1,\n         position = \"dodge\"\n  ) %&gt;%\n  gf_labs(title = \"Distribution of Age by gender1 and gender2\")\n\n\n\n\n\n\n\n\n\nFertility_modified %&gt;%\n  gf_bar(~work,\n         fill = ~afam,\n  ) %&gt;%\n  gf_labs(title = \"Distribution of Work Hours by afam\")\n\n\n\n\n\n\n\n\n\nHere, the real problem is that I have terribly, horribly failed at understanding what ‘afam’ actually is. Is it short for -’ African American’, or is it - ‘Alliance for Action to Strengthen Marriages and Family’ (suggested by google)? The former obviously makes more sense.\n\n\nFertility_modified %&gt;%\n  gf_bar(~work,\n         fill = ~gender1,\n  ) %&gt;%\n  gf_labs(title = \"Distribution of Work Hours by gender1\")\n\n\n\n\n\n\n\n\n\nFertility_modified %&gt;%\n  gf_bar(~work,\n         fill = ~gender2,\n  ) %&gt;%\n  gf_labs(title = \"Distribution of Work Hours by gender2\")\n\n\n\n\n\n\n\n\n\nFertility_modified %&gt;%\n  gf_bar(~hispanic,\n  ) %&gt;%\n  gf_labs(title = \"Distribution of hispanic\")"
  },
  {
    "objectID": "posts/Aish-day-5/index.html",
    "href": "posts/Aish-day-5/index.html",
    "title": "day-5",
    "section": "",
    "text": "Today, we are learning all about box plots.\n\ndata visualization that gives us an idea of the distribution of a Quant variable, for each level of another Qual variable.\nboxplot focuses on the mean and quartiles. It uses sequence number or ranks of Quant variable.\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(ggformula)\nlibrary(palmerpenguins) # Our new favourite dataset\n\n\nwages &lt;- read_csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/gss_wages.csv\")\n\nRows: 61697 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): occrecode, wrkstat, gender, educcat, maritalcat\ndbl (7): rownames, year, realrinc, age, occ10, prestg10, childs\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nglimpse(wages)\n\nRows: 61,697\nColumns: 12\n$ rownames   &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ year       &lt;dbl&gt; 1974, 1974, 1974, 1974, 1974, 1974, 1974, 1974, 1974, 1974,…\n$ realrinc   &lt;dbl&gt; 4935, 43178, NA, NA, 18505, 22206, 55515, NA, NA, 4935, NA,…\n$ age        &lt;dbl&gt; 21, 41, 83, 69, 58, 30, 48, 67, 51, 54, 89, 71, 27, 30, 22,…\n$ occ10      &lt;dbl&gt; 5620, 2040, NA, NA, 5820, 910, 230, 6355, 4720, 3940, 4810,…\n$ occrecode  &lt;chr&gt; \"Office and Administrative Support\", \"Professional\", NA, NA…\n$ prestg10   &lt;dbl&gt; 25, 66, NA, NA, 37, 45, 59, 49, 28, 38, 47, 45, 50, 29, 33,…\n$ childs     &lt;dbl&gt; 0, 3, 2, 2, 0, 0, 2, 1, 2, 2, 3, 1, 4, 3, 0, 1, 2, 3, 4, 8,…\n$ wrkstat    &lt;chr&gt; \"School\", \"Full-Time\", \"Housekeeper\", \"Housekeeper\", \"Full-…\n$ gender     &lt;chr&gt; \"Male\", \"Male\", \"Female\", \"Female\", \"Female\", \"Male\", \"Male…\n$ educcat    &lt;chr&gt; \"High School\", \"Bachelor\", \"Less Than High School\", \"Less T…\n$ maritalcat &lt;chr&gt; \"Married\", \"Married\", \"Widowed\", \"Widowed\", \"Never Married\"…\n\n\n\nskimr::skim(wages)\n\n\nData summary\n\n\nName\nwages\n\n\nNumber of rows\n61697\n\n\nNumber of columns\n12\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n5\n\n\nnumeric\n7\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\noccrecode\n3561\n0.94\n5\n37\n0\n11\n0\n\n\nwrkstat\n21\n1.00\n5\n23\n0\n8\n0\n\n\ngender\n0\n1.00\n4\n6\n0\n2\n0\n\n\neduccat\n135\n1.00\n8\n21\n0\n5\n0\n\n\nmaritalcat\n27\n1.00\n7\n13\n0\n5\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nrownames\n0\n1.00\n30849.00\n17810.53\n1\n15425\n30849\n46273\n61697.0\n▇▇▇▇▇\n\n\nyear\n0\n1.00\n1996.07\n12.79\n1974\n1985\n1996\n2006\n2018.0\n▆▇▇▇▇\n\n\nrealrinc\n23810\n0.61\n22326.36\n28581.79\n227\n8156\n16563\n27171\n480144.5\n▇▁▁▁▁\n\n\nage\n219\n1.00\n46.18\n17.56\n18\n32\n44\n59\n89.0\n▇▇▆▅▂\n\n\nocc10\n3561\n0.94\n4695.77\n2627.72\n10\n2710\n4720\n6230\n9997.0\n▃▅▇▂▃\n\n\nprestg10\n4186\n0.93\n43.06\n12.99\n16\n33\n42\n50\n80.0\n▃▇▇▃▁\n\n\nchilds\n189\n1.00\n1.92\n1.76\n0\n0\n2\n3\n8.0\n▇▇▂▁▁\n\n\n\n\n\n\ninspect(wages)\n\n\ncategorical variables:  \n        name     class levels     n missing\n1  occrecode character     11 58136    3561\n2    wrkstat character      8 61676      21\n3     gender character      2 61697       0\n4    educcat character      5 61562     135\n5 maritalcat character      5 61670      27\n                                   distribution\n1 Professional (19%), Service (16.9%) ...      \n2 Full-Time (49.4%), Housekeeper (15.1%) ...   \n3 Female (56.1%), Male (43.9%)                 \n4 High School (51.5%) ...                      \n5 Married (51.7%), Never Married (21.8%) ...   \n\nquantitative variables:  \n      name   class  min    Q1 median    Q3      max         mean           sd\n1 rownames numeric    1 15425  30849 46273  61697.0 30849.000000 17810.534116\n2     year numeric 1974  1985   1996  2006   2018.0  1996.073715    12.794470\n3 realrinc numeric  227  8156  16563 27171 480144.5 22326.359234 28581.794499\n4      age numeric   18    32     44    59     89.0    46.176177    17.561065\n5    occ10 numeric   10  2710   4720  6230   9997.0  4695.774081  2627.724076\n6 prestg10 numeric   16    33     42    50     80.0    43.060701    12.987526\n7   childs numeric    0     0      2     3      8.0     1.923457     1.763569\n      n missing\n1 61697       0\n2 61697       0\n3 37887   23810\n4 61478     219\n5 58136    3561\n6 57511    4186\n7 61508     189\n\n\n\nwages_clean &lt;-\n  wages %&gt;%\n  tidyr::drop_na(realrinc) # choose column or leave blank to choose all\n\n\nwages_clean &lt;-  wages %&gt;% tidyr::drop_na(realrinc)\n\n\n\n\nwages_clean %&gt;%\n  gf_boxplot(realrinc ~ \"Income\") %&gt;% # Dummy X-axis \"variable\"\n  gf_labs(\n    title = \"Plot 1A: Income has a skewed distribution\",\n    subtitle = \"Many outliers on the high side\"\n  )\n\n\n\n\n\n\n\n\n\nIncome is a very skewed distribution, as might be expected.\nPresence of many higher-side outliers is noted.\n\n\n\n\n\nwages_clean %&gt;%\n  gf_boxplot(gender ~ realrinc) %&gt;%\n  gf_labs(title = \"Plot 2A: Income by Gender\")\n\n\n\n\n\n\n\n\n\nwages_clean %&gt;%\n  gf_boxplot(gender ~ log10(realrinc)) %&gt;%\n  gf_labs(title = \"Plot 2B: Log(Income) by Gender\")\n\n\n\n\n\n\n\n\n\nlog10(realrinc) means we’re using a math trick to shrink down the income numbers so they’re easier to compare (think of it like zooming out to see the differences better).\nboth codes are making pictures to show how much each gender makes, but the second one uses a “zoomed-out” version of income numbers to make things clearer.\n\n\nwages_clean %&gt;%\n  gf_boxplot(gender ~ realrinc, fill = ~gender) %&gt;%\n  gf_refine(scale_x_log10()) %&gt;%\n  gf_labs(title = \"Plot 2C: Income filled by Gender, log scale\")\n\n\n\n\n\n\n\n\n\nThe IQR for males is smaller than the IQR for females. There is less variation in the middle ranges of realrinc for men.\nThere are outliers on both sides, indicating that there may be many people who make very small amounts of money and large amounts of money in both genders.\n\n\n\n\n\nwages_clean %&gt;%\n  gf_boxplot(educcat ~ realrinc) %&gt;%\n  gf_labs(title = \"Plot 3A: Income by Education Category\")\n\n\n\n\n\n\n\n\n\nwages_clean %&gt;%\n  gf_boxplot(educcat ~ log10(realrinc)) %&gt;%\n  gf_labs(title = \"Plot 3B: Log(Income) by Education Category\")\n\n\n\n\n\n\n\n\n\nwages_clean %&gt;%\n  gf_boxplot(\n    reorder(educcat, realrinc, FUN = median) ~ log(realrinc),\n    fill = ~educcat,\n    alpha = 0.3\n  ) %&gt;%\n  gf_labs(title = \"Plot 3C: Log(Income) by Education Category, sorted\") %&gt;%\n  gf_labs(\n    x = \"Log Income\",\n    y = \"Education Category\"\n  )\n\n\n\n\n\n\n\n\n\nwages_clean %&gt;%\n  gf_boxplot(reorder(educcat, realrinc, FUN = median) ~ realrinc,\n    fill = ~educcat,\n    alpha = 0.5\n  ) %&gt;%\n  gf_refine(scale_x_log10()) %&gt;%\n  gf_labs(\n    title = \"Plot 3D: Income by Education Category, sorted\",\n    subtitle = \"Log Income\"\n  ) %&gt;%\n  gf_labs(\n    x = \"Income\",\n    y = \"Education Category\"\n  )\n\n\n\n\n\n\n\n\n\nrealrinc rises with educcat, which is to be expected.\nHowever, there are people with very low and very high income in all categories of educcat\nHence educcat alone may not be a good predictor for realrinc.\n\n\n\n\n\nwages %&gt;%\n  drop_na() %&gt;%\n  gf_boxplot(reorder(educcat, realrinc) ~ log10(realrinc),\n    fill = ~educcat,\n    alpha = 0.5\n  ) %&gt;%\n  gf_facet_wrap(vars(childs)) %&gt;%\n  gf_refine(scale_fill_brewer(type = \"qual\", palette = \"Dark2\")) %&gt;%\n  gf_labs(\n    title = \"Plot 4A: Log Income by Education Category and Family Size\",\n    x = \"Log income\",\n    y = \"No. of Children\"\n  )\n\n\n\n\n\n\n\n\n\nwages %&gt;%\n  drop_na() %&gt;%\n  mutate(childs = as_factor(childs)) %&gt;%\n  gf_boxplot(childs ~ log10(realrinc),\n    group = ~childs,\n    fill = ~childs,\n    alpha = 0.5\n  ) %&gt;%\n  gf_facet_wrap(~gender) %&gt;%\n  gf_refine(scale_fill_brewer(type = \"qual\", palette = \"Set3\")) %&gt;%\n  gf_labs(\n    title = \"Plot 4B: Log Income by Gender and Family Size\",\n    x = \"Log income\",\n    y = \"No. of Children\"\n  )\n\n\n\n\n\n\n\n\n\nFrom Figure 6, we see that realrinc increases with educcat, across (almost) all family sizes childs.\nHowever, this trend breaks a little when family sizes childs is large, say &gt;= 7. Be aware that the data observations for such large families may be sparse and this inference may not be necessarily valid.\nFrom Figure 7, we see that the effect of childs on realrinc is different for each gender! For females, the income steadily drops with the number of children, whereas for males it actually increases up to a certain family size before decreasing again."
  },
  {
    "objectID": "posts/Aish-day-5/index.html#correlations",
    "href": "posts/Aish-day-5/index.html#correlations",
    "title": "day-5",
    "section": "Correlations",
    "text": "Correlations\n\nlibrary(tidyverse) # Tidy data processing and plotting\nlibrary(ggformula) # Formula based plots\nlibrary(mosaic) # Our go-to package\nlibrary(skimr) # Another Data inspection package\n\n\nAttaching package: 'skimr'\n\n\nThe following object is masked from 'package:mosaic':\n\n    n_missing\n\nlibrary(kableExtra) # Making good tables with data\n\n\nAttaching package: 'kableExtra'\n\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows\n\nlibrary(GGally) # Corr plots\n\nRegistered S3 method overwritten by 'GGally':\n  method from   \n  +.gg   ggplot2\n\nlibrary(corrplot) # More corrplots\n\ncorrplot 0.94 loaded\n\nlibrary(ggExtra) # Making Combination Plots\n\nlibrary(devtools)\n\nLoading required package: usethis\n\ndevtools::install_github(\"rpruim/Lock5withR\")\n\nUsing GitHub PAT from the git credential store.\n\n\nSkipping install of 'Lock5withR' from a github remote, the SHA1 (f2773d9f) has not changed since last install.\n  Use `force = TRUE` to force installation\n\nlibrary(Lock5withR) # Datasets\nlibrary(palmerpenguins) # A famous dataset\n\nlibrary(easystats) # Easy Statistical Analysis and Charts\n\n# Attaching packages: easystats 0.7.3\n✔ bayestestR  0.14.0   ✔ correlation 0.8.5 \n✔ datawizard  0.13.0   ✔ effectsize  0.8.9 \n✔ insight     0.20.5   ✔ modelbased  0.8.8 \n✔ performance 0.12.3   ✔ parameters  0.22.2\n✔ report      0.5.9    ✔ see         0.9.0 \n\nlibrary(correlation) # Different Types of Correlations\n# From the easystats collection of packages\n\nIn statistical terms we use correlation to denote association between two quantitative variables. We also assume that the association is linear, that one variable increases or decreases a fixed amount for a unit increase or decrease in the other.\n\nHollywoodMovies2011 -&gt; movies\nglimpse(movies)\n\nRows: 136\nColumns: 14\n$ Movie             &lt;fct&gt; \"Insidious\", \"Paranormal Activity 3\", \"Bad Teacher\",…\n$ LeadStudio        &lt;fct&gt; Sony, Independent, Independent, Warner Bros, Relativ…\n$ RottenTomatoes    &lt;int&gt; 67, 68, 44, 96, 90, 93, 75, 35, 63, 69, 69, 49, 26, …\n$ AudienceScore     &lt;int&gt; 65, 58, 38, 92, 77, 84, 91, 58, 74, 73, 72, 57, 68, …\n$ Story             &lt;fct&gt; Monster Force, Monster Force, Comedy, Rivalry, Rival…\n$ Genre             &lt;fct&gt; Horror, Horror, Comedy, Fantasy, Comedy, Romance, Dr…\n$ TheatersOpenWeek  &lt;int&gt; 2408, 3321, 3049, 4375, 2918, 944, 2534, 3615, NA, 2…\n$ BOAverageOpenWeek &lt;int&gt; 5511, 15829, 10365, 38672, 8995, 6177, 10278, 23775,…\n$ DomesticGross     &lt;dbl&gt; 54.01, 103.66, 100.29, 381.01, 169.11, 56.18, 169.22…\n$ ForeignGross      &lt;dbl&gt; 43.00, 98.24, 115.90, 947.10, 119.28, 83.00, 30.10, …\n$ WorldGross        &lt;dbl&gt; 97.009, 201.897, 216.196, 1328.111, 288.382, 139.177…\n$ Budget            &lt;dbl&gt; 1.5, 5.0, 20.0, 125.0, 32.5, 17.0, 25.0, 80.0, 0.2, …\n$ Profitability     &lt;dbl&gt; 64.672667, 40.379400, 10.809800, 10.624888, 8.873292…\n$ OpeningWeekend    &lt;dbl&gt; 13.27, 52.57, 31.60, 169.19, 26.25, 5.83, 26.04, 85.…"
  },
  {
    "objectID": "posts/Aish-day-5/index.html#scatter-plots",
    "href": "posts/Aish-day-5/index.html#scatter-plots",
    "title": "day-5",
    "section": "Scatter Plots",
    "text": "Scatter Plots\n\nmovies_quant &lt;- movies %&gt;%\n  drop_na() %&gt;%\n  select(where(is.numeric))\nmovies_quant\n\n    RottenTomatoes AudienceScore TheatersOpenWeek BOAverageOpenWeek\n1               67            65             2408              5511\n2               68            58             3321             15829\n3               44            38             3049             10365\n4               96            92             4375             38672\n5               90            77             2918              8995\n6               93            84              944              6177\n7               75            91             2534             10278\n8               35            58             3615             23775\n9               69            73             2756              6860\n10              69            72             3040              9310\n11              49            57             3018              6512\n12              26            68             4061             34012\n13              35            67             4088             23937\n14              56            52             2994              8469\n15              71            73             3826             10252\n16              82            78             3379             10492\n17              83            87             3648             15024\n18              23            31             3328              2615\n19              23            50             3395             10489\n20              93            93             2458              3517\n21              93            79             2886              3929\n22              82            80             3925             12142\n23              55            57             3043              7183\n24              85            76             2199              4761\n25              71            68             2926              6364\n26              34            61             4155             21697\n27              61            56             3155              5715\n28              92            81             2961              5002\n29              93            86             3448              8672\n30              37            54             1719              2955\n31              30            39             2787              3390\n32              60            79             3703             10704\n33              38            55             1552              2470\n34              47            63             3167              7500\n35              47            54             3339              5524\n36              38            55             3122              3860\n37              60            72             2817              5979\n38              35            50             3417             10411\n39              77            80             3955             16618\n40              26            50             3579             10490\n41              78            81             3020              6326\n42              38            56             4115             16072\n43              22            40             3295              3534\n44              19            63             3548              8601\n45              78            75             3715             17512\n46              20            43             2985              4955\n47              71            71             3549              4383\n48              72            67             2840              7450\n49               4            29             2534              5921\n50              46            79             2214              4789\n51              58            81             3440              7942\n52              72            70             2802              4655\n53              36            59             3112             10349\n54              58            57             3305              5656\n55              32            57             3154              6167\n56              84            81             3507              5461\n57               4            46             3118              3504\n58              35            44             2950              4588\n59              10            32             2816              3769\n60              76            70             1826              5427\n61              84            63             3222              6935\n62              87            88             3641             15134\n63              83            76             3952              8623\n64              14            42             3482              5763\n65              71            67             2535              4880\n66              11            41             3030              4622\n67              95            89             2993              6516\n68              38            50             2473              3014\n69              44            47             3584              9335\n70              84            82             2707              4879\n71              88            69             3917              9722\n72              24            48             3017              2875\n73              34            46             2973              4405\n74              84            61                4             93230\n75              19            50             1952              5047\n76              68            61             3367              7135\n77              97            87             3440              8500\n78              16            25             2806              2995\n79              28            55             2614              3982\n80              24            50             3002              1806\n81              43            48             2888              4616\n82              24            53             2913              4645\n83              17            37             2864              5221\n84              53            52             2703              4226\n85              59            37             2760              3089\n86              75            68             3114              2477\n87              26            49             3276              3731\n88              91            79             2405              3267\n89              27            48             3816             13935\n90              23            48             3033              6284\n91              39            43             2296              3782\n92              44            50             3750              9715\n93               4            59             3438              7273\n94              23            31             2940              6060\n95              83            93             1869              2805\n96              83            84              247              7174\n97              41            59             3606              5889\n98               7            38             2661              3055\n99              25            48             2986              3132\n100             36            52             2996              2835\n101             45            38             2290              2265\n102             92            82             3376              3537\n103             56            65              707              4960\n104             22            34             3015              3324\n105             26            36             2769              3380\n106             50            48             2273              2259\n107             46            66              265              3856\n108             66            55              106              6111\n109             62            57               22              4890\n110             36            43             3117              2218\n111             38            62             2150              1513\n    DomesticGross ForeignGross WorldGross Budget Profitability OpeningWeekend\n1           54.01        43.00     97.009    1.5    64.6726667          13.27\n2          103.66        98.24    201.897    5.0    40.3794000          52.57\n3          100.29       115.90    216.196   20.0    10.8098000          31.60\n4          381.01       947.10   1328.111  125.0    10.6248880         169.19\n5          169.11       119.28    288.382   32.5     8.8732923          26.25\n6           56.18        83.00    139.177   17.0     8.1868824           5.83\n7          169.22        30.10    199.324   25.0     7.9729600          26.04\n8          254.46       327.00    581.464   80.0     7.2683000          85.95\n9           79.25        82.60    161.849   27.0     5.9944074          18.91\n10         117.54        92.10    209.638   35.0     5.9896571          28.30\n11          70.60        77.10    147.700   25.0     5.9080000          19.70\n12         260.80       374.00    634.800  110.0     5.7709091         138.12\n13         352.39       770.81   1123.195  195.0     5.7599744          97.85\n14          99.97        94.00    193.967   36.0     5.3879722          25.36\n15         143.62       341.02    484.634   90.0     5.3848222          39.23\n16         127.00       132.71    259.713   50.0     5.1942600          35.45\n17         176.70       304.52    481.226   93.0     5.1744731          54.81\n18          17.69         7.88     25.562    5.0     5.1124000           8.70\n19         142.61       419.54    562.158  110.0     5.1105273          35.61\n20          34.90         1.62     36.511    8.0     4.5638750           8.64\n21          34.68        32.33     67.007   15.0     4.4671333          11.34\n22         165.25       497.78    663.024  150.0     4.4201600          47.66\n23          63.69        67.10    130.786   30.0     4.3595333          21.86\n24          40.49        13.70     54.194   12.5     4.3355200          10.47\n25          55.80        93.74    149.541   35.0     4.2726000          18.62\n26         241.07       802.80   1043.871  250.0     4.1754840          90.15\n27          42.59       115.30    157.887   40.0     3.9471750          18.03\n28          54.71        68.57    123.278   32.0     3.8524375          14.81\n29         197.80       336.70    534.500  145.0     3.6862069          29.55\n30          13.84        41.40     55.241   15.0     3.6827333           5.08\n31          23.20        85.40    108.600   30.0     3.6200000           9.40\n32         179.04       261.00    440.040  125.0     3.5203200          39.63\n33           8.31       149.63    157.939   45.0     3.5097556           3.83\n34          52.70        19.72     72.416   21.0     3.4483810          23.75\n35          68.22       119.14    187.355   55.0     3.4064545          18.45\n36          36.49        90.90    127.393   40.0     3.1848250          12.05\n37          58.71        58.39    117.094   38.0     3.0814211          16.84\n38          83.55       128.27    211.818   70.0     3.0259714          35.57\n39         181.03       267.48    448.512  150.0     2.9900800          65.72\n40         108.09        75.87    183.953   63.0     2.9198889          37.54\n41          84.34        58.50    142.841   50.0     2.8568200          19.10\n42         191.45       360.40    551.850  200.0     2.7592500          66.14\n43          38.54        35.54     74.080   27.0     2.7437037          11.64\n44         103.03       111.92    214.945   80.0     2.6868125          30.51\n45         176.65       191.75    368.404  140.0     2.6314571          65.06\n46          33.00        63.00     96.000   37.0     2.5945946          14.80\n47          51.16        10.90     62.053   24.0     2.5855417          15.56\n48          62.50        65.37    127.868   50.2     2.5471713          21.16\n49          37.30         3.19     40.492   16.0     2.5307500          15.00\n50          43.85         0.41     44.267   18.0     2.4592778          10.60\n51          83.61       186.20    269.811  110.0     2.4528273          27.32\n52          37.41        60.57     97.983   40.0     2.4495750          13.04\n53          80.49       102.00    182.485   75.0     2.4331333          32.21\n54          38.18        58.96     97.137   40.0     2.4284250          18.69\n55          55.10        89.40    144.500   60.0     2.4083333          19.45\n56          71.08        16.86     87.947   37.0     2.3769459          19.15\n57          28.07        54.00     82.069   35.0     2.3448286          10.93\n58          45.06        38.10     83.160   36.0     2.3100000          13.54\n59          24.80        66.80     91.600   40.0     2.2900000          10.60\n60          31.18        14.25     45.429   20.0     2.2714500           9.91\n61          75.64        59.80    135.443   60.0     2.2573833          22.40\n62         146.41       207.22    353.623  160.0     2.2101437          55.10\n63         142.09       142.30    284.386  130.0     2.1875846          34.08\n64          80.36        89.94    170.301   80.0     2.1287625          20.07\n65          40.26        23.52     63.781   30.0     2.1260333          12.37\n66          37.66        51.50     89.162   42.0     2.1229048          14.01\n67          74.21        27.90    102.109   50.0     2.0421800          19.50\n68          23.18        16.48     39.664   20.0     1.9832000           7.45\n69          98.80       129.00    227.800  120.0     1.8983333          33.50\n70          58.01        17.00     75.009   40.0     1.8752250          13.21\n71         123.26       121.90    245.154  135.0     1.8159556          38.08\n72          20.25       111.90    132.147   75.0     1.7619600           8.67\n73          35.61        16.80     52.408   30.0     1.7469333          13.10\n74          13.30        41.00     54.303   32.0     1.6969687           0.37\n75          27.87         0.97     28.833   17.0     1.6960588           9.85\n76          74.50        47.00    121.504   75.0     1.6200533          24.03\n77          66.63         5.80     72.426   45.0     1.6094667          29.24\n78          18.88        19.83     38.702   25.0     1.5480800           8.40\n79          36.67        24.30     60.965   40.0     1.5241250          10.41\n80          14.01        16.42     30.426   20.0     1.5213000           5.42\n81          37.05         3.49     40.546   28.0     1.4480714          13.33\n82          37.08        33.75     70.833   52.0     1.3621731          13.53\n83          29.14        49.17     78.308   60.0     1.3051333          14.95\n84          29.20        22.00     51.200   40.0     1.2800000          11.40\n85          24.05         7.50     31.546   25.0     1.2618400           8.53\n86          18.30        18.80     37.102   30.0     1.2367333           7.71\n87          33.04        12.70     45.735   40.0     1.1433750          12.22\n88          26.69         6.46     33.152   30.0     1.1050667           7.86\n89         116.60       103.25    219.851  200.0     1.0992550          53.17\n90          36.39        53.40     89.792   82.0     1.0950244          19.06\n91          19.49         7.63     27.121   25.0     1.0848400           8.68\n92         100.24        74.58    174.821  163.0     1.0725215          36.43\n93          68.91        15.00     83.911   79.0     1.0621646          25.00\n94          48.50        21.20     69.700   70.0     0.9957143          17.80\n95          13.66         9.40     23.057   25.0     0.9222800           5.24\n96           5.31         2.95      8.258   10.0     0.8258000           1.75\n97          57.31        49.20    106.507  135.0     0.7889407          21.24\n98          21.30        17.20     38.502   50.0     0.7700400           8.13\n99          25.12        27.84     52.961   70.0     0.7565857           9.35\n100         16.93        10.50     27.428   38.0     0.7217895           8.49\n101         10.72        18.21     28.931   45.0     0.6429111           5.19\n102         33.70        57.50     91.203  150.0     0.6080200          12.07\n103         11.54         2.67     14.211   25.0     0.5684400           3.51\n104         21.30        27.50     48.795   90.0     0.5421667          10.02\n105         21.60         3.26     24.856   49.9     0.4981162           9.36\n106         13.07         8.48     21.552   45.0     0.4789333           5.14\n107          4.46         9.73     14.190   30.0     0.4730000           1.02\n108          4.40         0.40      4.800   15.0     0.3200000           0.64\n109          0.97         5.40      6.370   21.0     0.3033333           0.11\n110         21.39        17.60     38.992  150.0     0.2599467           6.91\n111          7.17         0.24      7.410   41.0     0.1807317           3.25\n\n\n\nmovies %&gt;%\n  gf_point(DomesticGross ~ WorldGross) %&gt;%\n  gf_lm() %&gt;%\n  gf_labs(\n    title = \"Scatter Plot\",\n    subtitle = \"Movie Gross Earnings: Domestics vs World\"\n  )\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_lm()`).\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\nWarning: Using the `size` aesthetic with geom_line was deprecated in ggplot2 3.4.0.\nℹ Please use the `linewidth` aesthetic instead.\n\n\n\n\n\n\n\n\n\n\nmovies %&gt;%\n  gf_point(Profitability ~ OpeningWeekend) %&gt;%\n  gf_lm() %&gt;%\n  gf_labs(\n    title = \"Scatter Plot\",\n    subtitle = \"Movies: Does Opening Week Earnings indicate Profitability?\"\n  )\n\nWarning: Removed 5 rows containing non-finite outside the scale range\n(`stat_lm()`).\n\n\nWarning: Removed 5 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\nmovies %&gt;%\n  gf_point(RottenTomatoes ~ AudienceScore) %&gt;%\n  gf_lm() %&gt;%\n  gf_labs(\n    title = \"Scatter Plot\",\n    subtitle = \"Movie Ratings: Tomatoes vs Audience\"\n  )\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_lm()`).\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\nmovies %&gt;%\n  drop_na() %&gt;%\n  gf_point(RottenTomatoes ~ AudienceScore,\n    color = ~Genre\n  ) %&gt;%\n  gf_lm() %&gt;%\n  gf_labs(\n    title = \"Scatter Plot\",\n    subtitle = \"Movie Ratings: Trends by Genre\"\n  )\n\n\n\n\n\n\n\n\n\nDomesticGross and World Gross are related, though there are fewer movies at the high end of DomesticGross…\nAudienceScore and RottenTomatoes seem clearly related…both increase together.\nOpeningWeek and Profitability are also related in a linear way. There are just two movies which have been extremely profitable..but they do not influence the slope of the trend line too much, because of their location midway in the range of OpeningWeek. Influence is something that is a key concept in Linear Regression.\nBy and large, there are only small variations in slope across Genres."
  },
  {
    "objectID": "posts/Aish-day-5/index.html#quantizing-correlation",
    "href": "posts/Aish-day-5/index.html#quantizing-correlation",
    "title": "day-5",
    "section": "Quantizing Correlation",
    "text": "Quantizing Correlation\n\nPoints to remember\nthe correlation score (often called the correlation coefficient) is a number that tells you how strongly two things are related or connected.\n\n1 means perfect positive correlation: when one variable goes up, the other one always goes up in a straight line.\n-1 means perfect negative correlation: when one variable goes up, the other one always goes down in a straight line.\n0 means no correlation: the variables don’t seem to be related at all.\n\nexamples-\n\n\nExamples-\n\nIf you were looking at height and weight, you might find a positive correlation because, in general, taller people tend to weigh more.\nIf you looked at exercise and weight, you might see a negative correlation, meaning the more someone exercises, the lower their weight tends to be.\n\n\n\nIf you were looking at height and weight, you might find a positive correlation because, in general, taller people tend to weigh more.\nIf you looked at exercise and weight, you might see a negative correlation, meaning the more someone exercises, the lower their weight tends to be.\n\n\nGGally::ggpairs(\n  movies %&gt;% drop_na(),\n  # Select Quant variables only for now\n  columns = c(\n    \"RottenTomatoes\", \"AudienceScore\", \"DomesticGross\", \"ForeignGross\"\n  ),\n  switch = \"both\",\n  # axis labels in more traditional locations(left and bottom)\n\n  progress = FALSE,\n  # no compute progress messages needed\n\n  # Choose the diagonal graphs (always single variable! Think!)\n  diag = list(continuous = \"barDiag\"),\n  # choosing histogram,not density\n\n  # Choose lower triangle graphs, two-variable graphs\n  lower = list(continuous = wrap(\"smooth\", alpha = 0.3, se = FALSE)),\n  title = \"Movies Data Correlations Plot #1\"\n)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\nGGally::ggpairs(\n  movies %&gt;% drop_na(),\n  # Select Quant variables only for now\n  columns = c(\n    \"Budget\", \"Profitability\", \"DomesticGross\", \"ForeignGross\"\n  ),\n  switch = \"both\",\n  # axis labels in more traditional locations(left and bottom)\n\n  progress = FALSE,\n  # no compute progress messages needed\n\n  # Choose the diagonal graphs (always single variable! Think!)\n  diag = list(continuous = \"barDiag\"),\n  # choosing histogram,not density\n\n  # Choose lower triangle graphs, two-variable graphs\n  lower = list(continuous = wrap(\"smooth\", alpha = 0.3, se = FALSE)),\n  title = \"Movies Data Correlations Plot #2\"\n)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\nThe Budget variable has good correlation scores with DomesticGross and ForeignGross.\nProfitability and Budget seem to have a very slight negative correlation, but this does not appear to be significant."
  },
  {
    "objectID": "posts/Aish-day-5/index.html#doing-a-correlation-test",
    "href": "posts/Aish-day-5/index.html#doing-a-correlation-test",
    "title": "day-5",
    "section": "Doing a correlation Test",
    "text": "Doing a correlation Test\n\nmosaic::cor_test(Profitability ~ Budget, data = movies) %&gt;%\n  broom::tidy() %&gt;%\n  knitr::kable(\n    digits = 2,\n    caption = \"Movie Profitability vs Budget\"\n  )\n\n\nMovie Profitability vs Budget\n\n\n\n\n\n\n\n\n\n\n\n\nestimate\nstatistic\np.value\nparameter\nconf.low\nconf.high\nmethod\nalternative\n\n\n\n\n-0.08\n-0.96\n0.34\n132\n-0.25\n0.09\nPearson’s product-moment correlation\ntwo.sided\n\n\n\n\n\n\nmosaic::cor_test(DomesticGross ~ Budget, data = movies) %&gt;%\n  broom::tidy() %&gt;%\n  knitr::kable(\n    digits = 2,\n    caption = \"Movie Domestic Gross vs Budget\"\n  )\n\n\nMovie Domestic Gross vs Budget\n\n\n\n\n\n\n\n\n\n\n\n\nestimate\nstatistic\np.value\nparameter\nconf.low\nconf.high\nmethod\nalternative\n\n\n\n\n0.7\n11.06\n0\n131\n0.6\n0.77\nPearson’s product-moment correlation\ntwo.sided\n\n\n\n\n\n\nmosaic::cor_test(ForeignGross ~ Budget, data = movies) %&gt;%\n  broom::tidy() %&gt;%\n  knitr::kable(\n    digits = 2,\n    caption = \"Movie Foreign Gross vs Budget\"\n  )\n\n\nMovie Foreign Gross vs Budget\n\n\n\n\n\n\n\n\n\n\n\n\nestimate\nstatistic\np.value\nparameter\nconf.low\nconf.high\nmethod\nalternative\n\n\n\n\n0.69\n10.22\n0\n118\n0.58\n0.77\nPearson’s product-moment correlation\ntwo.sided\n\n\n\n\n\n\nglimpse(mtcars)\n\nRows: 32\nColumns: 11\n$ mpg  &lt;dbl&gt; 21.0, 21.0, 22.8, 21.4, 18.7, 18.1, 14.3, 24.4, 22.8, 19.2, 17.8,…\n$ cyl  &lt;dbl&gt; 6, 6, 4, 6, 8, 6, 8, 4, 4, 6, 6, 8, 8, 8, 8, 8, 8, 4, 4, 4, 4, 8,…\n$ disp &lt;dbl&gt; 160.0, 160.0, 108.0, 258.0, 360.0, 225.0, 360.0, 146.7, 140.8, 16…\n$ hp   &lt;dbl&gt; 110, 110, 93, 110, 175, 105, 245, 62, 95, 123, 123, 180, 180, 180…\n$ drat &lt;dbl&gt; 3.90, 3.90, 3.85, 3.08, 3.15, 2.76, 3.21, 3.69, 3.92, 3.92, 3.92,…\n$ wt   &lt;dbl&gt; 2.620, 2.875, 2.320, 3.215, 3.440, 3.460, 3.570, 3.190, 3.150, 3.…\n$ qsec &lt;dbl&gt; 16.46, 17.02, 18.61, 19.44, 17.02, 20.22, 15.84, 20.00, 22.90, 18…\n$ vs   &lt;dbl&gt; 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,…\n$ am   &lt;dbl&gt; 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,…\n$ gear &lt;dbl&gt; 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 4, 4, 3, 3,…\n$ carb &lt;dbl&gt; 4, 4, 1, 1, 2, 1, 4, 2, 2, 4, 4, 3, 3, 3, 4, 4, 4, 1, 2, 1, 1, 2,…\n\n\n\n## Target variable: mpg\n## Calculate all correlations\ncor &lt;- correlation::correlation(mtcars)\ncor\n\n# Correlation Matrix (pearson-method)\n\nParameter1 | Parameter2 |     r |         95% CI | t(30) |         p\n--------------------------------------------------------------------\nmpg        |        cyl | -0.85 | [-0.93, -0.72] | -8.92 | &lt; .001***\nmpg        |       disp | -0.85 | [-0.92, -0.71] | -8.75 | &lt; .001***\nmpg        |         hp | -0.78 | [-0.89, -0.59] | -6.74 | &lt; .001***\nmpg        |       drat |  0.68 | [ 0.44,  0.83] |  5.10 | &lt; .001***\nmpg        |         wt | -0.87 | [-0.93, -0.74] | -9.56 | &lt; .001***\nmpg        |       qsec |  0.42 | [ 0.08,  0.67] |  2.53 | 0.222    \nmpg        |         vs |  0.66 | [ 0.41,  0.82] |  4.86 | 0.001**  \nmpg        |         am |  0.60 | [ 0.32,  0.78] |  4.11 | 0.008**  \nmpg        |       gear |  0.48 | [ 0.16,  0.71] |  3.00 | 0.097    \nmpg        |       carb | -0.55 | [-0.75, -0.25] | -3.62 | 0.024*   \ncyl        |       disp |  0.90 | [ 0.81,  0.95] | 11.45 | &lt; .001***\ncyl        |         hp |  0.83 | [ 0.68,  0.92] |  8.23 | &lt; .001***\ncyl        |       drat | -0.70 | [-0.84, -0.46] | -5.37 | &lt; .001***\ncyl        |         wt |  0.78 | [ 0.60,  0.89] |  6.88 | &lt; .001***\ncyl        |       qsec | -0.59 | [-0.78, -0.31] | -4.02 | 0.010*   \ncyl        |         vs | -0.81 | [-0.90, -0.64] | -7.59 | &lt; .001***\ncyl        |         am | -0.52 | [-0.74, -0.21] | -3.36 | 0.043*   \ncyl        |       gear | -0.49 | [-0.72, -0.17] | -3.10 | 0.079    \ncyl        |       carb |  0.53 | [ 0.22,  0.74] |  3.40 | 0.041*   \ndisp       |         hp |  0.79 | [ 0.61,  0.89] |  7.08 | &lt; .001***\ndisp       |       drat | -0.71 | [-0.85, -0.48] | -5.53 | &lt; .001***\ndisp       |         wt |  0.89 | [ 0.78,  0.94] | 10.58 | &lt; .001***\ndisp       |       qsec | -0.43 | [-0.68, -0.10] | -2.64 | 0.197    \ndisp       |         vs | -0.71 | [-0.85, -0.48] | -5.53 | &lt; .001***\ndisp       |         am | -0.59 | [-0.78, -0.31] | -4.02 | 0.010*   \ndisp       |       gear | -0.56 | [-0.76, -0.26] | -3.66 | 0.023*   \ndisp       |       carb |  0.39 | [ 0.05,  0.65] |  2.35 | 0.303    \nhp         |       drat | -0.45 | [-0.69, -0.12] | -2.75 | 0.170    \nhp         |         wt |  0.66 | [ 0.40,  0.82] |  4.80 | 0.001**  \nhp         |       qsec | -0.71 | [-0.85, -0.48] | -5.49 | &lt; .001***\nhp         |         vs | -0.72 | [-0.86, -0.50] | -5.73 | &lt; .001***\nhp         |         am | -0.24 | [-0.55,  0.12] | -1.37 | &gt; .999   \nhp         |       gear | -0.13 | [-0.45,  0.23] | -0.69 | &gt; .999   \nhp         |       carb |  0.75 | [ 0.54,  0.87] |  6.21 | &lt; .001***\ndrat       |         wt | -0.71 | [-0.85, -0.48] | -5.56 | &lt; .001***\ndrat       |       qsec |  0.09 | [-0.27,  0.43] |  0.50 | &gt; .999   \ndrat       |         vs |  0.44 | [ 0.11,  0.68] |  2.69 | 0.187    \ndrat       |         am |  0.71 | [ 0.48,  0.85] |  5.57 | &lt; .001***\ndrat       |       gear |  0.70 | [ 0.46,  0.84] |  5.36 | &lt; .001***\ndrat       |       carb | -0.09 | [-0.43,  0.27] | -0.50 | &gt; .999   \nwt         |       qsec | -0.17 | [-0.49,  0.19] | -0.97 | &gt; .999   \nwt         |         vs | -0.55 | [-0.76, -0.26] | -3.65 | 0.023*   \nwt         |         am | -0.69 | [-0.84, -0.45] | -5.26 | &lt; .001***\nwt         |       gear | -0.58 | [-0.77, -0.29] | -3.93 | 0.012*   \nwt         |       carb |  0.43 | [ 0.09,  0.68] |  2.59 | 0.205    \nqsec       |         vs |  0.74 | [ 0.53,  0.87] |  6.11 | &lt; .001***\nqsec       |         am | -0.23 | [-0.54,  0.13] | -1.29 | &gt; .999   \nqsec       |       gear | -0.21 | [-0.52,  0.15] | -1.19 | &gt; .999   \nqsec       |       carb | -0.66 | [-0.82, -0.40] | -4.76 | 0.001**  \nvs         |         am |  0.17 | [-0.19,  0.49] |  0.94 | &gt; .999   \nvs         |       gear |  0.21 | [-0.15,  0.52] |  1.15 | &gt; .999   \nvs         |       carb | -0.57 | [-0.77, -0.28] | -3.80 | 0.017*   \nam         |       gear |  0.79 | [ 0.62,  0.89] |  7.16 | &lt; .001***\nam         |       carb |  0.06 | [-0.30,  0.40] |  0.32 | &gt; .999   \ngear       |       carb |  0.27 | [-0.08,  0.57] |  1.56 | &gt; .999   \n\np-value adjustment method: Holm (1979)\nObservations: 32\n\n\n\nIn a correlation test, there is something called an uncertainty band - it gives you the range [x +- y]. This uncertainity should not be such that the range falls both on negative as well as positive. The correlation score should either be +ve or -ve. It should never be both.\n\n\ncor %&gt;%\n  # Filter for target variable `mpg` and plot\n  filter(Parameter1 == \"mpg\") %&gt;%\n  gf_point(r ~ reorder(Parameter2, r), size = 4) %&gt;%\n  gf_errorbar(CI_low + CI_high ~ reorder(Parameter2, r),\n    width = 0.5\n  ) %&gt;%\n  gf_hline(yintercept = 0, color = \"grey\", linewidth = 2) %&gt;%\n  gf_labs(\n    title = \"Correlation Errorbar Chart\",\n    subtitle = \"Target variable: mpg\",\n    x = \"Predictor Variable\",\n    y = \"Correlation Score with mpg\"\n  )\n\n\n\n\n\n\n\n\n\nSeveral variables are negatively correlated and some are positively correlated with ’mpg`. (The grey line shows “zero correlation”)\nSince none of the error bars straddle zero, the correlations are mostly significant.\n\n\nlibrary(ggExtra)\n\npenguins %&gt;%\n  drop_na() %&gt;%\n  gf_point(body_mass_g ~ flipper_length_mm, colour = ~species) %&gt;%\n  gf_smooth(method = \"lm\") %&gt;%\n  gf_refine(scale_colour_brewer(palette = \"Accent\")) %&gt;%\n  gf_labs(title = \"Scatter Plot with Marginal Densities\") %&gt;%\n  ggExtra::ggMarginal(\n    type = \"density\", groupColour = TRUE,\n    groupFill = TRUE, margins = \"both\"\n  )"
  },
  {
    "objectID": "posts/Aish-day-2/index.html",
    "href": "posts/Aish-day-2/index.html",
    "title": "day-2",
    "section": "",
    "text": "I am working with data summaries. First, mpg, then something else.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(ggformula)\nlibrary(kableExtra)\n\n\nAttaching package: 'kableExtra'\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows"
  },
  {
    "objectID": "posts/Aish-day-2/index.html#introduction",
    "href": "posts/Aish-day-2/index.html#introduction",
    "title": "day-2",
    "section": "",
    "text": "I am working with data summaries. First, mpg, then something else.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(ggformula)\nlibrary(kableExtra)\n\n\nAttaching package: 'kableExtra'\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows"
  },
  {
    "objectID": "posts/Aish-day-2/index.html#look-at-this-mpg-dataset",
    "href": "posts/Aish-day-2/index.html#look-at-this-mpg-dataset",
    "title": "day-2",
    "section": "Look at this mpg dataset",
    "text": "Look at this mpg dataset\n\nglimpse(mpg)\n\nRows: 234\nColumns: 11\n$ manufacturer &lt;chr&gt; \"audi\", \"audi\", \"audi\", \"audi\", \"audi\", \"audi\", \"audi\", \"…\n$ model        &lt;chr&gt; \"a4\", \"a4\", \"a4\", \"a4\", \"a4\", \"a4\", \"a4\", \"a4 quattro\", \"…\n$ displ        &lt;dbl&gt; 1.8, 1.8, 2.0, 2.0, 2.8, 2.8, 3.1, 1.8, 1.8, 2.0, 2.0, 2.…\n$ year         &lt;int&gt; 1999, 1999, 2008, 2008, 1999, 1999, 2008, 1999, 1999, 200…\n$ cyl          &lt;int&gt; 4, 4, 4, 4, 6, 6, 6, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 8, 8, …\n$ trans        &lt;chr&gt; \"auto(l5)\", \"manual(m5)\", \"manual(m6)\", \"auto(av)\", \"auto…\n$ drv          &lt;chr&gt; \"f\", \"f\", \"f\", \"f\", \"f\", \"f\", \"f\", \"4\", \"4\", \"4\", \"4\", \"4…\n$ cty          &lt;int&gt; 18, 21, 20, 21, 16, 18, 18, 18, 16, 20, 19, 15, 17, 17, 1…\n$ hwy          &lt;int&gt; 29, 29, 31, 30, 26, 26, 27, 26, 25, 28, 27, 25, 25, 25, 2…\n$ fl           &lt;chr&gt; \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p…\n$ class        &lt;chr&gt; \"compact\", \"compact\", \"compact\", \"compact\", \"compact\", \"c…\n\n\n\nPurpose of glimpse():\n\nProvides a compact overview of a dataset, showing variable names, types, and a preview of the values in each column.\ncomes under ‘tidyverse package’.\n\n\nmpg\n\n# A tibble: 234 × 11\n   manufacturer model      displ  year   cyl trans drv     cty   hwy fl    class\n   &lt;chr&gt;        &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt;\n 1 audi         a4           1.8  1999     4 auto… f        18    29 p     comp…\n 2 audi         a4           1.8  1999     4 manu… f        21    29 p     comp…\n 3 audi         a4           2    2008     4 manu… f        20    31 p     comp…\n 4 audi         a4           2    2008     4 auto… f        21    30 p     comp…\n 5 audi         a4           2.8  1999     6 auto… f        16    26 p     comp…\n 6 audi         a4           2.8  1999     6 manu… f        18    26 p     comp…\n 7 audi         a4           3.1  2008     6 auto… f        18    27 p     comp…\n 8 audi         a4 quattro   1.8  1999     4 manu… 4        18    26 p     comp…\n 9 audi         a4 quattro   1.8  1999     4 auto… 4        16    25 p     comp…\n10 audi         a4 quattro   2    2008     4 manu… 4        20    28 p     comp…\n# ℹ 224 more rows\n\n  head(10)\n\n[1] 10\n\n\n\ninspect(mpg)\n\n\ncategorical variables:  \n          name     class levels   n missing\n1 manufacturer character     15 234       0\n2        model character     38 234       0\n3        trans character     10 234       0\n4          drv character      3 234       0\n5           fl character      5 234       0\n6        class character      7 234       0\n                                   distribution\n1 dodge (15.8%), toyota (14.5%) ...            \n2 caravan 2wd (4.7%) ...                       \n3 auto(l4) (35.5%), manual(m5) (24.8%) ...     \n4 f (45.3%), 4 (44%), r (10.7%)                \n5 r (71.8%), p (22.2%), e (3.4%) ...           \n6 suv (26.5%), compact (20.1%) ...             \n\nquantitative variables:  \n   name   class    min     Q1 median     Q3  max        mean       sd   n\n1 displ numeric    1.6    2.4    3.3    4.6    7    3.471795 1.291959 234\n2  year integer 1999.0 1999.0 2003.5 2008.0 2008 2003.500000 4.509646 234\n3   cyl integer    4.0    4.0    6.0    8.0    8    5.888889 1.611534 234\n4   cty integer    9.0   14.0   17.0   19.0   35   16.858974 4.255946 234\n5   hwy integer   12.0   18.0   24.0   27.0   44   23.440171 5.954643 234\n  missing\n1       0\n2       0\n3       0\n4       0\n5       0\n\n\n\n\nPurpose of inspect():\n\nProvides a detailed comparison of the structure and contents of data frames. You use it when you want a deeper inspection of your dataset.\n\n\nskimr::skim(mpg)\n\n\nData summary\n\n\nName\nmpg\n\n\nNumber of rows\n234\n\n\nNumber of columns\n11\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n6\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nmanufacturer\n0\n1\n4\n10\n0\n15\n0\n\n\nmodel\n0\n1\n2\n22\n0\n38\n0\n\n\ntrans\n0\n1\n8\n10\n0\n10\n0\n\n\ndrv\n0\n1\n1\n1\n0\n3\n0\n\n\nfl\n0\n1\n1\n1\n0\n5\n0\n\n\nclass\n0\n1\n3\n10\n0\n7\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\ndispl\n0\n1\n3.47\n1.29\n1.6\n2.4\n3.3\n4.6\n7\n▇▆▆▃▁\n\n\nyear\n0\n1\n2003.50\n4.51\n1999.0\n1999.0\n2003.5\n2008.0\n2008\n▇▁▁▁▇\n\n\ncyl\n0\n1\n5.89\n1.61\n4.0\n4.0\n6.0\n8.0\n8\n▇▁▇▁▇\n\n\ncty\n0\n1\n16.86\n4.26\n9.0\n14.0\n17.0\n19.0\n35\n▆▇▃▁▁\n\n\nhwy\n0\n1\n23.44\n5.95\n12.0\n18.0\n24.0\n27.0\n44\n▅▅▇▁▁\n\n\n\n\n\n\n\nPurpose of skim():\n\nComes under ‘skimr’.\nProvides an in-depth summary of your data, including counts, mean, median, min/max, unique values, and missing values for each variable. You use it when you need detailed description for each column in your dataset, both for numeric and catagorical values.\n\n\nmpg_modified &lt;- mpg %&gt;%\n  dplyr::mutate(\n    cyl = as_factor(cyl),\n    fl = as_factor(fl),\n    drv = as_factor(drv),\n    class = as_factor(class),\n    trans = as_factor(trans)\n  )\nglimpse(mpg_modified)\n\nRows: 234\nColumns: 11\n$ manufacturer &lt;chr&gt; \"audi\", \"audi\", \"audi\", \"audi\", \"audi\", \"audi\", \"audi\", \"…\n$ model        &lt;chr&gt; \"a4\", \"a4\", \"a4\", \"a4\", \"a4\", \"a4\", \"a4\", \"a4 quattro\", \"…\n$ displ        &lt;dbl&gt; 1.8, 1.8, 2.0, 2.0, 2.8, 2.8, 3.1, 1.8, 1.8, 2.0, 2.0, 2.…\n$ year         &lt;int&gt; 1999, 1999, 2008, 2008, 1999, 1999, 2008, 1999, 1999, 200…\n$ cyl          &lt;fct&gt; 4, 4, 4, 4, 6, 6, 6, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 8, 8, …\n$ trans        &lt;fct&gt; auto(l5), manual(m5), manual(m6), auto(av), auto(l5), man…\n$ drv          &lt;fct&gt; f, f, f, f, f, f, f, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, r, …\n$ cty          &lt;int&gt; 18, 21, 20, 21, 16, 18, 18, 18, 16, 20, 19, 15, 17, 17, 1…\n$ hwy          &lt;int&gt; 29, 29, 31, 30, 26, 26, 27, 26, 25, 28, 27, 25, 25, 25, 2…\n$ fl           &lt;fct&gt; p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, r, …\n$ class        &lt;fct&gt; compact, compact, compact, compact, compact, compact, com…\n\n\n\nFactors?? what are those?\nA factor in R is a data type used to represent categorical variables. It stores both the values of the variable (called levels) and the actual data. Factors are particularly useful for handling nominal (unordered categories) and ordinal (ordered categories) data.\n\nNominal variables: Categories that do not have a specific order (e.g., “Male”, “Female”, “Yes”, “No”).\n\n\n\nOrdinal variables: Categories that have a meaningful order (e.g., “Low”, “Medium”, “High”).\n\nWhen you convert a variable into a factor, R internally stores it as an integer where each integer corresponds to a category (or level), but displays the original categories as labels.\nThe need to convert data into factors arises when you want to treat variables as categorical, ensure correct ordering for ordinal data, save memory, and properly represent your data in models or plots.\n\nmpg_modified %&gt;%\n  group_by(cyl) %&gt;%\n  summarize(average_hwy = mean(hwy), count = n())\n\n# A tibble: 4 × 3\n  cyl   average_hwy count\n  &lt;fct&gt;       &lt;dbl&gt; &lt;int&gt;\n1 4            28.8    81\n2 5            28.8     4\n3 6            22.8    79\n4 8            17.6    70\n\n\n\nmpg_modified %&gt;%\n  group_by(cyl, fl) %&gt;%\n  summarize(average_hwy = mean(hwy), count = n())\n\n`summarise()` has grouped output by 'cyl'. You can override using the `.groups`\nargument.\n\n\n# A tibble: 13 × 4\n# Groups:   cyl [4]\n   cyl   fl    average_hwy count\n   &lt;fct&gt; &lt;fct&gt;       &lt;dbl&gt; &lt;int&gt;\n 1 4     p            27.8    22\n 2 4     r            28.3    55\n 3 4     d            43       3\n 4 4     c            36       1\n 5 5     r            28.8     4\n 6 6     p            25.3    17\n 7 6     r            22.2    60\n 8 6     e            17       1\n 9 6     d            22       1\n10 8     p            20.8    13\n11 8     r            17.5    49\n12 8     e            12.7     7\n13 8     d            17       1"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My-Blog-for-Peasants",
    "section": "",
    "text": "day-2\n\n\n\n\n\n\n\n\n\n\n\nAishwarya\n\n\n\n\n\n\n\n\n\n\n\n\nDay-4\n\n\n\n\n\n\n\n\n\n\n\nAish\n\n\n\n\n\n\n\n\n\n\n\n\nday-5\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nday-6\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDay-7\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDay-3\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDataset-3: Hearing loss in children\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDataset-1: Do Women live longer?\n\n\n\n\n\n\n\n\n\n\n\nAish\n\n\n\n\n\n\n\n\n\n\n\n\nDataset-2: Movie Profits\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMy name is Aish K\n\n\n\n\n\n\n\n\n\n\n\nAishwarya\n\n\n\n\n\n\n\n\n\n\n\n\nPost With Code\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nSep 26, 2024\n\n\nHarlow Malloc\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nSep 23, 2024\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Aish-day-4/index.html",
    "href": "posts/Aish-day-4/index.html",
    "title": "Day-4",
    "section": "",
    "text": "We have downloaded a new library today - “crosstable”. It is used for fast stats for multiple variables in table form.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(ggformula)\nlibrary(skimr)\n\n\nAttaching package: 'skimr'\n\nThe following object is masked from 'package:mosaic':\n\n    n_missing\n\nlibrary(crosstable)\n\n\nAttaching package: 'crosstable'\n\nThe following object is masked from 'package:purrr':\n\n    compact\n\n\n\n\n\n\nglimpse(diamonds)\n\nRows: 53,940\nColumns: 10\n$ carat   &lt;dbl&gt; 0.23, 0.21, 0.23, 0.29, 0.31, 0.24, 0.24, 0.26, 0.22, 0.23, 0.…\n$ cut     &lt;ord&gt; Ideal, Premium, Good, Premium, Good, Very Good, Very Good, Ver…\n$ color   &lt;ord&gt; E, E, E, I, J, J, I, H, E, H, J, J, F, J, E, E, I, J, J, J, I,…\n$ clarity &lt;ord&gt; SI2, SI1, VS1, VS2, SI2, VVS2, VVS1, SI1, VS2, VS1, SI1, VS1, …\n$ depth   &lt;dbl&gt; 61.5, 59.8, 56.9, 62.4, 63.3, 62.8, 62.3, 61.9, 65.1, 59.4, 64…\n$ table   &lt;dbl&gt; 55, 61, 65, 58, 58, 57, 57, 55, 61, 61, 55, 56, 61, 54, 62, 58…\n$ price   &lt;int&gt; 326, 326, 327, 334, 335, 336, 336, 337, 337, 338, 339, 340, 34…\n$ x       &lt;dbl&gt; 3.95, 3.89, 4.05, 4.20, 4.34, 3.94, 3.95, 4.07, 3.87, 4.00, 4.…\n$ y       &lt;dbl&gt; 3.98, 3.84, 4.07, 4.23, 4.35, 3.96, 3.98, 4.11, 3.78, 4.05, 4.…\n$ z       &lt;dbl&gt; 2.43, 2.31, 2.31, 2.63, 2.75, 2.48, 2.47, 2.53, 2.49, 2.39, 2.…\n\n\n\nskim(diamonds)\n\n\nData summary\n\n\nName\ndiamonds\n\n\nNumber of rows\n53940\n\n\nNumber of columns\n10\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n3\n\n\nnumeric\n7\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\ncut\n0\n1\nTRUE\n5\nIde: 21551, Pre: 13791, Ver: 12082, Goo: 4906\n\n\ncolor\n0\n1\nTRUE\n7\nG: 11292, E: 9797, F: 9542, H: 8304\n\n\nclarity\n0\n1\nTRUE\n8\nSI1: 13065, VS2: 12258, SI2: 9194, VS1: 8171\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\ncarat\n0\n1\n0.80\n0.47\n0.2\n0.40\n0.70\n1.04\n5.01\n▇▂▁▁▁\n\n\ndepth\n0\n1\n61.75\n1.43\n43.0\n61.00\n61.80\n62.50\n79.00\n▁▁▇▁▁\n\n\ntable\n0\n1\n57.46\n2.23\n43.0\n56.00\n57.00\n59.00\n95.00\n▁▇▁▁▁\n\n\nprice\n0\n1\n3932.80\n3989.44\n326.0\n950.00\n2401.00\n5324.25\n18823.00\n▇▂▁▁▁\n\n\nx\n0\n1\n5.73\n1.12\n0.0\n4.71\n5.70\n6.54\n10.74\n▁▁▇▃▁\n\n\ny\n0\n1\n5.73\n1.14\n0.0\n4.72\n5.71\n6.54\n58.90\n▇▁▁▁▁\n\n\nz\n0\n1\n3.54\n0.71\n0.0\n2.91\n3.53\n4.04\n31.80\n▇▁▁▁▁\n\n\n\n\n\n\ninspect(diamonds)\n\n\ncategorical variables:  \n     name   class levels     n missing\n1     cut ordered      5 53940       0\n2   color ordered      7 53940       0\n3 clarity ordered      8 53940       0\n                                   distribution\n1 Ideal (40%), Premium (25.6%) ...             \n2 G (20.9%), E (18.2%), F (17.7%) ...          \n3 SI1 (24.2%), VS2 (22.7%), SI2 (17%) ...      \n\nquantitative variables:  \n   name   class   min     Q1  median      Q3      max         mean           sd\n1 carat numeric   0.2   0.40    0.70    1.04     5.01    0.7979397    0.4740112\n2 depth numeric  43.0  61.00   61.80   62.50    79.00   61.7494049    1.4326213\n3 table numeric  43.0  56.00   57.00   59.00    95.00   57.4571839    2.2344906\n4 price integer 326.0 950.00 2401.00 5324.25 18823.00 3932.7997219 3989.4397381\n5     x numeric   0.0   4.71    5.70    6.54    10.74    5.7311572    1.1217607\n6     y numeric   0.0   4.72    5.71    6.54    58.90    5.7345260    1.1421347\n7     z numeric   0.0   2.91    3.53    4.04    31.80    3.5387338    0.7056988\n      n missing\n1 53940       0\n2 53940       0\n3 53940       0\n4 53940       0\n5 53940       0\n6 53940       0\n7 53940       0\n\n\n\ngf_histogram(~price, data = diamonds) %&gt;%\n  gf_labs(\n    title = \"Plot 1A: Diamond Prices\",\n    caption = \"ggformula\"\n  )\n\n\n\n\n\n\n\n\n\ndiamonds %&gt;% \n  gf_histogram(~price, bins = 100) %&gt;% \n  gf_labs(\n    title = \"Plot 1B: Diamond Prices\",\n    caption = \"ggformula\"\n\n  )\n\n\n\n\n\n\n\n\n\n\n\nThere are a great many diamonds at relatively low prices, but there are a good few diamonds at very high prices too.\nUsing a high number of bins does not materially change the view of the histogram.\n\n\ndiamonds %&gt;% \n  gf_histogram(~carat) %&gt;% \n  gf_labs(\n     title = \"Plot 2A: Carats of Diamonds\",\n    caption = \"ggformula\"\n  )\n\n\n\n\n\n\n\n\n\ndiamonds %&gt;% \n  gf_histogram(~carat, bins = 100) %&gt;% \n  gf_labs(\n     title = \"Plot 2B: Carats of Diamonds\",\n    caption = \"ggformula\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nthere is a marked “discreteness” to the distribution. Some values of carat are far more common than others. For example, 1, 1.5, and 2 carat diamonds are large in number.\n\n\ndiamonds %&gt;% \n  gf_histogram(~price, fill = ~cut) %&gt;% \n  gf_labs(\n     title = \"Plot 3A: Diamond Prices\", caption = \"ggformula\")\n\n\n\n\n\n\n\n\n\ndiamonds %&gt;%\n  gf_histogram(~price, fill = ~cut, color = \"black\", alpha = 0.3) %&gt;%\n  gf_labs(\n    title = \"Plot 3B: Prices by Cut\",\n    caption = \"ggformula\"\n  )\n\n\n\n\n\n\n\n\n\ndiamonds %&gt;%\n  gf_histogram(~price, fill = ~cut, color = \"black\", alpha = 0.3) %&gt;%\n  gf_facet_wrap(~cut) %&gt;%\n  gf_labs(\n    title = \"Plot 3C: Prices by Filled and Facetted by Cut\",\n    caption = \"ggformula\"\n  ) %&gt;%\n  gf_theme(theme(\n    axis.text.x = element_text(\n      angle = 45,\n      hjust = 1\n    )\n  ))\n\n\n\n\n\n\n\n\n\ndiamonds %&gt;%\n  gf_histogram(~price, fill = ~cut, color = \"black\", alpha = 0.3) %&gt;%\n  gf_facet_wrap(~cut, scales = \"free_y\", nrow = 2) %&gt;%\n  gf_labs(\n    title = \"Plot 3D: Prices Filled and Facetted by Cut\",\n    subtitle = \"Free y-scale\",\n    caption = \"ggformula\"\n  ) %&gt;%\n  gf_theme(theme(\n    axis.text.x =\n      element_text(\n        angle = 45,\n        hjust = 1\n      )\n  ))\n\n\n\n\n\n\n\n\n\ninstall.packages(\"shiny\")\nlibrary(shiny)\nrunExample(\"01_hello\") # an interactive histogram\n\n\n\n\n\n\nrace_df &lt;- read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-10-26/race.csv\")\n\nRows: 1207 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (5): event, race, city, country, participation\ndbl  (6): race_year_id, distance, elevation_gain, elevation_loss, aid_statio...\ndate (1): date\ntime (1): start_time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nrank_df &lt;- read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-10-26/ultra_rankings.csv\")\n\nRows: 137803 Columns: 8\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): runner, time, gender, nationality\ndbl (4): race_year_id, rank, age, time_in_seconds\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nglimpse(race_df)\n\nRows: 1,207\nColumns: 13\n$ race_year_id   &lt;dbl&gt; 68140, 72496, 69855, 67856, 70469, 66887, 67851, 68241,…\n$ event          &lt;chr&gt; \"Peak District Ultras\", \"UTMB®\", \"Grand Raid des Pyréné…\n$ race           &lt;chr&gt; \"Millstone 100\", \"UTMB®\", \"Ultra Tour 160\", \"PERSENK UL…\n$ city           &lt;chr&gt; \"Castleton\", \"Chamonix\", \"vielle-Aure\", \"Asenovgrad\", \"…\n$ country        &lt;chr&gt; \"United Kingdom\", \"France\", \"France\", \"Bulgaria\", \"Turk…\n$ date           &lt;date&gt; 2021-09-03, 2021-08-27, 2021-08-20, 2021-08-20, 2021-0…\n$ start_time     &lt;time&gt; 19:00:00, 17:00:00, 05:00:00, 18:00:00, 18:00:00, 17:0…\n$ participation  &lt;chr&gt; \"solo\", \"Solo\", \"solo\", \"solo\", \"solo\", \"solo\", \"solo\",…\n$ distance       &lt;dbl&gt; 166.9, 170.7, 167.0, 164.0, 159.9, 159.9, 163.8, 163.9,…\n$ elevation_gain &lt;dbl&gt; 4520, 9930, 9980, 7490, 100, 9850, 5460, 4630, 6410, 31…\n$ elevation_loss &lt;dbl&gt; -4520, -9930, -9980, -7500, -100, -9850, -5460, -4660, …\n$ aid_stations   &lt;dbl&gt; 10, 11, 13, 13, 12, 15, 5, 8, 13, 23, 13, 5, 12, 15, 0,…\n$ participants   &lt;dbl&gt; 150, 2300, 600, 150, 0, 300, 0, 200, 120, 100, 300, 50,…\n\n\n\nglimpse(rank_df)\n\nRows: 137,803\nColumns: 8\n$ race_year_id    &lt;dbl&gt; 68140, 68140, 68140, 68140, 68140, 68140, 68140, 68140…\n$ rank            &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, NA, NA, NA,…\n$ runner          &lt;chr&gt; \"VERHEUL Jasper\", \"MOULDING JON\", \"RICHARDSON Phill\", …\n$ time            &lt;chr&gt; \"26H 35M 25S\", \"27H 0M 29S\", \"28H 49M 7S\", \"30H 53M 37…\n$ age             &lt;dbl&gt; 30, 43, 38, 55, 48, 31, 55, 40, 47, 29, 48, 47, 52, 49…\n$ gender          &lt;chr&gt; \"M\", \"M\", \"M\", \"W\", \"W\", \"M\", \"W\", \"W\", \"M\", \"M\", \"M\",…\n$ nationality     &lt;chr&gt; \"GBR\", \"GBR\", \"GBR\", \"GBR\", \"GBR\", \"GBR\", \"GBR\", \"GBR\"…\n$ time_in_seconds &lt;dbl&gt; 95725, 97229, 103747, 111217, 117981, 118000, 120601, …\n\n\n\nrace_df %&gt;%\n  favstats(~distance, data = .)\n\n min    Q1 median     Q3   max     mean       sd    n missing\n   0 160.1  161.5 165.15 179.1 152.6187 39.87864 1207       0\n\n\n\n##\nrace_df %&gt;%\n  favstats(~participants, data = .)\n\n min Q1 median  Q3  max     mean       sd    n missing\n   0  0     21 150 2900 120.4872 281.8337 1207       0\n\n\n\n##\nrank_df %&gt;%\n  drop_na() %&gt;%\n  favstats(time_in_seconds ~ gender, data = .)\n\n  gender  min      Q1 median       Q3    max     mean       sd      n missing\n1      M 3600 96536.5 115845 149761.5 288000 123271.1 37615.42 101643       0\n2      W 9191 96695.0 107062 131464.0 296806 117296.5 34604.26  18341       0\n\n\n\n## library(crosstable)\ncrosstable(time_in_seconds + age ~ gender, data = rank_df) %&gt;%\n  crosstable::as_flextable()\n\nlabelvariablegenderMWNAtime_in_secondsMin / Max3600.0 / 2.9e+059191.0 / 3.0e+058131.0 / 2.2e+05Med [IQR]1.2e+05 [9.7e+04;1.5e+05]1.1e+05 [9.7e+04;1.3e+05]1.2e+05 [9.9e+04;1.5e+05]Mean (std)1.2e+05 (3.8e+04)1.2e+05 (3.5e+04)1.2e+05 (4.4e+04)N (NA)101643 (15073)18341 (2716)28 (2)ageMin / Max0 / 133.00 / 81.029.0 / 59.0Med [IQR]47.0 [40.0;53.0]45.0 [39.0;52.0]40.5 [36.0;50.5]Mean (std)46.4 (10.2)45.3 (9.7)41.7 (9.0)N (NA)116716 (0)21057 (0)30 (0)\n\n\n\n\n\nrace_df %&gt;%\n  count(country) %&gt;%\n  arrange(desc(n))\n\n# A tibble: 61 × 2\n   country            n\n   &lt;chr&gt;          &lt;int&gt;\n 1 United States    438\n 2 United Kingdom   110\n 3 France            56\n 4 Australia         46\n 5 Sweden            46\n 6 China             45\n 7 Canada            32\n 8 Spain             27\n 9 Japan             24\n10 Poland            23\n# ℹ 51 more rows\n\n\n\nrank_df %&gt;%\n  count(nationality) %&gt;%\n  arrange(desc(n))\n\n# A tibble: 133 × 2\n   nationality     n\n   &lt;chr&gt;       &lt;int&gt;\n 1 USA         47259\n 2 FRA         28905\n 3 GBR         11076\n 4 JPN          6729\n 5 ESP          5478\n 6 CHN          4744\n 7 CAN          2822\n 8 ITA          2794\n 9 SWE          2293\n10 AUS          1683\n# ℹ 123 more rows\n\n\nInsights:\n\nthe first piece of code tells the no. of races hosted by the respective countries, whereas the secodn piece of code tells no, of participants from each county.\nThe top three locations for races were the USA, UK, and France. These are also the countries that send the maximum number of participants, naturally!\n\n\n\n\n\nrank_df %&gt;%\n  filter(rank %in% c(1, 2, 3)) %&gt;%\n  count(nationality) %&gt;%\n  arrange(desc(n))\n\n# A tibble: 69 × 2\n   nationality     n\n   &lt;chr&gt;       &lt;int&gt;\n 1 USA          1240\n 2 GBR           347\n 3 FRA           210\n 4 AUS           140\n 5 CAN           132\n 6 CHN           128\n 7 SWE           124\n 8 ESP           113\n 9 JPN            94\n10 ITA            79\n# ℹ 59 more rows\n\n\n\n\n\n\nlongest_races &lt;- race_df %&gt;%\n  slice_max(n = 5, order_by = distance) # Longest distance races\nlongest_races\n\n# A tibble: 6 × 13\n  race_year_id event     race  city  country date       start_time participation\n         &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;   &lt;date&gt;     &lt;time&gt;     &lt;chr&gt;        \n1        68776 Ultra To… Ut4M… Gren… France  2021-07-16 18:00      Solo         \n2        55551 Ultra Tr… Inth… Chom… Thaila… 2020-02-14 10:00      solo         \n3         7484 Le TREG®… LE T… Fada  Chad    2015-02-06 00:00      solo         \n4         7594 THE GREA… 100 … Pato… Austra… 2014-09-13 00:00      Solo         \n5        71066 ULTRA 01  Ultr… Oyon… France  2021-07-09 18:00      solo         \n6        23565 EstrelAç… Estr… Penh… Portug… 2017-10-06 18:00      Solo         \n# ℹ 5 more variables: distance &lt;dbl&gt;, elevation_gain &lt;dbl&gt;,\n#   elevation_loss &lt;dbl&gt;, aid_stations &lt;dbl&gt;, participants &lt;dbl&gt;\n\nlongest_races %&gt;%\n  left_join(., rank_df, by = \"race_year_id\") %&gt;% # total participants in longest 4 races\n  filter(rank %in% c(1:10)) %&gt;% # Top 10 ranks\n  count(nationality) %&gt;%\n  arrange(desc(n))\n\n# A tibble: 9 × 2\n  nationality     n\n  &lt;chr&gt;       &lt;int&gt;\n1 FRA            26\n2 AUS             9\n3 POR             8\n4 THA             8\n5 BEL             1\n6 BRA             1\n7 ESP             1\n8 MAS             1\n9 RUS             1\n\n\n\n\n\n\nrank_df %&gt;%\n  gf_histogram(~time_in_seconds, bins = 75) %&gt;%\n  gf_labs(title = \"Histogram of Race Times\")\n\nWarning: Removed 17791 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\n\n\n“1e+05” means 1×10 to the power 5. this is equal to 100,000 seconds.\n\n\n\n\n\nrace_df %&gt;%\n  gf_histogram(~distance, bins = 50) %&gt;%\n  gf_labs(title = \"Histogram of Race Distances\")\n\n\n\n\n\n\n\n\n\nrace_df %&gt;%\n  filter(distance == 0)\n\n# A tibble: 74 × 13\n   race_year_id event    race  city  country date       start_time participation\n          &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;   &lt;date&gt;     &lt;time&gt;     &lt;chr&gt;        \n 1        64771 The Old… 100m… Hanm… New Ze… 2021-05-14 10:00      solo         \n 2        71220 Run Lov… 100M  &lt;NA&gt;  United… 2021-02-26 00:00      solo         \n 3        67160 IDAHO M… 100 … &lt;NA&gt;  United… 2020-09-12 00:00      solo         \n 4        67713 Pine cr… 100M… Well… PA, Un… 2020-09-12 00:00      solo         \n 5        51777 Chiemga… 100 … Berg… Germany 2020-07-31 13:00      Solo         \n 6        66413 Palisad… Moos… Irwin United… 2020-07-17 05:00      solo         \n 7        62593 Run Lov… 100M  &lt;NA&gt;  United… 2020-02-28 00:00      solo         \n 8        50097 The Gre… The … Hanm… New Ze… 2020-01-17 07:00      solo         \n 9        65861 Loup Ga… 100M  Vill… LA, Un… 2019-12-14 00:00      solo         \n10        59415 RIO DEL… 100 … &lt;NA&gt;  United… 2019-11-07 00:00      solo         \n# ℹ 64 more rows\n# ℹ 5 more variables: distance &lt;dbl&gt;, elevation_gain &lt;dbl&gt;,\n#   elevation_loss &lt;dbl&gt;, aid_stations &lt;dbl&gt;, participants &lt;dbl&gt;\n\n\n\nsome of these zero-distance races have had participants too! Perhaps these were cancelled events…all of them are stated to be 100 mile events…\n\n\n\n\n\nrace_times &lt;- race_df %&gt;%\n  count(start_time) %&gt;%\n  arrange(desc(n))\nrace_times\n\n# A tibble: 39 × 2\n   start_time     n\n   &lt;time&gt;     &lt;int&gt;\n 1 00:00        513\n 2 06:00        114\n 3 08:00         63\n 4 10:00         60\n 5 07:00         58\n 6 18:00         50\n 7 05:00         48\n 8 12:00         38\n 9 04:00         30\n10 09:00         27\n# ℹ 29 more rows\n\n\n\n# Demo purposes only!\n\nrace_start_factor &lt;- race_df %&gt;%\n  filter(distance == 0) %&gt;% # Races that actually took place\n  mutate(\n    start_day_time =\n      case_when(\n        start_time &gt; hms(\"02:00:00\") &\n          start_time &lt;= hms(\"06:00:00\") ~ \"early_morning\",\n        start_time &gt; hms(\"06:00:01\") &\n          start_time &lt;= hms(\"10:00:00\") ~ \"late_morning\",\n        start_time &gt; hms(\"10:00:01\") &\n          start_time &lt;= hms(\"14:00:00\") ~ \"mid_day\",\n        start_time &gt; hms(\"14:00:01\") &\n          start_time &lt;= hms(\"18:00:00\") ~ \"afternoon\",\n        start_time &gt; hms(\"18:00:01\") &\n          start_time &lt;= hms(\"22:00:00\") ~ \"evening\",\n        start_time &gt; hms(\"22:00:01\") &\n          start_time &lt;= hms(\"23:59:59\") ~ \"night\",\n        start_time &gt;= hms(\"00:00:00\") &\n          start_time &lt;= hms(\"02:00:00\") ~ \"postmidnight\",\n        .default = \"other\"\n      )\n  ) %&gt;%\n  mutate(\n    start_day_time =\n      as_factor(start_day_time) %&gt;%\n        fct_collapse(\n          .f = .,\n          night = c(\"night\", \"postmidnight\")\n        )\n  )\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `start_day_time = `%&gt;%`(...)`.\nCaused by warning:\n! Unknown levels in `f`: night\n\n##\n# Join with rank_df\nrace_start_factor %&gt;%\n  left_join(rank_df, by = \"race_year_id\") %&gt;%\n  drop_na(time_in_seconds) %&gt;%\n  gf_histogram(\n    ~time_in_seconds,\n    bins = 75,\n    fill = ~start_day_time,\n    color = ~start_day_time,\n    alpha = 0.5\n  ) %&gt;%\n  gf_facet_wrap(vars(start_day_time), ncol = 2, scales = \"free_y\") %&gt;%\n  gf_labs(title = \"Race Times by Start-Time\")"
  },
  {
    "objectID": "posts/Aish-day-4/index.html#quantities",
    "href": "posts/Aish-day-4/index.html#quantities",
    "title": "Day-4",
    "section": "",
    "text": "We have downloaded a new library today - “crosstable”. It is used for fast stats for multiple variables in table form.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(ggformula)\nlibrary(skimr)\n\n\nAttaching package: 'skimr'\n\nThe following object is masked from 'package:mosaic':\n\n    n_missing\n\nlibrary(crosstable)\n\n\nAttaching package: 'crosstable'\n\nThe following object is masked from 'package:purrr':\n\n    compact"
  },
  {
    "objectID": "posts/Aish-day-4/index.html#examining-the-diamonds-dataset.",
    "href": "posts/Aish-day-4/index.html#examining-the-diamonds-dataset.",
    "title": "Day-4",
    "section": "",
    "text": "glimpse(diamonds)\n\nRows: 53,940\nColumns: 10\n$ carat   &lt;dbl&gt; 0.23, 0.21, 0.23, 0.29, 0.31, 0.24, 0.24, 0.26, 0.22, 0.23, 0.…\n$ cut     &lt;ord&gt; Ideal, Premium, Good, Premium, Good, Very Good, Very Good, Ver…\n$ color   &lt;ord&gt; E, E, E, I, J, J, I, H, E, H, J, J, F, J, E, E, I, J, J, J, I,…\n$ clarity &lt;ord&gt; SI2, SI1, VS1, VS2, SI2, VVS2, VVS1, SI1, VS2, VS1, SI1, VS1, …\n$ depth   &lt;dbl&gt; 61.5, 59.8, 56.9, 62.4, 63.3, 62.8, 62.3, 61.9, 65.1, 59.4, 64…\n$ table   &lt;dbl&gt; 55, 61, 65, 58, 58, 57, 57, 55, 61, 61, 55, 56, 61, 54, 62, 58…\n$ price   &lt;int&gt; 326, 326, 327, 334, 335, 336, 336, 337, 337, 338, 339, 340, 34…\n$ x       &lt;dbl&gt; 3.95, 3.89, 4.05, 4.20, 4.34, 3.94, 3.95, 4.07, 3.87, 4.00, 4.…\n$ y       &lt;dbl&gt; 3.98, 3.84, 4.07, 4.23, 4.35, 3.96, 3.98, 4.11, 3.78, 4.05, 4.…\n$ z       &lt;dbl&gt; 2.43, 2.31, 2.31, 2.63, 2.75, 2.48, 2.47, 2.53, 2.49, 2.39, 2.…\n\n\n\nskim(diamonds)\n\n\nData summary\n\n\nName\ndiamonds\n\n\nNumber of rows\n53940\n\n\nNumber of columns\n10\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n3\n\n\nnumeric\n7\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\ncut\n0\n1\nTRUE\n5\nIde: 21551, Pre: 13791, Ver: 12082, Goo: 4906\n\n\ncolor\n0\n1\nTRUE\n7\nG: 11292, E: 9797, F: 9542, H: 8304\n\n\nclarity\n0\n1\nTRUE\n8\nSI1: 13065, VS2: 12258, SI2: 9194, VS1: 8171\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\ncarat\n0\n1\n0.80\n0.47\n0.2\n0.40\n0.70\n1.04\n5.01\n▇▂▁▁▁\n\n\ndepth\n0\n1\n61.75\n1.43\n43.0\n61.00\n61.80\n62.50\n79.00\n▁▁▇▁▁\n\n\ntable\n0\n1\n57.46\n2.23\n43.0\n56.00\n57.00\n59.00\n95.00\n▁▇▁▁▁\n\n\nprice\n0\n1\n3932.80\n3989.44\n326.0\n950.00\n2401.00\n5324.25\n18823.00\n▇▂▁▁▁\n\n\nx\n0\n1\n5.73\n1.12\n0.0\n4.71\n5.70\n6.54\n10.74\n▁▁▇▃▁\n\n\ny\n0\n1\n5.73\n1.14\n0.0\n4.72\n5.71\n6.54\n58.90\n▇▁▁▁▁\n\n\nz\n0\n1\n3.54\n0.71\n0.0\n2.91\n3.53\n4.04\n31.80\n▇▁▁▁▁\n\n\n\n\n\n\ninspect(diamonds)\n\n\ncategorical variables:  \n     name   class levels     n missing\n1     cut ordered      5 53940       0\n2   color ordered      7 53940       0\n3 clarity ordered      8 53940       0\n                                   distribution\n1 Ideal (40%), Premium (25.6%) ...             \n2 G (20.9%), E (18.2%), F (17.7%) ...          \n3 SI1 (24.2%), VS2 (22.7%), SI2 (17%) ...      \n\nquantitative variables:  \n   name   class   min     Q1  median      Q3      max         mean           sd\n1 carat numeric   0.2   0.40    0.70    1.04     5.01    0.7979397    0.4740112\n2 depth numeric  43.0  61.00   61.80   62.50    79.00   61.7494049    1.4326213\n3 table numeric  43.0  56.00   57.00   59.00    95.00   57.4571839    2.2344906\n4 price integer 326.0 950.00 2401.00 5324.25 18823.00 3932.7997219 3989.4397381\n5     x numeric   0.0   4.71    5.70    6.54    10.74    5.7311572    1.1217607\n6     y numeric   0.0   4.72    5.71    6.54    58.90    5.7345260    1.1421347\n7     z numeric   0.0   2.91    3.53    4.04    31.80    3.5387338    0.7056988\n      n missing\n1 53940       0\n2 53940       0\n3 53940       0\n4 53940       0\n5 53940       0\n6 53940       0\n7 53940       0\n\n\n\ngf_histogram(~price, data = diamonds) %&gt;%\n  gf_labs(\n    title = \"Plot 1A: Diamond Prices\",\n    caption = \"ggformula\"\n  )\n\n\n\n\n\n\n\n\n\ndiamonds %&gt;% \n  gf_histogram(~price, bins = 100) %&gt;% \n  gf_labs(\n    title = \"Plot 1B: Diamond Prices\",\n    caption = \"ggformula\"\n\n  )\n\n\n\n\n\n\n\n\n\n\n\nThere are a great many diamonds at relatively low prices, but there are a good few diamonds at very high prices too.\nUsing a high number of bins does not materially change the view of the histogram.\n\n\ndiamonds %&gt;% \n  gf_histogram(~carat) %&gt;% \n  gf_labs(\n     title = \"Plot 2A: Carats of Diamonds\",\n    caption = \"ggformula\"\n  )\n\n\n\n\n\n\n\n\n\ndiamonds %&gt;% \n  gf_histogram(~carat, bins = 100) %&gt;% \n  gf_labs(\n     title = \"Plot 2B: Carats of Diamonds\",\n    caption = \"ggformula\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nthere is a marked “discreteness” to the distribution. Some values of carat are far more common than others. For example, 1, 1.5, and 2 carat diamonds are large in number.\n\n\ndiamonds %&gt;% \n  gf_histogram(~price, fill = ~cut) %&gt;% \n  gf_labs(\n     title = \"Plot 3A: Diamond Prices\", caption = \"ggformula\")\n\n\n\n\n\n\n\n\n\ndiamonds %&gt;%\n  gf_histogram(~price, fill = ~cut, color = \"black\", alpha = 0.3) %&gt;%\n  gf_labs(\n    title = \"Plot 3B: Prices by Cut\",\n    caption = \"ggformula\"\n  )\n\n\n\n\n\n\n\n\n\ndiamonds %&gt;%\n  gf_histogram(~price, fill = ~cut, color = \"black\", alpha = 0.3) %&gt;%\n  gf_facet_wrap(~cut) %&gt;%\n  gf_labs(\n    title = \"Plot 3C: Prices by Filled and Facetted by Cut\",\n    caption = \"ggformula\"\n  ) %&gt;%\n  gf_theme(theme(\n    axis.text.x = element_text(\n      angle = 45,\n      hjust = 1\n    )\n  ))\n\n\n\n\n\n\n\n\n\ndiamonds %&gt;%\n  gf_histogram(~price, fill = ~cut, color = \"black\", alpha = 0.3) %&gt;%\n  gf_facet_wrap(~cut, scales = \"free_y\", nrow = 2) %&gt;%\n  gf_labs(\n    title = \"Plot 3D: Prices Filled and Facetted by Cut\",\n    subtitle = \"Free y-scale\",\n    caption = \"ggformula\"\n  ) %&gt;%\n  gf_theme(theme(\n    axis.text.x =\n      element_text(\n        angle = 45,\n        hjust = 1\n      )\n  ))\n\n\n\n\n\n\n\n\n\ninstall.packages(\"shiny\")\nlibrary(shiny)\nrunExample(\"01_hello\") # an interactive histogram"
  },
  {
    "objectID": "posts/Aish-day-4/index.html#examining-the-race-dataset.",
    "href": "posts/Aish-day-4/index.html#examining-the-race-dataset.",
    "title": "Day-4",
    "section": "",
    "text": "race_df &lt;- read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-10-26/race.csv\")\n\nRows: 1207 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (5): event, race, city, country, participation\ndbl  (6): race_year_id, distance, elevation_gain, elevation_loss, aid_statio...\ndate (1): date\ntime (1): start_time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nrank_df &lt;- read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-10-26/ultra_rankings.csv\")\n\nRows: 137803 Columns: 8\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): runner, time, gender, nationality\ndbl (4): race_year_id, rank, age, time_in_seconds\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nglimpse(race_df)\n\nRows: 1,207\nColumns: 13\n$ race_year_id   &lt;dbl&gt; 68140, 72496, 69855, 67856, 70469, 66887, 67851, 68241,…\n$ event          &lt;chr&gt; \"Peak District Ultras\", \"UTMB®\", \"Grand Raid des Pyréné…\n$ race           &lt;chr&gt; \"Millstone 100\", \"UTMB®\", \"Ultra Tour 160\", \"PERSENK UL…\n$ city           &lt;chr&gt; \"Castleton\", \"Chamonix\", \"vielle-Aure\", \"Asenovgrad\", \"…\n$ country        &lt;chr&gt; \"United Kingdom\", \"France\", \"France\", \"Bulgaria\", \"Turk…\n$ date           &lt;date&gt; 2021-09-03, 2021-08-27, 2021-08-20, 2021-08-20, 2021-0…\n$ start_time     &lt;time&gt; 19:00:00, 17:00:00, 05:00:00, 18:00:00, 18:00:00, 17:0…\n$ participation  &lt;chr&gt; \"solo\", \"Solo\", \"solo\", \"solo\", \"solo\", \"solo\", \"solo\",…\n$ distance       &lt;dbl&gt; 166.9, 170.7, 167.0, 164.0, 159.9, 159.9, 163.8, 163.9,…\n$ elevation_gain &lt;dbl&gt; 4520, 9930, 9980, 7490, 100, 9850, 5460, 4630, 6410, 31…\n$ elevation_loss &lt;dbl&gt; -4520, -9930, -9980, -7500, -100, -9850, -5460, -4660, …\n$ aid_stations   &lt;dbl&gt; 10, 11, 13, 13, 12, 15, 5, 8, 13, 23, 13, 5, 12, 15, 0,…\n$ participants   &lt;dbl&gt; 150, 2300, 600, 150, 0, 300, 0, 200, 120, 100, 300, 50,…\n\n\n\nglimpse(rank_df)\n\nRows: 137,803\nColumns: 8\n$ race_year_id    &lt;dbl&gt; 68140, 68140, 68140, 68140, 68140, 68140, 68140, 68140…\n$ rank            &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, NA, NA, NA,…\n$ runner          &lt;chr&gt; \"VERHEUL Jasper\", \"MOULDING JON\", \"RICHARDSON Phill\", …\n$ time            &lt;chr&gt; \"26H 35M 25S\", \"27H 0M 29S\", \"28H 49M 7S\", \"30H 53M 37…\n$ age             &lt;dbl&gt; 30, 43, 38, 55, 48, 31, 55, 40, 47, 29, 48, 47, 52, 49…\n$ gender          &lt;chr&gt; \"M\", \"M\", \"M\", \"W\", \"W\", \"M\", \"W\", \"W\", \"M\", \"M\", \"M\",…\n$ nationality     &lt;chr&gt; \"GBR\", \"GBR\", \"GBR\", \"GBR\", \"GBR\", \"GBR\", \"GBR\", \"GBR\"…\n$ time_in_seconds &lt;dbl&gt; 95725, 97229, 103747, 111217, 117981, 118000, 120601, …\n\n\n\nrace_df %&gt;%\n  favstats(~distance, data = .)\n\n min    Q1 median     Q3   max     mean       sd    n missing\n   0 160.1  161.5 165.15 179.1 152.6187 39.87864 1207       0\n\n\n\n##\nrace_df %&gt;%\n  favstats(~participants, data = .)\n\n min Q1 median  Q3  max     mean       sd    n missing\n   0  0     21 150 2900 120.4872 281.8337 1207       0\n\n\n\n##\nrank_df %&gt;%\n  drop_na() %&gt;%\n  favstats(time_in_seconds ~ gender, data = .)\n\n  gender  min      Q1 median       Q3    max     mean       sd      n missing\n1      M 3600 96536.5 115845 149761.5 288000 123271.1 37615.42 101643       0\n2      W 9191 96695.0 107062 131464.0 296806 117296.5 34604.26  18341       0\n\n\n\n## library(crosstable)\ncrosstable(time_in_seconds + age ~ gender, data = rank_df) %&gt;%\n  crosstable::as_flextable()\n\nlabelvariablegenderMWNAtime_in_secondsMin / Max3600.0 / 2.9e+059191.0 / 3.0e+058131.0 / 2.2e+05Med [IQR]1.2e+05 [9.7e+04;1.5e+05]1.1e+05 [9.7e+04;1.3e+05]1.2e+05 [9.9e+04;1.5e+05]Mean (std)1.2e+05 (3.8e+04)1.2e+05 (3.5e+04)1.2e+05 (4.4e+04)N (NA)101643 (15073)18341 (2716)28 (2)ageMin / Max0 / 133.00 / 81.029.0 / 59.0Med [IQR]47.0 [40.0;53.0]45.0 [39.0;52.0]40.5 [36.0;50.5]Mean (std)46.4 (10.2)45.3 (9.7)41.7 (9.0)N (NA)116716 (0)21057 (0)30 (0)\n\n\n\n\n\nrace_df %&gt;%\n  count(country) %&gt;%\n  arrange(desc(n))\n\n# A tibble: 61 × 2\n   country            n\n   &lt;chr&gt;          &lt;int&gt;\n 1 United States    438\n 2 United Kingdom   110\n 3 France            56\n 4 Australia         46\n 5 Sweden            46\n 6 China             45\n 7 Canada            32\n 8 Spain             27\n 9 Japan             24\n10 Poland            23\n# ℹ 51 more rows\n\n\n\nrank_df %&gt;%\n  count(nationality) %&gt;%\n  arrange(desc(n))\n\n# A tibble: 133 × 2\n   nationality     n\n   &lt;chr&gt;       &lt;int&gt;\n 1 USA         47259\n 2 FRA         28905\n 3 GBR         11076\n 4 JPN          6729\n 5 ESP          5478\n 6 CHN          4744\n 7 CAN          2822\n 8 ITA          2794\n 9 SWE          2293\n10 AUS          1683\n# ℹ 123 more rows\n\n\nInsights:\n\nthe first piece of code tells the no. of races hosted by the respective countries, whereas the secodn piece of code tells no, of participants from each county.\nThe top three locations for races were the USA, UK, and France. These are also the countries that send the maximum number of participants, naturally!\n\n\n\n\n\nrank_df %&gt;%\n  filter(rank %in% c(1, 2, 3)) %&gt;%\n  count(nationality) %&gt;%\n  arrange(desc(n))\n\n# A tibble: 69 × 2\n   nationality     n\n   &lt;chr&gt;       &lt;int&gt;\n 1 USA          1240\n 2 GBR           347\n 3 FRA           210\n 4 AUS           140\n 5 CAN           132\n 6 CHN           128\n 7 SWE           124\n 8 ESP           113\n 9 JPN            94\n10 ITA            79\n# ℹ 59 more rows\n\n\n\n\n\n\nlongest_races &lt;- race_df %&gt;%\n  slice_max(n = 5, order_by = distance) # Longest distance races\nlongest_races\n\n# A tibble: 6 × 13\n  race_year_id event     race  city  country date       start_time participation\n         &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;   &lt;date&gt;     &lt;time&gt;     &lt;chr&gt;        \n1        68776 Ultra To… Ut4M… Gren… France  2021-07-16 18:00      Solo         \n2        55551 Ultra Tr… Inth… Chom… Thaila… 2020-02-14 10:00      solo         \n3         7484 Le TREG®… LE T… Fada  Chad    2015-02-06 00:00      solo         \n4         7594 THE GREA… 100 … Pato… Austra… 2014-09-13 00:00      Solo         \n5        71066 ULTRA 01  Ultr… Oyon… France  2021-07-09 18:00      solo         \n6        23565 EstrelAç… Estr… Penh… Portug… 2017-10-06 18:00      Solo         \n# ℹ 5 more variables: distance &lt;dbl&gt;, elevation_gain &lt;dbl&gt;,\n#   elevation_loss &lt;dbl&gt;, aid_stations &lt;dbl&gt;, participants &lt;dbl&gt;\n\nlongest_races %&gt;%\n  left_join(., rank_df, by = \"race_year_id\") %&gt;% # total participants in longest 4 races\n  filter(rank %in% c(1:10)) %&gt;% # Top 10 ranks\n  count(nationality) %&gt;%\n  arrange(desc(n))\n\n# A tibble: 9 × 2\n  nationality     n\n  &lt;chr&gt;       &lt;int&gt;\n1 FRA            26\n2 AUS             9\n3 POR             8\n4 THA             8\n5 BEL             1\n6 BRA             1\n7 ESP             1\n8 MAS             1\n9 RUS             1\n\n\n\n\n\n\nrank_df %&gt;%\n  gf_histogram(~time_in_seconds, bins = 75) %&gt;%\n  gf_labs(title = \"Histogram of Race Times\")\n\nWarning: Removed 17791 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\n\n\n“1e+05” means 1×10 to the power 5. this is equal to 100,000 seconds.\n\n\n\n\n\nrace_df %&gt;%\n  gf_histogram(~distance, bins = 50) %&gt;%\n  gf_labs(title = \"Histogram of Race Distances\")\n\n\n\n\n\n\n\n\n\nrace_df %&gt;%\n  filter(distance == 0)\n\n# A tibble: 74 × 13\n   race_year_id event    race  city  country date       start_time participation\n          &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;   &lt;date&gt;     &lt;time&gt;     &lt;chr&gt;        \n 1        64771 The Old… 100m… Hanm… New Ze… 2021-05-14 10:00      solo         \n 2        71220 Run Lov… 100M  &lt;NA&gt;  United… 2021-02-26 00:00      solo         \n 3        67160 IDAHO M… 100 … &lt;NA&gt;  United… 2020-09-12 00:00      solo         \n 4        67713 Pine cr… 100M… Well… PA, Un… 2020-09-12 00:00      solo         \n 5        51777 Chiemga… 100 … Berg… Germany 2020-07-31 13:00      Solo         \n 6        66413 Palisad… Moos… Irwin United… 2020-07-17 05:00      solo         \n 7        62593 Run Lov… 100M  &lt;NA&gt;  United… 2020-02-28 00:00      solo         \n 8        50097 The Gre… The … Hanm… New Ze… 2020-01-17 07:00      solo         \n 9        65861 Loup Ga… 100M  Vill… LA, Un… 2019-12-14 00:00      solo         \n10        59415 RIO DEL… 100 … &lt;NA&gt;  United… 2019-11-07 00:00      solo         \n# ℹ 64 more rows\n# ℹ 5 more variables: distance &lt;dbl&gt;, elevation_gain &lt;dbl&gt;,\n#   elevation_loss &lt;dbl&gt;, aid_stations &lt;dbl&gt;, participants &lt;dbl&gt;\n\n\n\nsome of these zero-distance races have had participants too! Perhaps these were cancelled events…all of them are stated to be 100 mile events…\n\n\n\n\n\nrace_times &lt;- race_df %&gt;%\n  count(start_time) %&gt;%\n  arrange(desc(n))\nrace_times\n\n# A tibble: 39 × 2\n   start_time     n\n   &lt;time&gt;     &lt;int&gt;\n 1 00:00        513\n 2 06:00        114\n 3 08:00         63\n 4 10:00         60\n 5 07:00         58\n 6 18:00         50\n 7 05:00         48\n 8 12:00         38\n 9 04:00         30\n10 09:00         27\n# ℹ 29 more rows\n\n\n\n# Demo purposes only!\n\nrace_start_factor &lt;- race_df %&gt;%\n  filter(distance == 0) %&gt;% # Races that actually took place\n  mutate(\n    start_day_time =\n      case_when(\n        start_time &gt; hms(\"02:00:00\") &\n          start_time &lt;= hms(\"06:00:00\") ~ \"early_morning\",\n        start_time &gt; hms(\"06:00:01\") &\n          start_time &lt;= hms(\"10:00:00\") ~ \"late_morning\",\n        start_time &gt; hms(\"10:00:01\") &\n          start_time &lt;= hms(\"14:00:00\") ~ \"mid_day\",\n        start_time &gt; hms(\"14:00:01\") &\n          start_time &lt;= hms(\"18:00:00\") ~ \"afternoon\",\n        start_time &gt; hms(\"18:00:01\") &\n          start_time &lt;= hms(\"22:00:00\") ~ \"evening\",\n        start_time &gt; hms(\"22:00:01\") &\n          start_time &lt;= hms(\"23:59:59\") ~ \"night\",\n        start_time &gt;= hms(\"00:00:00\") &\n          start_time &lt;= hms(\"02:00:00\") ~ \"postmidnight\",\n        .default = \"other\"\n      )\n  ) %&gt;%\n  mutate(\n    start_day_time =\n      as_factor(start_day_time) %&gt;%\n        fct_collapse(\n          .f = .,\n          night = c(\"night\", \"postmidnight\")\n        )\n  )\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `start_day_time = `%&gt;%`(...)`.\nCaused by warning:\n! Unknown levels in `f`: night\n\n##\n# Join with rank_df\nrace_start_factor %&gt;%\n  left_join(rank_df, by = \"race_year_id\") %&gt;%\n  drop_na(time_in_seconds) %&gt;%\n  gf_histogram(\n    ~time_in_seconds,\n    bins = 75,\n    fill = ~start_day_time,\n    color = ~start_day_time,\n    alpha = 0.5\n  ) %&gt;%\n  gf_facet_wrap(vars(start_day_time), ncol = 2, scales = \"free_y\") %&gt;%\n  gf_labs(title = \"Race Times by Start-Time\")"
  },
  {
    "objectID": "posts/Aish-day-6/index.html",
    "href": "posts/Aish-day-6/index.html",
    "title": "day-6",
    "section": "",
    "text": "Samples, Populations, Statistics and Inference\n\nAccording to the CLT, as the sample size increases, the distribution of the sample means becomes more tightly concentrated around the population mean, and the sampling distribution becomes narrower.\nSample size: number of observations or data points in sample. eg - If you are conducting a survey and collect responses from 100 people, your sample size is 100.\nshorter the sample, more inaccuracies.\nAs the sample becomes longer, the estimate of the mean becomes narrower.\n\nSince we would always work with a sample mean, it is not possible to know what the exact population mean is. However, there is something called as a confidence interval, whisk is the standard deviation around the sample mean. With confidence interval, we can say that the probability of population mean being within this range is rather very high.\n\nnarrow confidence intervals correlate to high accuracy of the sample set.\n\n\n\nBasics of Randomization Tests\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(ggformula)\nlibrary(infer)\n\n\nAttaching package: 'infer'\n\nThe following objects are masked from 'package:mosaic':\n\n    prop_test, t_test\n\nlibrary(broom) # Clean test results in tibble form\nlibrary(resampledata) # Datasets from Chihara and Hesterberg's book\n\n\nAttaching package: 'resampledata'\n\nThe following object is masked from 'package:datasets':\n\n    Titanic\n\nlibrary(openintro) # More datasets\n\nLoading required package: airports\nLoading required package: cherryblossom\nLoading required package: usdata\n\nAttaching package: 'openintro'\n\nThe following object is masked from 'package:mosaic':\n\n    dotPlot\n\nThe following objects are masked from 'package:lattice':\n\n    ethanol, lsegments\n\n\nAs we will notice, the process of Statistical Inference is an attitude: ain’t nothing happenin’! We look at data that we might have received or collected ourselves, and look at it with this attitude, seemingly, of some disbelief. We state either that:\n\nthere is really nothing happening with our research question, and that anything we see in the data is the outcome of random chance.\nthe value/statistic indicated by the data is off the mark and ought to be something else.\n\nWe then calculate how slim the chances are of the given data sample showing up like that, given our belief. It is a distance measurement of sorts. If those chances are too low, then that might alter our belief. This is the attitude that lies at the heart of Hypothesis Testing.\n\nCase Study #1: Toy data\n\nset.seed(40)  # for replication\n# Data as individual vectors ( for t.tests etc)\ny &lt;- rnorm(50, mean = 2, sd = 2)\n\n# And as tibble too\nmydata &lt;- tibble(y = y)\nmydata\n\n# A tibble: 50 × 1\n        y\n    &lt;dbl&gt;\n 1  2.96 \n 2  2.99 \n 3  0.281\n 4  0.342\n 5  1.36 \n 6 -0.608\n 7 -0.843\n 8  5.49 \n 9  1.42 \n10 -0.618\n# ℹ 40 more rows\n\n\n\n\nInspecting and Charting Data\n\nmydata %&gt;%\n    gf_density(~y) %&gt;%\n    gf_fitdistr(dist = \"dnorm\") %&gt;%\n    gf_labs(title = \"Densities of Original Data Variables\", subtitle = \"Compared with Normal Density\")\n\n\n\n\n\n\n\n\n\nThe variable y appear to be centred around 2\nIt does not seem to be normally distributed…\n\nResearch Question - Could the mean of the population μ, from which y has been drawn, be zero?\nAssumption - variable does not appear to be normally distributed. This would affect the test we can use to make inferences about the population mean."
  },
  {
    "objectID": "posts/do-women-live-longer/index.html",
    "href": "posts/do-women-live-longer/index.html",
    "title": "Dataset-1: Do Women live longer?",
    "section": "",
    "text": "I don’t know yet. If yes, then good for me I suppose :)\nLet’s find out.\nFirst, we gotta set up our document with relevant packages.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(skimr)\n\n\nAttaching package: 'skimr'\n\nThe following object is masked from 'package:mosaic':\n\n    n_missing\n\nlibrary(ggformula)\n\nNow, let’s import the dataset.\n\nwomen &lt;- read_delim(file = \"../../data/women.csv\",delim =\";\")\n\nRows: 18408 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\nchr (3): Entity, Code, Continent\ndbl (2): Year, Population - Sex: all - Age: all - Variant: estimates\nnum (2): Life expectancy - Sex: female - Age: at birth - Variant: estimates,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nglimpse(women)\n\nRows: 18,408\nColumns: 7\n$ Entity                                                               &lt;chr&gt; \"…\n$ Code                                                                 &lt;chr&gt; \"…\n$ Year                                                                 &lt;dbl&gt; 2…\n$ `Life expectancy - Sex: female - Age: at birth - Variant: estimates` &lt;dbl&gt; N…\n$ `Life expectancy - Sex: male - Age: at birth - Variant: estimates`   &lt;dbl&gt; N…\n$ `Population - Sex: all - Age: all - Variant: estimates`              &lt;dbl&gt; N…\n$ Continent                                                            &lt;chr&gt; \"…\n\nview(women)\n\n\nskim(women)\n\n\nData summary\n\n\nName\nwomen\n\n\nNumber of rows\n18408\n\n\nNumber of columns\n7\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n3\n\n\nnumeric\n4\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nEntity\n0\n1.00\n4\n59\n0\n303\n0\n\n\nCode\n1224\n0.93\n3\n8\n0\n286\n0\n\n\nContinent\n18123\n0.02\n4\n13\n0\n7\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nYear\n0\n1.00\n1985.58\n20.81\n1950\n1968.0\n1986\n2004\n2021\n▇▇▇▇▇\n\n\nLife expectancy - Sex: female - Age: at birth - Variant: estimates\n48\n1.00\n659.67\n125.11\n127\n574.0\n689\n757\n887\n▁▁▅▇▇\n\n\nLife expectancy - Sex: male - Age: at birth - Variant: estimates\n48\n1.00\n610.25\n115.53\n101\n534.0\n634\n697\n848\n▁▁▃▇▅\n\n\nPopulation - Sex: all - Age: all - Variant: estimates\n120\n0.99\n126470436.62\n588851230.77\n1363\n291591.5\n3833998\n16785464\n7909295000\n▇▁▁▁▁\n\n\n\n\n\n\ninspect(women)\n\n\ncategorical variables:  \n       name     class levels     n missing\n1    Entity character    303 18408       0\n2      Code character    286 17184    1224\n3 Continent character      7   285   18123\n                                   distribution\n1 Afghanistan (0.4%) ...                       \n2 ABW (0.4%), AFG (0.4%), AGO (0.4%) ...       \n3 Europe (26.3%), Asia (21.8%) ...             \n\nquantitative variables:  \n                                                                name   class\n1                                                               Year numeric\n2 Life expectancy - Sex: female - Age: at birth - Variant: estimates numeric\n3   Life expectancy - Sex: male - Age: at birth - Variant: estimates numeric\n4              Population - Sex: all - Age: all - Variant: estimates numeric\n   min       Q1  median       Q3        max         mean           sd     n\n1 1950   1968.0    1986     2004       2021 1.985577e+03 2.081051e+01 18408\n2  127    574.0     689      757        887 6.596735e+02 1.251064e+02 18360\n3  101    534.0     634      697        848 6.102504e+02 1.155310e+02 18360\n4 1363 291591.5 3833998 16785464 7909295000 1.264704e+08 5.888512e+08 18288\n  missing\n1       0\n2      48\n3      48\n4     120\n\n\n\n\n\n\n\nEntity (chr): Name of the country.\nCode (chr): code of the entity.\nyear (chr): year of entry.\nContinent (chr): continents from which the entries belong (fct).\n\n\n\n\n\nLifeExpFemale (dbl): life expectancy of females of the respective country.\nLifeExpMale (dbl): life expectancy of males of the respective country.\nPopulation (dbl): Population of the country.\n\n\nwomen_modified &lt;- women %&gt;% \n  filter(Year == 2015)\nglimpse(women_modified)\n\nRows: 303\nColumns: 7\n$ Entity                                                               &lt;chr&gt; \"…\n$ Code                                                                 &lt;chr&gt; \"…\n$ Year                                                                 &lt;dbl&gt; 2…\n$ `Life expectancy - Sex: female - Age: at birth - Variant: estimates` &lt;dbl&gt; N…\n$ `Life expectancy - Sex: male - Age: at birth - Variant: estimates`   &lt;dbl&gt; N…\n$ `Population - Sex: all - Age: all - Variant: estimates`              &lt;dbl&gt; N…\n$ Continent                                                            &lt;chr&gt; \"…\n\n\nSo, the reason why I have filtered out the data on the basis on year 2015 is so that I can replicate the table in Arvind’s website. I suppose, it has been done also because it is easier to analyse such context while keeping the year constant. Why? I think it is so because there are other vital factors ( like pollution index, poverty index, cultural and ‘current’ affairs etc.) that play a crucial role in determining the life expectancy, and they tend to change overtime.\nNow, I will drop the missing values.\n\nwomen_modified &lt;- women_modified %&gt;% drop_na()\n\nglimpse(women_modified)\n\nRows: 236\nColumns: 7\n$ Entity                                                               &lt;chr&gt; \"…\n$ Code                                                                 &lt;chr&gt; \"…\n$ Year                                                                 &lt;dbl&gt; 2…\n$ `Life expectancy - Sex: female - Age: at birth - Variant: estimates` &lt;dbl&gt; 6…\n$ `Life expectancy - Sex: male - Age: at birth - Variant: estimates`   &lt;dbl&gt; 6…\n$ `Population - Sex: all - Age: all - Variant: estimates`              &lt;dbl&gt; 3…\n$ Continent                                                            &lt;chr&gt; \"…\n\n\nNow, we shall do some renaming and mutating to make our lives easier.\n\nwomen_modified &lt;- women_modified %&gt;% \n  mutate(\n    life_exp_female = `Life expectancy - Sex: female - Age: at birth - Variant: estimates` / 10,\n    life_exp_male = `Life expectancy - Sex: male - Age: at birth - Variant: estimates` / 10,\n    Continent = as.factor(Continent)\n  )\n\nglimpse(women_modified)\n\nRows: 236\nColumns: 9\n$ Entity                                                               &lt;chr&gt; \"…\n$ Code                                                                 &lt;chr&gt; \"…\n$ Year                                                                 &lt;dbl&gt; 2…\n$ `Life expectancy - Sex: female - Age: at birth - Variant: estimates` &lt;dbl&gt; 6…\n$ `Life expectancy - Sex: male - Age: at birth - Variant: estimates`   &lt;dbl&gt; 6…\n$ `Population - Sex: all - Age: all - Variant: estimates`              &lt;dbl&gt; 3…\n$ Continent                                                            &lt;fct&gt; A…\n$ life_exp_female                                                      &lt;dbl&gt; 6…\n$ life_exp_male                                                        &lt;dbl&gt; 6…\n\n\nHere we go!\nI shall now recreate the chart that is given on Arvind’s website.\n\nwomen_modified %&gt;%\n  gf_point(life_exp_female ~ life_exp_male) %&gt;%\n  gf_labs(\n    title = \"Scatter Plot\",\n    subtitle = \"Life expectancy across years\"\n  )\n\n\n\n\n\n\n\n\nThis is a scatter plot! It is depicting the correlation between life expectancy between males and females. I am unable to recreate the exact replica of the graph; I can’t figure out how to. However, it seems like we can make do with this for the time being.\nWhen we look at this graph carefully, we see that almost all the points are placed such that for every point, x ( male life expectancy) &lt; y(female life expectancy).\nTo better understand what is going on, I will add a line to the graph.\n\nwomen_modified %&gt;%\n  gf_point(life_exp_female ~ life_exp_male) %&gt;%\n  gf_lm() %&gt;% \n  gf_labs(\n    title = \"Scatter Plot\",\n    subtitle = \"Life expectancy across years\"\n  )\n\nWarning: Using the `size` aesthetic with geom_line was deprecated in ggplot2 3.4.0.\nℹ Please use the `linewidth` aesthetic instead.\n\n\n\n\n\n\n\n\n\n\n\nWe see that while it may appear that the slope (m) = 1, it is not true. When we look carefully, we see that vale on the x axis starts from 50 onwards, whereas it start from 60 onwards on y axis. Hence, m is not 1.\nIn the website’s chart, it is clearly seen that life expectancy for both the genders is more or less the same in countries with bigger populations.\n\n\n\nit represents slop of the graph when m = 1, meaning when there is a 1:1 correlation between both the variables. It is also called the equality line.\n\n\n\n\n\nFiltering by year\ndropping rows with missing data\nrenaming and mutating data\n\nI used mutate to both rename and mutate the data variables\nrenames the life expectancy variables and then divided them by 10 to get the exact age.\nI converted ‘continent’ variable to factor as it had 7 levels. It seemed only fair to convert it to a factor.\n\n\n\n\n\nLife expectancy is calculated at different stages and ages. I do not think the researchers went around on the streets gathering data themselves, although that would’ve been fun. However, I believe this data might have been obtained through different sources over the years. For example, they would’ve contacted WHO and other trusted organizations to gather this data. Government websites, and hospitals from across the world would’ve been contacted for the same.\nIt is also possible that physical surveys were conducted by authorities, especially in smaller countries where it is probably not possible to find tidy data, and accessibility through digital mediums is not entirely possible.\n\n\n\n\nWhich gender lives longer in a particular city?\nDo women live longer than men in countries with big populations?\nWomen tend to live a longer and happier life, no matter where they are [Hypothesis].\n\n\n\n\nAcross most countries, women consistently live longer than men, with nearly all data points above the equality line. In Countries with bigger populations, life expectancy is mostly same between both the genders. Despite being considered the weaker gender, women outlive the ‘stronger’ men."
  },
  {
    "objectID": "posts/do-women-live-longer/index.html#data-dictionary",
    "href": "posts/do-women-live-longer/index.html#data-dictionary",
    "title": "Dataset-1: Do Women live longer?",
    "section": "",
    "text": "Entity (chr): Name of the country.\nCode (chr): code of the entity.\nyear (chr): year of entry.\nContinent (chr): continents from which the entries belong (fct).\n\n\n\n\n\nLifeExpFemale (dbl): life expectancy of females of the respective country.\nLifeExpMale (dbl): life expectancy of males of the respective country.\nPopulation (dbl): Population of the country.\n\n\nwomen_modified &lt;- women %&gt;% \n  filter(Year == 2015)\nglimpse(women_modified)\n\nRows: 303\nColumns: 7\n$ Entity                                                               &lt;chr&gt; \"…\n$ Code                                                                 &lt;chr&gt; \"…\n$ Year                                                                 &lt;dbl&gt; 2…\n$ `Life expectancy - Sex: female - Age: at birth - Variant: estimates` &lt;dbl&gt; N…\n$ `Life expectancy - Sex: male - Age: at birth - Variant: estimates`   &lt;dbl&gt; N…\n$ `Population - Sex: all - Age: all - Variant: estimates`              &lt;dbl&gt; N…\n$ Continent                                                            &lt;chr&gt; \"…\n\n\nSo, the reason why I have filtered out the data on the basis on year 2015 is so that I can replicate the table in Arvind’s website. I suppose, it has been done also because it is easier to analyse such context while keeping the year constant. Why? I think it is so because there are other vital factors ( like pollution index, poverty index, cultural and ‘current’ affairs etc.) that play a crucial role in determining the life expectancy, and they tend to change overtime.\nNow, I will drop the missing values.\n\nwomen_modified &lt;- women_modified %&gt;% drop_na()\n\nglimpse(women_modified)\n\nRows: 236\nColumns: 7\n$ Entity                                                               &lt;chr&gt; \"…\n$ Code                                                                 &lt;chr&gt; \"…\n$ Year                                                                 &lt;dbl&gt; 2…\n$ `Life expectancy - Sex: female - Age: at birth - Variant: estimates` &lt;dbl&gt; 6…\n$ `Life expectancy - Sex: male - Age: at birth - Variant: estimates`   &lt;dbl&gt; 6…\n$ `Population - Sex: all - Age: all - Variant: estimates`              &lt;dbl&gt; 3…\n$ Continent                                                            &lt;chr&gt; \"…\n\n\nNow, we shall do some renaming and mutating to make our lives easier.\n\nwomen_modified &lt;- women_modified %&gt;% \n  mutate(\n    life_exp_female = `Life expectancy - Sex: female - Age: at birth - Variant: estimates` / 10,\n    life_exp_male = `Life expectancy - Sex: male - Age: at birth - Variant: estimates` / 10,\n    Continent = as.factor(Continent)\n  )\n\nglimpse(women_modified)\n\nRows: 236\nColumns: 9\n$ Entity                                                               &lt;chr&gt; \"…\n$ Code                                                                 &lt;chr&gt; \"…\n$ Year                                                                 &lt;dbl&gt; 2…\n$ `Life expectancy - Sex: female - Age: at birth - Variant: estimates` &lt;dbl&gt; 6…\n$ `Life expectancy - Sex: male - Age: at birth - Variant: estimates`   &lt;dbl&gt; 6…\n$ `Population - Sex: all - Age: all - Variant: estimates`              &lt;dbl&gt; 3…\n$ Continent                                                            &lt;fct&gt; A…\n$ life_exp_female                                                      &lt;dbl&gt; 6…\n$ life_exp_male                                                        &lt;dbl&gt; 6…\n\n\nHere we go!\nI shall now recreate the chart that is given on Arvind’s website.\n\nwomen_modified %&gt;%\n  gf_point(life_exp_female ~ life_exp_male) %&gt;%\n  gf_labs(\n    title = \"Scatter Plot\",\n    subtitle = \"Life expectancy across years\"\n  )\n\n\n\n\n\n\n\n\nThis is a scatter plot! It is depicting the correlation between life expectancy between males and females. I am unable to recreate the exact replica of the graph; I can’t figure out how to. However, it seems like we can make do with this for the time being.\nWhen we look at this graph carefully, we see that almost all the points are placed such that for every point, x ( male life expectancy) &lt; y(female life expectancy).\nTo better understand what is going on, I will add a line to the graph.\n\nwomen_modified %&gt;%\n  gf_point(life_exp_female ~ life_exp_male) %&gt;%\n  gf_lm() %&gt;% \n  gf_labs(\n    title = \"Scatter Plot\",\n    subtitle = \"Life expectancy across years\"\n  )\n\nWarning: Using the `size` aesthetic with geom_line was deprecated in ggplot2 3.4.0.\nℹ Please use the `linewidth` aesthetic instead.\n\n\n\n\n\n\n\n\n\n\n\nWe see that while it may appear that the slope (m) = 1, it is not true. When we look carefully, we see that vale on the x axis starts from 50 onwards, whereas it start from 60 onwards on y axis. Hence, m is not 1.\nIn the website’s chart, it is clearly seen that life expectancy for both the genders is more or less the same in countries with bigger populations.\n\n\n\nit represents slop of the graph when m = 1, meaning when there is a 1:1 correlation between both the variables. It is also called the equality line.\n\n\n\n\n\nFiltering by year\ndropping rows with missing data\nrenaming and mutating data\n\nI used mutate to both rename and mutate the data variables\nrenames the life expectancy variables and then divided them by 10 to get the exact age.\nI converted ‘continent’ variable to factor as it had 7 levels. It seemed only fair to convert it to a factor.\n\n\n\n\n\nLife expectancy is calculated at different stages and ages. I do not think the researchers went around on the streets gathering data themselves, although that would’ve been fun. However, I believe this data might have been obtained through different sources over the years. For example, they would’ve contacted WHO and other trusted organizations to gather this data. Government websites, and hospitals from across the world would’ve been contacted for the same.\nIt is also possible that physical surveys were conducted by authorities, especially in smaller countries where it is probably not possible to find tidy data, and accessibility through digital mediums is not entirely possible.\n\n\n\n\nWhich gender lives longer in a particular city?\nDo women live longer than men in countries with big populations?\nWomen tend to live a longer and happier life, no matter where they are [Hypothesis].\n\n\n\n\nAcross most countries, women consistently live longer than men, with nearly all data points above the equality line. In Countries with bigger populations, life expectancy is mostly same between both the genders. Despite being considered the weaker gender, women outlive the ‘stronger’ men."
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/Movie-profits/index.html",
    "href": "posts/Movie-profits/index.html",
    "title": "Dataset-2: Movie Profits",
    "section": "",
    "text": "Let’s set up our document with libraries first.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(skimr)\n\n\nAttaching package: 'skimr'\n\nThe following object is masked from 'package:mosaic':\n\n    n_missing\n\nlibrary(ggformula)\n\nNow, let’s import the dataset.\n\nmovie &lt;- read_delim(file = \"../../data/movie_profit.csv\",delim =\";\")\n\nRows: 3310 Columns: 10\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\nchr  (4): movie, distributor, mpaa_rating, genre\ndbl  (4): production_budget, domestic_gross, worldwide_gross, decade\nnum  (1): profit_ratio\ndate (1): release_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nglimpse(movie)\n\nRows: 3,310\nColumns: 10\n$ release_date      &lt;date&gt; 2005-07-22, 1998-08-28, 1997-03-28, 2000-07-14, 201…\n$ movie             &lt;chr&gt; \"November\", \"I Married a Strange Person\", \"Love and …\n$ production_budget &lt;dbl&gt; 250000, 250000, 250000, 250000, 250000, 250000, 2500…\n$ domestic_gross    &lt;dbl&gt; 191862, 203134, 212285, 1055671, 3395391, 3802390, 3…\n$ worldwide_gross   &lt;dbl&gt; 191862, 203134, 743216, 1157672, 3728400, 3809226, 3…\n$ distributor       &lt;chr&gt; \"Other\", \"Other\", \"Other\", \"Other\", \"Paramount Pictu…\n$ mpaa_rating       &lt;chr&gt; \"R\", NA, \"R\", \"R\", \"PG-13\", \"R\", \"R\", \"R\", \"R\", \"R\",…\n$ genre             &lt;chr&gt; \"Drama\", \"Comedy\", \"Comedy\", \"Drama\", \"Drama\", \"Dram…\n$ profit_ratio      &lt;dbl&gt; 7.674480e+13, 8.125360e+13, 2.972864e+14, 4.630688e+…\n$ decade            &lt;dbl&gt; 2000, 1990, 1990, 2000, 2010, 2000, 2010, 2000, 2010…\n\nview(movie)\n\n\nskim(movie)\n\n\nData summary\n\n\nName\nmovie\n\n\nNumber of rows\n3310\n\n\nNumber of columns\n10\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n4\n\n\nDate\n1\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nmovie\n0\n1.00\n1\n35\n0\n3310\n0\n\n\ndistributor\n42\n0.99\n5\n18\n0\n6\n0\n\n\nmpaa_rating\n130\n0.96\n1\n5\n0\n4\n0\n\n\ngenre\n0\n1.00\n5\n9\n0\n5\n0\n\n\n\nVariable type: Date\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\nrelease_date\n0\n1\n1936-02-05\n2017-12-22\n2005-06-30\n1723\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nproduction_budget\n0\n1\n3.326794e+07\n3.460741e+07\n2.50e+05\n9.500000e+06\n2.000000e+07\n4.500000e+07\n1.750000e+08\n▇▂▁▁▁\n\n\ndomestic_gross\n0\n1\n4.551509e+07\n5.852794e+07\n0.00e+00\n6.530094e+06\n2.558731e+07\n6.046695e+07\n4.745447e+08\n▇▁▁▁▁\n\n\nworldwide_gross\n0\n1\n9.384123e+07\n1.389514e+08\n4.23e+02\n1.086144e+07\n4.040903e+07\n1.184703e+08\n1.162782e+09\n▇▁▁▁▁\n\n\nprofit_ratio\n0\n1\n4.319388e+14\n1.501736e+15\n1.38e+10\n7.861269e+13\n1.962499e+14\n3.942158e+14\n4.315179e+16\n▇▁▁▁▁\n\n\ndecade\n0\n1\n1.998790e+03\n1.061000e+01\n1.93e+03\n1.990000e+03\n2.000000e+03\n2.010000e+03\n2.010000e+03\n▁▁▁▃▇\n\n\n\n\n\n\ninspect(movie)\n\n\ncategorical variables:  \n         name     class levels    n missing\n1       movie character   3310 3310       0\n2 distributor character      6 3268      42\n3 mpaa_rating character      4 3180     130\n4       genre character      5 3310       0\n                                   distribution\n1 10 Days in a Madhouse (0%) ...               \n2  Other (53.2%), Warner Bros. (11%) ...       \n3 R (46.4%), PG-13 (33.5%), PG (17.4%) ...     \n4 Drama (36.5%), Comedy (24.1%) ...            \n\nDate variables:  \n          name class      first       last min_diff  max_diff    n missing\n1 release_date  Date 1936-02-05 2017-12-22   0 days 2592 days 3310       0\n\nquantitative variables:  \n               name   class      min           Q1       median           Q3\n1 production_budget numeric 2.50e+05 9.500000e+06 2.000000e+07 4.500000e+07\n2    domestic_gross numeric 0.00e+00 6.530094e+06 2.558731e+07 6.046695e+07\n3   worldwide_gross numeric 4.23e+02 1.086144e+07 4.040903e+07 1.184703e+08\n4      profit_ratio numeric 1.38e+10 7.861269e+13 1.962499e+14 3.942158e+14\n5            decade numeric 1.93e+03 1.990000e+03 2.000000e+03 2.010000e+03\n           max         mean           sd    n missing\n1 1.750000e+08 3.326794e+07 3.460741e+07 3310       0\n2 4.745447e+08 4.551509e+07 5.852794e+07 3310       0\n3 1.162782e+09 9.384123e+07 1.389514e+08 3310       0\n4 4.315179e+16 4.319388e+14 1.501736e+15 3310       0\n5 2.010000e+03 1.998785e+03 1.061308e+01 3310       0\n\n\n\n\n\n\n\nmovie (chr): Name of the movie.\ndistributor (chr): company that is distributing the movie (fct).\nmpaa_rating (chr): movie rating (fct).\ngenre (chr): movie genre (fct).\ndecade (chr): movie genre.\n\n\n\n\n\nrelease_date (date): date of release.\nproduction_budget (dbl): budget for production of the movie.\ndomestic_gross (dbl): gross income for the movie in domestic box office.\nworldwide_gross (dbl): gross income for the movie in international box office.\nprofit_ratio (dbl): ratio of profit.\n\nThis dataset has equal numbers of qual as well as quant variables. profit_ratio is the target variable here, whereas genre and distributor are the potential predictor variables.\nNow, I will mutate some variables and turn them into factors.\n\nmovie_modified &lt;- movie %&gt;% \n  mutate(\n    distributor = as.factor(distributor),\n    mpaa_rating = as.factor(mpaa_rating),\n    genre = as.factor(genre),\n    decade = as.factor(decade)\n  )\n\nglimpse(movie_modified)\n\nRows: 3,310\nColumns: 10\n$ release_date      &lt;date&gt; 2005-07-22, 1998-08-28, 1997-03-28, 2000-07-14, 201…\n$ movie             &lt;chr&gt; \"November\", \"I Married a Strange Person\", \"Love and …\n$ production_budget &lt;dbl&gt; 250000, 250000, 250000, 250000, 250000, 250000, 2500…\n$ domestic_gross    &lt;dbl&gt; 191862, 203134, 212285, 1055671, 3395391, 3802390, 3…\n$ worldwide_gross   &lt;dbl&gt; 191862, 203134, 743216, 1157672, 3728400, 3809226, 3…\n$ distributor       &lt;fct&gt; Other, Other, Other, Other, Paramount Pictures, Para…\n$ mpaa_rating       &lt;fct&gt; R, NA, R, R, PG-13, R, R, R, R, R, R, R, PG-13, NA, …\n$ genre             &lt;fct&gt; Drama, Comedy, Comedy, Drama, Drama, Drama, Action, …\n$ profit_ratio      &lt;dbl&gt; 7.674480e+13, 8.125360e+13, 2.972864e+14, 4.630688e+…\n$ decade            &lt;fct&gt; 2000, 1990, 1990, 2000, 2010, 2000, 2010, 2000, 2010…\n\nprint(movie_modified)\n\n# A tibble: 3,310 × 10\n   release_date movie           production_budget domestic_gross worldwide_gross\n   &lt;date&gt;       &lt;chr&gt;                       &lt;dbl&gt;          &lt;dbl&gt;           &lt;dbl&gt;\n 1 2005-07-22   November                   250000         191862          191862\n 2 1998-08-28   I Married a St…            250000         203134          203134\n 3 1997-03-28   Love and Other…            250000         212285          743216\n 4 2000-07-14   Chuck&Buck                 250000        1055671         1157672\n 5 2011-10-28   Like Crazy                 250000        3395391         3728400\n 6 2003-04-11   Better Luck To…            250000        3802390         3809226\n 7 2017-04-28   Sleight                    250000        3930990         3934450\n 8 2002-06-28   Lovely and Ama…            250000        4210379         4613482\n 9 2012-08-17   Compliance                 270000         319285          830700\n10 2005-05-06   Fighting Tommy…            300000          10514           10514\n# ℹ 3,300 more rows\n# ℹ 5 more variables: distributor &lt;fct&gt;, mpaa_rating &lt;fct&gt;, genre &lt;fct&gt;,\n#   profit_ratio &lt;dbl&gt;, decade &lt;fct&gt;\n\n\n\n\n\n\nThe first one would be internet browsing. Availing data from sources like imdb, wikipedia, etc.\nLet’s say that an individual was very excited and enthusiastic about obtaining this dataset. They might have visited their nearest movie theaters every friday to get the movie names. For an enquiry to become a data set, it has to start somewhere with some variable.\nMore enthusiasm would’ve led them to call a production house and ask questions regarding the budget.\n\n\n\n\n\ndo profit margins for different genres vary across major film distributors?\nwhich genres are more profitable for each of the distributors?\nHow does the distributor “N/A” compare to the other big distributors?\nWhat is the comparison between domestic gross and international gross of the movies?\nwhat has been the trend in production budget across decades?\nwhich genre had most profit in each decade?\n\nLet’s replicate the graph now.\n\nmovie_modified %&gt;%\n  group_by(distributor, genre) %&gt;%                 \n  \n  summarise(median_profit_ratio = median(profit_ratio, na.rm = TRUE)) %&gt;%  \n  ggplot(aes(x = genre, y = median_profit_ratio)) +  \n  geom_bar(stat = \"identity\", fill = \"darkgray\") +   \n  facet_wrap(~ distributor) +                        \n  coord_flip() +                                     \n  labs(\n    title = \"Profits made by Film Distributors\",\n    subtitle = \"Ratio of Profits to Budgets\",\n    x = \"Genre\", \n    y = \"Median Profit Ratio\",\n    caption = \"Tidy Tuesday Oct 23, 2018\"\n  ) +\n  theme_minimal() +                                  \n  theme(\n    strip.text = element_text(face = \"bold\"),        \n    plot.title = element_text(face = \"bold\", size = 16)  \n  )\n\n`summarise()` has grouped output by 'distributor'. You can override using the\n`.groups` argument.\n\n\n\n\n\n\n\n\n\n[KINDLY NOTE: I have taken the help of chatgpt to replicate this graph as I was unable to figure it out myself.]\nThis is a bar graph!\n\n\n\n\nAll distributors have at least one genre that they make most profit from.\n‘Action’ genre is most successful in very small scale distributors named ‘N/A’.\n20th century fox has the most uniform distribution of profit margin across all genres.\n‘Drama’ seems to have the equal profitability margin across all distributors.\n‘Action’, ‘Adventure’, and ‘Horror’ generally have the done the most profit across all distributors.\n\n\n\n\nUse of delimiter in order to separate the columns.\n\n\n\nSince genres like action, adventure, and horror have uniform profits across all distributors, it is therefore more probable to make profitable movies belonging to these genres.\nBig distributors like 20th century fox and universal studios usually manage to make profits out of any of the said genre regardless of the rating.\nif one cannot get hold of these big distributors, the best way to break through would be to make action movies and sell them all across small distributors.\n\n\n\nThe company that had started out as “Comedy Spread” was doing wonders just a decade ago. Their light-hearted films and rom-com hits had audiences laughing all the way to the box office. However, times have changed now. People prefer action over drama and comedy (I can’t seem to understand why). With every passing year, their profits from action-packed blockbusters soared. It’s as if audiences crave the thrill of explosions, chases, and stunts more than ever. “Comedy Spread” finds itself at a crossroads—will they change themselves to survive in this market, or will they stick to their roots, hoping the world rekindles its love for a good laugh? Only time will tell."
  },
  {
    "objectID": "posts/Movie-profits/index.html#data-dictionary",
    "href": "posts/Movie-profits/index.html#data-dictionary",
    "title": "Dataset-2: Movie Profits",
    "section": "",
    "text": "movie (chr): Name of the movie.\ndistributor (chr): company that is distributing the movie (fct).\nmpaa_rating (chr): movie rating (fct).\ngenre (chr): movie genre (fct).\ndecade (chr): movie genre.\n\n\n\n\n\nrelease_date (date): date of release.\nproduction_budget (dbl): budget for production of the movie.\ndomestic_gross (dbl): gross income for the movie in domestic box office.\nworldwide_gross (dbl): gross income for the movie in international box office.\nprofit_ratio (dbl): ratio of profit.\n\nThis dataset has equal numbers of qual as well as quant variables. profit_ratio is the target variable here, whereas genre and distributor are the potential predictor variables.\nNow, I will mutate some variables and turn them into factors.\n\nmovie_modified &lt;- movie %&gt;% \n  mutate(\n    distributor = as.factor(distributor),\n    mpaa_rating = as.factor(mpaa_rating),\n    genre = as.factor(genre),\n    decade = as.factor(decade)\n  )\n\nglimpse(movie_modified)\n\nRows: 3,310\nColumns: 10\n$ release_date      &lt;date&gt; 2005-07-22, 1998-08-28, 1997-03-28, 2000-07-14, 201…\n$ movie             &lt;chr&gt; \"November\", \"I Married a Strange Person\", \"Love and …\n$ production_budget &lt;dbl&gt; 250000, 250000, 250000, 250000, 250000, 250000, 2500…\n$ domestic_gross    &lt;dbl&gt; 191862, 203134, 212285, 1055671, 3395391, 3802390, 3…\n$ worldwide_gross   &lt;dbl&gt; 191862, 203134, 743216, 1157672, 3728400, 3809226, 3…\n$ distributor       &lt;fct&gt; Other, Other, Other, Other, Paramount Pictures, Para…\n$ mpaa_rating       &lt;fct&gt; R, NA, R, R, PG-13, R, R, R, R, R, R, R, PG-13, NA, …\n$ genre             &lt;fct&gt; Drama, Comedy, Comedy, Drama, Drama, Drama, Action, …\n$ profit_ratio      &lt;dbl&gt; 7.674480e+13, 8.125360e+13, 2.972864e+14, 4.630688e+…\n$ decade            &lt;fct&gt; 2000, 1990, 1990, 2000, 2010, 2000, 2010, 2000, 2010…\n\nprint(movie_modified)\n\n# A tibble: 3,310 × 10\n   release_date movie           production_budget domestic_gross worldwide_gross\n   &lt;date&gt;       &lt;chr&gt;                       &lt;dbl&gt;          &lt;dbl&gt;           &lt;dbl&gt;\n 1 2005-07-22   November                   250000         191862          191862\n 2 1998-08-28   I Married a St…            250000         203134          203134\n 3 1997-03-28   Love and Other…            250000         212285          743216\n 4 2000-07-14   Chuck&Buck                 250000        1055671         1157672\n 5 2011-10-28   Like Crazy                 250000        3395391         3728400\n 6 2003-04-11   Better Luck To…            250000        3802390         3809226\n 7 2017-04-28   Sleight                    250000        3930990         3934450\n 8 2002-06-28   Lovely and Ama…            250000        4210379         4613482\n 9 2012-08-17   Compliance                 270000         319285          830700\n10 2005-05-06   Fighting Tommy…            300000          10514           10514\n# ℹ 3,300 more rows\n# ℹ 5 more variables: distributor &lt;fct&gt;, mpaa_rating &lt;fct&gt;, genre &lt;fct&gt;,\n#   profit_ratio &lt;dbl&gt;, decade &lt;fct&gt;\n\n\n\n\n\n\nThe first one would be internet browsing. Availing data from sources like imdb, wikipedia, etc.\nLet’s say that an individual was very excited and enthusiastic about obtaining this dataset. They might have visited their nearest movie theaters every friday to get the movie names. For an enquiry to become a data set, it has to start somewhere with some variable.\nMore enthusiasm would’ve led them to call a production house and ask questions regarding the budget.\n\n\n\n\n\ndo profit margins for different genres vary across major film distributors?\nwhich genres are more profitable for each of the distributors?\nHow does the distributor “N/A” compare to the other big distributors?\nWhat is the comparison between domestic gross and international gross of the movies?\nwhat has been the trend in production budget across decades?\nwhich genre had most profit in each decade?\n\nLet’s replicate the graph now.\n\nmovie_modified %&gt;%\n  group_by(distributor, genre) %&gt;%                 \n  \n  summarise(median_profit_ratio = median(profit_ratio, na.rm = TRUE)) %&gt;%  \n  ggplot(aes(x = genre, y = median_profit_ratio)) +  \n  geom_bar(stat = \"identity\", fill = \"darkgray\") +   \n  facet_wrap(~ distributor) +                        \n  coord_flip() +                                     \n  labs(\n    title = \"Profits made by Film Distributors\",\n    subtitle = \"Ratio of Profits to Budgets\",\n    x = \"Genre\", \n    y = \"Median Profit Ratio\",\n    caption = \"Tidy Tuesday Oct 23, 2018\"\n  ) +\n  theme_minimal() +                                  \n  theme(\n    strip.text = element_text(face = \"bold\"),        \n    plot.title = element_text(face = \"bold\", size = 16)  \n  )\n\n`summarise()` has grouped output by 'distributor'. You can override using the\n`.groups` argument.\n\n\n\n\n\n\n\n\n\n[KINDLY NOTE: I have taken the help of chatgpt to replicate this graph as I was unable to figure it out myself.]\nThis is a bar graph!\n\n\n\n\nAll distributors have at least one genre that they make most profit from.\n‘Action’ genre is most successful in very small scale distributors named ‘N/A’.\n20th century fox has the most uniform distribution of profit margin across all genres.\n‘Drama’ seems to have the equal profitability margin across all distributors.\n‘Action’, ‘Adventure’, and ‘Horror’ generally have the done the most profit across all distributors.\n\n\n\n\nUse of delimiter in order to separate the columns.\n\n\n\nSince genres like action, adventure, and horror have uniform profits across all distributors, it is therefore more probable to make profitable movies belonging to these genres.\nBig distributors like 20th century fox and universal studios usually manage to make profits out of any of the said genre regardless of the rating.\nif one cannot get hold of these big distributors, the best way to break through would be to make action movies and sell them all across small distributors.\n\n\n\nThe company that had started out as “Comedy Spread” was doing wonders just a decade ago. Their light-hearted films and rom-com hits had audiences laughing all the way to the box office. However, times have changed now. People prefer action over drama and comedy (I can’t seem to understand why). With every passing year, their profits from action-packed blockbusters soared. It’s as if audiences crave the thrill of explosions, chases, and stunts more than ever. “Comedy Spread” finds itself at a crossroads—will they change themselves to survive in this market, or will they stick to their roots, hoping the world rekindles its love for a good laugh? Only time will tell."
  },
  {
    "objectID": "posts/Aish-day-7/index.html",
    "href": "posts/Aish-day-7/index.html",
    "title": "Day-7",
    "section": "",
    "text": "Inference for Two Independent Means\n\n“To be nobody but myself – in a world which is doing its best, night and day, to make you everybody else – means to fight the hardest battle which any human being can fight, and never stop fighting.”\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(mosaic) # Our go-to package\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(ggformula)\nlibrary(infer) # An alternative package for inference using tidy data\n\n\nAttaching package: 'infer'\n\nThe following objects are masked from 'package:mosaic':\n\n    prop_test, t_test\n\nlibrary(broom) # Clean test results in tibble form\nlibrary(skimr) # data inspection\n\n\nAttaching package: 'skimr'\n\nThe following object is masked from 'package:mosaic':\n\n    n_missing\n\nlibrary(resampledata3) # Datasets from Chihara and Hesterberg's book\n\n\nAttaching package: 'resampledata3'\n\nThe following object is masked from 'package:datasets':\n\n    Titanic\n\nlibrary(openintro) # datasets\n\nLoading required package: airports\nLoading required package: cherryblossom\nLoading required package: usdata\n\nAttaching package: 'openintro'\n\nThe following object is masked from 'package:mosaic':\n\n    dotPlot\n\nThe following objects are masked from 'package:lattice':\n\n    ethanol, lsegments\n\nlibrary(gt) # for tables\n\n\nAttaching package: 'gt'\n\nThe following object is masked from 'package:openintro':\n\n    sp500\n\nlibrary(patchwork) # Arranging Plots\nlibrary(ggprism) # Interesting Categorical Axes\nlibrary(supernova) # Beginner-Friendly ANOVA Tables\n\n\ndata(\"MathAnxiety\",package = \"resampledata\")\nMathAnxiety\n\n      Age Gender     Grade AMAS RCMAS Arith\n1   137.8    Boy Secondary    9    20     6\n2   140.7    Boy Secondary   18     8     6\n3   137.9   Girl Secondary   23    26     5\n4   142.8   Girl Secondary   19    18     7\n5   135.6    Boy Secondary   23    20     1\n6   135.0   Girl Secondary   27    33     1\n7   133.6    Boy Secondary   22    23     4\n8   139.3    Boy Secondary   17    11     7\n9   131.7   Girl Secondary   28    32     2\n10  134.8    Boy Secondary   20    30     6\n11  141.3    Boy Secondary   16    10     2\n12  158.0    Boy Secondary   20     4     5\n13  155.1    Boy Secondary   21    23     2\n14  132.7    Boy Secondary   36    26     6\n15  134.1    Boy Secondary   16    24     2\n16  137.9    Boy Secondary   27    21     7\n17  132.6   Girl Secondary   28    30     2\n18  136.6   Girl Secondary   18    26     4\n19  146.7    Boy Secondary   29    18     7\n20  134.1   Girl Secondary   31    12     3\n21  135.4    Boy Secondary   21    15     8\n22  133.4    Boy Secondary   24    12     7\n23  137.6   Girl Secondary   17     8     7\n24  132.2    Boy Secondary   25    15     6\n25  141.5    Boy Secondary    9     3     3\n26  133.2    Boy Secondary   17    10     0\n27  133.6    Boy Secondary   37    30     3\n28  141.1    Boy Secondary   30    19     4\n29  143.4    Boy Secondary   21    18     4\n30  156.8    Boy Secondary   31    26     3\n31  144.4   Girl Secondary   35    21     4\n32  166.1    Boy Secondary   24    18     8\n33  144.2    Boy Secondary   21    16     2\n34  146.2   Girl Secondary   33    34     1\n35  151.2   Girl Secondary   27    14     5\n36  151.2    Boy Secondary   24    19     6\n37  143.6   Girl Secondary   20     7     3\n38  153.3    Boy Secondary    9    22     5\n39  152.6    Boy Secondary   25    23     0\n40  143.6   Girl Secondary   32    26     6\n41  151.2   Girl Secondary   19    10     1\n42  152.2    Boy Secondary   13    13     4\n43  161.5    Boy Secondary   29    30     4\n44  143.3   Girl Secondary   21    17     4\n45  151.3   Girl Secondary   23    15     2\n46  174.7    Boy Secondary   27    18     4\n47  146.2    Boy Secondary   20     4     4\n48  155.1    Boy Secondary   21    16     3\n49  149.1   Girl Secondary   20    21     4\n50  149.3   Girl Secondary   33    32     5\n51  144.5    Boy Secondary   21    32     1\n52  143.2   Girl Secondary   15    17     7\n53  150.3   Girl Secondary   25    33     1\n54  147.8    Boy Secondary   25    23     7\n55  145.0    Boy Secondary   12    14     3\n56  150.8   Girl Secondary   12    12     6\n57  145.8   Girl Secondary   28    17     4\n58  152.2    Boy Secondary   36    41     0\n59  145.6   Girl Secondary   13    13     4\n60  163.4   Girl Secondary   23    14     4\n61  158.6   Girl Secondary   25    17     3\n62  164.5    Boy Secondary   23    10     3\n63  154.3    Boy Secondary   13    16     4\n64  158.6    Boy Secondary   27    25     0\n65  159.4   Girl Secondary   16    18     5\n66  155.4    Boy Secondary   45    23     3\n67  164.3   Girl Secondary   25    23     0\n68  157.7    Boy Secondary   14    19     5\n69  162.8    Boy Secondary   25    25     4\n70  163.9    Boy Secondary   23     6     4\n71  157.3    Boy Secondary   28    15     0\n72  162.2    Boy Secondary   18     9     3\n73  162.3    Boy Secondary   17     8     5\n74  159.1   Girl Secondary   26    18     3\n75  160.6   Girl Secondary   18    15     3\n76  159.6    Boy Secondary   14     5     2\n77  162.0    Boy Secondary   14    11     6\n78  163.8    Boy Secondary   10    23     8\n79  175.9    Boy Secondary   16    18     6\n80  163.5   Girl Secondary   14    20     7\n81  169.1    Boy Secondary   11    15     7\n82  161.1    Boy Secondary   23    21     3\n83  160.0    Boy Secondary   22    23     7\n84  170.3    Boy Secondary   18    15     2\n85  162.6   Girl Secondary   15    13     5\n86  161.1    Boy Secondary   27    21     2\n87  155.9   Girl Secondary   31    23     3\n88  166.8    Boy Secondary   19     7     6\n89  178.9    Boy Secondary   20    27     5\n90  157.9    Boy Secondary   18    21     3\n91  157.7    Boy Secondary   15    11     5\n92  179.1    Boy Secondary   37    31     5\n93  160.6   Girl Secondary   14    23     8\n94  180.3    Boy Secondary   19     6     4\n95  165.5    Boy Secondary    9    27     0\n96  156.9    Boy Secondary   23    11     6\n97  132.1   Girl Secondary   21    23     7\n98  134.0    Boy Secondary   14     9     4\n99  143.1    Boy Secondary   12     8     6\n100 131.5    Boy Secondary   22     8     7\n101 135.4   Girl Secondary   25    15     4\n102 134.1    Boy Secondary   23    16     4\n103 141.2   Girl Secondary   33    29     4\n104 132.4    Boy Secondary   26    29     5\n105 132.4    Boy Secondary   24    15     8\n106 142.4    Boy Secondary   33    27     2\n107 132.7    Boy Secondary   22    15     8\n108 140.9    Boy Secondary   19    22     3\n109 142.2   Girl Secondary   25    34     4\n110 140.0    Boy Secondary   18    10     5\n111 136.3    Boy Secondary   20    28     5\n112 134.4   Girl Secondary   21     8     7\n113 136.6    Boy Secondary   29    23     6\n114 141.3   Girl Secondary   28    29     6\n115 132.3   Girl Secondary   19    14     5\n116 146.0   Girl Secondary   40    35     7\n117 138.8    Boy Secondary   16    19     5\n118 133.5   Girl Secondary   27    23     5\n119 140.6    Boy Secondary   34    22     1\n120 136.3    Boy Secondary   25    21     4\n121 136.4   Girl Secondary   28    14     5\n122 139.1    Boy Secondary   34    23     3\n123 133.3   Girl Secondary   22    20     5\n124 142.7   Girl Secondary   16    25     8\n125 152.7   Girl Secondary   14    17     6\n126 137.7   Girl Secondary   11    26     5\n127 145.5    Boy Secondary   31    24     1\n128 152.4    Boy Secondary   18     9     7\n129 158.8    Boy Secondary   30    15     2\n130 142.5    Boy Secondary   16    27     8\n131 156.7    Boy Secondary   34     1     2\n132 149.3    Boy Secondary   21    17     3\n133 144.4   Girl Secondary   27    25     6\n134 149.2    Boy Secondary   24    16     6\n135 147.9   Girl Secondary   22    16     7\n136 142.4   Girl Secondary   28    18     8\n137 153.3    Boy Secondary   23    21     5\n138 148.5    Boy Secondary   19    25     6\n139 158.7   Girl Secondary   29    28     2\n140 146.5    Boy Secondary   22    16     7\n141 142.4   Girl Secondary   28    19     2\n142 154.7    Boy Secondary   21    19     3\n143 167.4   Girl Secondary   35    25     1\n144 156.6    Boy Secondary   26    11     5\n145 155.1   Girl Secondary   21    17     7\n146 157.5   Girl Secondary   36    26     2\n147 151.1    Boy Secondary   14    10     1\n148 156.0   Girl Secondary   23    13     0\n149 155.3    Boy Secondary   20    15     1\n150 145.0   Girl Secondary   22    11     4\n151 149.6    Boy Secondary   21    22     6\n152 143.2   Girl Secondary   17    15     5\n153 152.5    Boy Secondary   18     7     8\n154 157.6    Boy Secondary   22    13     3\n155 152.9    Boy Secondary   12     1     2\n156 145.5   Girl Secondary   23     9     4\n157 163.1    Boy Secondary   22    20     1\n158 151.7    Boy Secondary   23    17     2\n159 145.2   Girl Secondary   33    32     3\n160 168.5    Boy Secondary   31    18     6\n161 148.6    Boy Secondary   22    26     5\n162 170.8    Boy Secondary   19    19     0\n163 164.1   Girl Secondary   25    26     1\n164 145.9    Boy Secondary   22    14     6\n165 148.7    Boy Secondary   12    12     5\n166 144.0   Girl Secondary   21    18     0\n167 150.6   Girl Secondary   19    17     6\n168 158.7    Boy Secondary   24     9     4\n169 157.4    Boy Secondary   18     6     7\n170 151.5    Boy Secondary   21    13     3\n171 159.5    Boy Secondary   18    13     7\n172 158.1    Boy Secondary   28    35     2\n173 173.3    Boy Secondary   20    10     7\n174 155.5    Boy Secondary   18    12     4\n175 158.2   Girl Secondary   17    15     7\n176 161.4   Girl Secondary   26    27     6\n177 162.3    Boy Secondary   27    14     3\n178 153.8    Boy Secondary   28    12     5\n179 161.0   Girl Secondary   21    16     5\n180 154.4   Girl Secondary   21    18     6\n181 163.4    Boy Secondary   15    12     6\n182 155.4   Girl Secondary   32    29     1\n183 162.2    Boy Secondary   12     8     7\n184 163.2    Boy Secondary   24    21     4\n185 160.5    Boy Secondary   12    38     4\n186 158.2    Boy Secondary   24    26     5\n187 167.0   Girl Secondary   20    19     1\n188 157.9   Girl Secondary   14    20     4\n189 156.9    Boy Secondary   19    36     5\n190 180.3   Girl Secondary   33    33     6\n191 164.5    Boy Secondary   26    22     5\n192 173.5   Girl Secondary   21    26     3\n193 159.8   Girl Secondary   18    10     7\n194 160.5    Boy Secondary   10    10     7\n195 157.2   Girl Secondary   22     4     3\n196 167.2    Boy Secondary   11     9     8\n197 187.5    Boy Secondary   26    13     0\n198 179.7    Boy Secondary   29    25     6\n199  97.1    Boy   Primary    9     9     7\n200 102.7   Girl   Primary   21    10     4\n201  96.4    Boy   Primary   26    23     1\n202  97.4    Boy   Primary   18    30     5\n203  97.4   Girl   Primary   23    25     3\n204  94.7   Girl   Primary   22    38     1\n205  93.1    Boy   Primary   16    20     4\n206 102.8    Boy   Primary   19    22     4\n207  94.8    Boy   Primary   14    17     7\n208  83.7   Girl   Primary   26    23     3\n209  92.7   Girl   Primary   10    12     3\n210 104.3    Boy   Primary   18     3     6\n211 102.3    Boy   Primary   18     5     1\n212 102.7   Girl   Primary   29    19     7\n213  95.9    Boy   Primary    9    34     1\n214  92.5   Girl   Primary   28    21     5\n215  99.2    Boy   Primary   28    30     6\n216 100.9   Girl   Primary   35    22     3\n217  91.0   Girl   Primary   17    13     4\n218 106.3    Boy   Primary   31    12     7\n219 113.5   Girl   Primary   29    20     7\n220 106.6   Girl   Primary   19    18     0\n221 111.4   Girl   Primary   10    27     7\n222 104.2   Girl   Primary   38    24     7\n223 105.0   Girl   Primary   17    15     3\n224 107.3   Girl   Primary   17    26     8\n225 100.3    Boy   Primary   36    14     7\n226 115.0    Boy   Primary   31    28     6\n227 112.9   Girl   Primary   13    15     7\n228 114.9   Girl   Primary   11    21     0\n229 118.7   Girl   Primary   20    27     5\n230 110.4   Girl   Primary   13    17     4\n231 107.0   Girl   Primary   30    27     8\n232 106.2    Boy   Primary   18    20     8\n233 112.7    Boy   Primary   27     9     7\n234 112.2    Boy   Primary   33    28     7\n235 120.8    Boy   Primary   21    21     4\n236 121.8   Girl   Primary   21     8     5\n237 115.0    Boy   Primary   21    23     7\n238 123.7   Girl   Primary   35    22     8\n239 116.9   Girl   Primary   24     9     3\n240 119.3    Boy   Primary   14    17     4\n241 125.2    Boy   Primary   20    16     3\n242 127.6    Boy   Primary   22    14     8\n243 120.0    Boy   Primary   29    29     2\n244 120.0    Boy   Primary   21    20     4\n245 127.2    Boy   Primary   25    25     7\n246 123.7   Girl   Primary   22    21     8\n247 115.0   Girl   Primary   23    14     7\n248 115.0   Girl   Primary   23    23     5\n249 125.4   Girl   Primary   21    24     7\n250 122.2    Boy   Primary   20    10     7\n251 125.3    Boy   Primary   15     7     6\n252 115.4   Girl   Primary   30    26     3\n253 128.2   Girl   Primary   26    11     7\n254 120.6    Boy   Primary   31    22     3\n255 121.4   Girl   Primary   27    28     0\n256 113.9    Boy   Primary   16    11     5\n257 117.8   Girl   Primary   23    24     4\n258 116.1   Girl   Primary   23    23     5\n259  94.0    Boy   Primary   13    15     5\n260  94.7   Girl   Primary   12    24     3\n261 101.0   Girl   Primary   11    19     5\n262 100.9   Girl   Primary   24    20     6\n263  94.9    Boy   Primary   11    15     6\n264 108.0    Boy   Primary   22     9     8\n265 109.3    Boy   Primary   33    25     7\n266 109.1   Girl   Primary   28    20     7\n267 116.1    Boy   Primary   18    15     8\n268 109.3    Boy   Primary   31    22     7\n269 112.6    Boy   Primary   26    25     5\n270 107.6    Boy   Primary   26    24     7\n271 111.1   Girl   Primary   27    23     6\n272 111.0   Girl   Primary   32    32     6\n273 105.6    Boy   Primary   29    19     8\n274 117.3   Girl   Primary   28    20     8\n275 110.7   Girl   Primary   32    31     8\n276 112.4   Girl   Primary   20    24     8\n277 106.4    Boy   Primary   26    29     8\n278 122.3    Boy   Primary   20    28     4\n279 127.1   Girl   Primary   27    27     5\n280 118.5   Girl   Primary   23     7     5\n281 126.2    Boy   Primary   22     8     8\n282 125.1    Boy   Primary   31    20     1\n283 120.4    Boy   Primary   13     5     8\n284 126.5    Boy   Primary   21    13     7\n285 125.0    Boy   Primary   15     5     4\n286 115.7    Boy   Primary   13     4     5\n287 126.1    Boy   Primary   20    13     4\n288 106.9    Boy   Primary   14    24     6\n289  97.3   Girl   Primary   27    27     5\n290  99.5    Boy   Primary   13     7     5\n291 105.9    Boy   Primary   16    15     6\n292  93.8    Boy   Primary   24    20     6\n293 106.0    Boy   Primary   19    21     4\n294 105.9   Girl   Primary   19     4     6\n295  98.0    Boy   Primary   21    26     4\n296  93.8   Girl   Primary   35    33     6\n297  95.5    Boy   Primary   17    23     6\n298  95.5    Boy   Primary   16    31     5\n299 106.1   Girl   Primary   14    19     6\n300 105.9   Girl   Primary   24    25     6\n301  96.8    Boy   Primary   18    23     6\n302  95.2   Girl   Primary   15    23     2\n303  97.3    Boy   Primary   17    22     5\n304 101.7   Girl   Primary   23    24     4\n305 101.5   Girl   Primary   31    12     3\n306 105.9   Girl   Primary   26    22     5\n307 102.7   Girl   Primary   28    17     4\n308 102.3    Boy   Primary   33    28     5\n309  96.3   Girl   Primary   28    18     5\n310  98.9    Boy   Primary   18    10     6\n311  95.9   Girl   Primary   33    23     3\n312 101.3   Girl   Primary   24    21     6\n313 100.4   Girl   Primary   22    22     6\n314 101.7    Boy   Primary   11    22     5\n315  97.9   Girl   Primary   22    31     5\n316 101.1   Girl   Primary   32    31     5\n317  95.1   Girl   Primary   29    34     5\n318 102.5   Girl   Primary   24    25     6\n319 102.1    Boy   Primary   22    22     6\n320 103.1   Girl   Primary   27    15     8\n321 105.0    Boy   Primary   11    14     8\n322 104.5    Boy   Primary   26    22     8\n323 103.6   Girl   Primary   25    18     5\n324 104.9   Girl   Primary   26    34     8\n325 102.7    Boy   Primary   22    19     5\n326 104.0    Boy   Primary   25    25     6\n327  97.7   Girl   Primary   14    14     7\n328 106.1    Boy   Primary   18    20     7\n329  96.2   Girl   Primary   13    27     7\n330  97.9    Boy   Primary   22    25     4\n331 105.4   Girl   Primary   22    22     8\n332  97.5   Girl   Primary   30    22     6\n333 101.7   Girl   Primary   14    14     7\n334 104.5    Boy   Primary   21    18     8\n335  96.3   Girl   Primary   16    14     7\n336  98.6    Boy   Primary   29    28     7\n337  98.6   Girl   Primary   38    28     6\n338 105.0    Boy   Primary   18    20     8\n339  97.9    Boy   Primary   26    22     7\n340  99.5   Girl   Primary   38    17     3\n341  98.4    Boy   Primary   30    20     5\n342 106.1    Boy   Primary   23    27     6\n343  97.7   Girl   Primary   26     3     6\n344  98.1   Girl   Primary   27    13     6\n345  95.2   Girl   Primary   17    19     4\n346  96.6   Girl   Primary   36    22     3\n347 103.7   Girl   Primary   29    23     1\n348  97.1    Boy   Primary    9     7     6\n349  99.1   Girl   Primary   22    12     3\n350 100.5    Boy   Primary    9     8     8\n351 105.8   Girl   Primary   31    29     5\n352 103.7   Girl   Primary   19     9     6\n353 101.8    Boy   Primary   19    28     6\n354 112.0    Boy   Primary   26    29     7\n355 110.1   Girl   Primary   17    25     8\n356 113.6   Girl   Primary   27    10     8\n357 118.6   Girl   Primary   24    15     4\n358 117.9   Girl   Primary   29    32     8\n359 107.5   Girl   Primary   22    20     7\n360 118.3    Boy   Primary   20    20     7\n361 112.4   Girl   Primary   28    19     8\n362 113.9    Boy   Primary   18    15     8\n363 108.5    Boy   Primary   27    28     8\n364 114.1    Boy   Primary   11     8     8\n365 115.7   Girl   Primary   18    21     6\n366 113.1   Girl   Primary   30    34     7\n367 117.2    Boy   Primary   20    21     6\n368 111.2   Girl   Primary   11     8     8\n369 118.0    Boy   Primary   24    31     8\n370 114.4   Girl   Primary   18    10     6\n371 115.5    Boy   Primary   17    16     8\n372 118.7   Girl   Primary   22    13     8\n373 115.6    Boy   Primary   31    26     8\n374 108.1   Girl   Primary   16     4     5\n375 111.3   Girl   Primary   14    15     7\n376 117.8   Girl   Primary   23    24     2\n377 112.1    Boy   Primary   11    21     7\n378 112.8   Girl   Primary   19    14     5\n379 107.2    Boy   Primary   19    10     3\n380 111.3   Girl   Primary   19    23     5\n381 106.7   Girl   Primary   29    25     8\n382 107.7   Girl   Primary   25    30     7\n383 106.5   Girl   Primary   20    15     6\n384 117.6    Boy   Primary   15    21     8\n385 115.6    Boy   Primary   13    28     8\n386 115.3   Girl   Primary   25    17     7\n387 107.7    Boy   Primary   29    24     5\n388 109.0    Boy   Primary   13     6     6\n389 117.0   Girl   Primary   20     9     8\n390 116.5    Boy   Primary   12    13     8\n391 115.2    Boy   Primary   32    28     6\n392 110.8   Girl   Primary   18    12     8\n393 116.9    Boy   Primary   23    17     6\n394 117.4   Girl   Primary   33    24     7\n395 118.3   Girl   Primary   28    14     7\n396 114.1    Boy   Primary   16    15     4\n397 112.2    Boy   Primary   17    15     7\n398 114.4    Boy   Primary   24    11     8\n399 117.6   Girl   Primary   29    28     8\n400 113.0    Boy   Primary   19    13     7\n401 110.9   Girl   Primary   31    21     6\n402 109.0   Girl   Primary   28    29     6\n403 125.9    Boy   Primary   25    25     8\n404 126.9    Boy   Primary   20    15     8\n405 124.7    Boy   Primary   15    15     7\n406 122.1   Girl   Primary   20    20     8\n407 123.4    Boy   Primary   21    28     7\n408 120.1   Girl   Primary   21    18     3\n409 124.4   Girl   Primary   25    33     8\n410 130.9    Boy   Primary   21    18     8\n411 130.1    Boy   Primary   24    12     8\n412 127.7    Boy   Primary   11    18     7\n413 126.1    Boy   Primary   29    19     5\n414 125.0    Boy   Primary   23    18     7\n415 121.7   Girl   Primary   18    11     7\n416 125.2    Boy   Primary   21    16     5\n417 126.6    Boy   Primary   27    25     3\n418 120.3    Boy   Primary   31    38     4\n419 122.1   Girl   Primary   16    27     8\n420 127.7    Boy   Primary   27    33     7\n421 118.9    Boy   Primary   11    15     8\n422 120.0   Girl   Primary   34    29     4\n423 120.0    Boy   Primary   33    25     6\n424 121.3   Girl   Primary   20    16     8\n425 135.1    Boy   Primary   12    17     1\n426 117.4   Girl   Primary   26    20     3\n427 123.3   Girl   Primary   26     6     4\n428 129.9    Boy   Primary   11    15     5\n429 126.9    Boy   Primary   19    25     5\n430 119.8    Boy   Primary   20    14     7\n431 127.9   Girl   Primary   34    19     6\n432 128.8    Boy   Primary   22    19     6\n433 119.8   Girl   Primary   12    26     7\n434 123.2   Girl   Primary   19    17     4\n435 125.1   Girl   Primary   23    11     8\n436 129.4    Boy   Primary   25    19     0\n437 124.9    Boy   Primary   21     5     8\n438 127.3   Girl   Primary   19    18     7\n439 122.0   Girl   Primary   25    14     7\n440 117.0   Girl   Primary   26    29     6\n441 128.4   Girl   Primary    9    13     8\n442 119.7   Girl   Primary   27    26     7\n443 130.9   Girl   Primary   17    20     7\n444 121.2    Boy   Primary   33    17     8\n445 115.4   Girl   Primary   14    25     2\n446 128.4   Girl   Primary   24    29     7\n447 121.0    Boy   Primary   20    18     8\n448 129.9    Boy   Primary   26    19     7\n449 130.9    Boy   Primary   22    20     8\n450 122.3   Girl   Primary   36    26     7\n451 123.5   Girl   Primary   25    17     8\n452 119.6   Girl   Primary   23    13     5\n453 118.5   Girl   Primary    9     9     8\n454 128.6    Boy   Primary   28    20     6\n455 123.1   Girl   Primary   14     7     7\n456 119.3   Girl   Primary   25    16     7\n457 128.3   Girl   Primary   19    13     7\n458 125.9    Boy   Primary   25    17     8\n459 130.8   Girl   Primary   14    20     8\n460   3.7   Girl   Primary   11     5     8\n461 125.7    Boy   Primary   22     5     6\n462 107.8   Girl   Primary   26    20     7\n463 113.4    Boy   Primary   28    25     7\n464 117.7    Boy   Primary   24     8     7\n465 115.3   Girl   Primary   20    24     7\n466 117.4   Girl   Primary   15    17     8\n467 111.2    Boy   Primary   18     9     6\n468 115.4   Girl   Primary   22    29     8\n469 110.2   Girl   Primary   29    35     6\n470 108.9    Boy   Primary   31    30     8\n471 112.1   Girl   Primary   24    29     8\n472 113.4    Boy   Primary   16    25     7\n473 107.3   Girl   Primary   29    28     6\n474 130.1   Girl   Primary    9     8     7\n475 123.7    Boy   Primary   27    19     6\n476 123.4   Girl   Primary   23    25     7\n477 130.7   Girl   Primary   26    20     8\n478 125.2   Girl   Primary   19    21     7\n479 129.5   Girl   Primary   23    21     7\n480 122.0   Girl   Primary   19    30     6\n481 126.2    Boy   Primary   29    31     3\n482 120.0    Boy   Primary   30    22     7\n483 100.9   Girl   Primary   28    26     5\n484  98.7    Boy   Primary   20     8     4\n485 102.7    Boy   Primary   24    33     5\n486  95.7   Girl   Primary   26    27     5\n487 102.5    Boy   Primary   25    20     6\n488  97.1    Boy   Primary   23    31     6\n489 103.5    Boy   Primary   30    24     5\n490  97.1    Boy   Primary   22    23     2\n491  99.3   Girl   Primary   28    32     6\n492  97.4    Boy   Primary   13    18     6\n493 101.9    Boy   Primary   26    17     3\n494  97.4    Boy   Primary   17     9     6\n495  98.7   Girl   Primary   27    26     4\n496 103.5    Boy   Primary   32    28     5\n497 104.5   Girl   Primary   25    25     6\n498 102.7    Boy   Primary   21    11     6\n499 103.1    Boy   Primary   22    22     6\n500 102.1   Girl   Primary   23    18     6\n501 101.2    Boy   Primary   22    26     5\n502 105.8   Girl   Primary   19    14     7\n503  96.0   Girl   Primary   18    19     7\n504 102.1    Boy   Primary   12    13     8\n505 106.1    Boy   Primary    4    18     5\n506 111.9    Boy   Primary   20    17     7\n507 100.1    Boy   Primary   18    16     3\n508 101.2    Boy   Primary   31    35     4\n509  95.8   Girl   Primary   27    30     6\n510  96.1   Girl   Primary   23    22     4\n511  95.8    Boy   Primary   29    29     4\n512 104.5    Boy   Primary   29    18     7\n513 100.9    Boy   Primary   15    14     7\n514  95.3    Boy   Primary   29    24     8\n515 103.3   Girl   Primary   20    16     8\n516  99.1   Girl   Primary   19    22     8\n517 102.1    Boy   Primary   19    13     5\n518 102.1    Boy   Primary   20    25     4\n519 103.2    Boy   Primary   17    21     4\n520  97.4    Boy   Primary   24    13     3\n521 101.1   Girl   Primary    9    12     4\n522 105.4    Boy   Primary   23    22     5\n523 105.4    Boy   Primary   20    25     6\n524 106.0    Boy   Primary   19    13     7\n525 105.3   Girl   Primary   16    19     3\n526 101.8    Boy   Primary   19    17     5\n527 104.3   Girl   Primary    9    28     5\n528  98.4   Girl   Primary   21    13     6\n529  96.3   Girl   Primary   29    27     3\n530  95.7    Boy   Primary    9    23     4\n531 106.0   Girl   Primary   15    27     6\n532 105.4   Girl   Primary   23    18     5\n533  99.1   Girl   Primary   19    33     2\n534 104.3   Girl   Primary   21    30     3\n535 105.4    Boy   Primary   22    12     6\n536  96.0    Boy   Primary    9    10     5\n537  96.3    Boy   Primary   24    13     4\n538 106.9    Boy   Primary   22    24     5\n539  98.0   Girl   Primary    9    10     5\n540 105.5   Girl   Primary    9    19     5\n541 117.9    Boy   Primary   18    15     8\n542 118.4   Girl   Primary   21    26     7\n543 110.7   Girl   Primary   26    17     6\n544 113.4    Boy   Primary   28    17     8\n545 110.3   Girl   Primary   31    34     1\n546 108.8    Boy   Primary   26    28     2\n547 110.7   Girl   Primary   21    27     8\n548 119.1   Girl   Primary   35    28     1\n549 107.5   Girl   Primary   26    14     4\n550 112.7   Girl   Primary   18    15     8\n551 116.2    Boy   Primary   26    24     7\n552 113.4   Girl   Primary   15    16     5\n553 108.7    Boy   Primary   19    23     1\n554 117.8   Girl   Primary   29    29     4\n555 109.6   Girl   Primary   17    18     3\n556 110.4    Boy   Primary   13     8     7\n557 111.2    Boy   Primary   24    14     5\n558 113.3    Boy   Primary   15    12     7\n559 112.7    Boy   Primary   17     6     6\n560 109.0   Girl   Primary   29    23     7\n561 110.0   Girl   Primary   16    23     6\n562 108.3    Boy   Primary   22    22     8\n563 112.9    Boy   Primary   25    13     6\n564 107.9    Boy   Primary   16    23     6\n565 110.1   Girl   Primary   25    21     6\n566 121.1    Boy   Primary   13    10     3\n567 123.2   Girl   Primary   26    30     4\n568 128.5    Boy   Primary   17    19     8\n569 124.7   Girl   Primary   23    14     5\n570 130.1    Boy   Primary   12    14     6\n571 122.0    Boy   Primary   12    16     8\n572 130.8   Girl   Primary   25    13     6\n573 122.9    Boy   Primary   13    23     6\n574 120.8    Boy   Primary   21     8     6\n575 123.2    Boy   Primary   21    19     5\n576 123.9    Boy   Primary   14    20     7\n577 128.6   Girl   Primary   19    19     7\n578 127.7    Boy   Primary   18    11     6\n579 122.9    Boy   Primary   18    10     5\n580 129.2   Girl   Primary   24    16     6\n581 120.0   Girl   Primary   16    14     6\n582 122.9   Girl   Primary   19    10     8\n583 125.7   Girl   Primary   20    26     7\n584 121.0   Girl   Primary    9    27     8\n585 123.2    Boy   Primary   20    12     8\n586 124.2    Boy   Primary   26     8     7\n587 126.5   Girl   Primary   29    37     6\n588 129.5   Girl   Primary   21    12     7\n589 126.9    Boy   Primary   26    20     3\n590 128.6    Boy   Primary   17    17     7\n591 122.3    Boy   Primary   15    13     8\n592 120.1    Boy   Primary   24    17     3\n593 128.0   Girl   Primary   34    22     6\n594 126.3   Girl   Primary   24    31     5\n595 126.2    Boy   Primary   27    11     5\n596 124.9   Girl   Primary   23     8     5\n597 125.3    Boy   Primary   27    11     5\n598 127.6   Girl   Primary   30    20     6\n599 125.6   Girl   Primary   24    31     4\n\nMathAnxiety_inspect &lt;- inspect(MathAnxiety)\nMathAnxiety_inspect$categorical\n\n# A tibble: 2 × 6\n  name   class  levels     n missing distribution                               \n  &lt;chr&gt;  &lt;chr&gt;   &lt;int&gt; &lt;int&gt;   &lt;int&gt; &lt;chr&gt;                                      \n1 Gender factor      2   599       0 \"Boy (53.9%), Girl (46.1%)                …\n2 Grade  factor      2   599       0 \"Primary (66.9%), Secondary (33.1%)       …\n\nMathAnxiety_inspect$quantitative\n\n# A tibble: 4 × 11\n  name  class     min    Q1 median    Q3   max   mean    sd     n missing\n* &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;   &lt;int&gt;\n1 Age   numeric   3.7  106.   121. 142.   188. 125.   22.3    599       0\n2 AMAS  integer   4     18     22   26.5   45   22.0   6.60   599       0\n3 RCMAS integer   1     14     19   25     41   19.2   7.57   599       0\n4 Arith integer   0      4      6    7      8    5.30  2.11   599       0\n\n\n\nMathAnxiety %&gt;%\n  gf_density(\n    ~ AMAS,\n    fill = ~ Gender,\n    alpha = 0.5,\n    title = \"Math Anxiety Score Densities\",\n    subtitle = \"Boys vs Girls\"\n  )\n\n\n\n\n\n\n\n##\nMathAnxiety %&gt;%\n  gf_boxplot(\n    AMAS ~ Gender,\n    fill = ~ Gender,\n    alpha = 0.5,\n    title = \"Math Anxiety Score Box Plots\",\n    subtitle = \"Boys vs Girls\"\n  ) \n\n\n\n\n\n\n\n##\nMathAnxiety %&gt;% count(Gender)\n\n  Gender   n\n1    Boy 323\n2   Girl 276\n\nMathAnxiety %&gt;% \n  group_by(Gender) %&gt;% \n  summarise(mean = mean(AMAS))\n\n# A tibble: 2 × 2\n  Gender  mean\n  &lt;fct&gt;  &lt;dbl&gt;\n1 Boy     21.2\n2 Girl    22.9\n\n\n\n\nComparing Multiple Means with ANOVA\n\nfrogs_orig &lt;- read_csv(\"../../data/frogs.csv\")\n\nRows: 60 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (4): Frogspawn sample id, Temperature13, Temperature18, Temperature25\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nfrogs_orig\n\n# A tibble: 60 × 4\n   `Frogspawn sample id` Temperature13 Temperature18 Temperature25\n                   &lt;dbl&gt;         &lt;dbl&gt;         &lt;dbl&gt;         &lt;dbl&gt;\n 1                     1            24            NA            NA\n 2                     2            NA            21            NA\n 3                     3            NA            NA            18\n 4                     4            26            NA            NA\n 5                     5            NA            22            NA\n 6                     6            NA            NA            14\n 7                     7            27            NA            NA\n 8                     8            NA            22            NA\n 9                     9            NA            NA            15\n10                    10            27            NA            NA\n# ℹ 50 more rows"
  },
  {
    "objectID": "posts/children-hearingloss/index.html",
    "href": "posts/children-hearingloss/index.html",
    "title": "Dataset-3: Hearing loss in children",
    "section": "",
    "text": "Let’s set up our document with libraries.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(skimr)\n\n\nAttaching package: 'skimr'\n\nThe following object is masked from 'package:mosaic':\n\n    n_missing\n\nlibrary(ggformula)\n\nwe shall now import our dataset.\n\nome &lt;- read_csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/OME.csv\")\n\nRows: 1097 Columns: 8\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): OME, Noise\ndbl (6): rownames, ID, Age, Loud, Correct, Trials\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nglimpse(ome)\n\nRows: 1,097\nColumns: 8\n$ rownames &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18…\n$ ID       &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3…\n$ Age      &lt;dbl&gt; 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 60, 60, 60, 60, 60, 6…\n$ OME      &lt;chr&gt; \"low\", \"low\", \"low\", \"low\", \"low\", \"low\", \"low\", \"low\", \"low\"…\n$ Loud     &lt;dbl&gt; 35, 35, 40, 40, 45, 45, 50, 50, 55, 55, 35, 35, 40, 40, 45, 4…\n$ Noise    &lt;chr&gt; \"coherent\", \"incoherent\", \"coherent\", \"incoherent\", \"coherent…\n$ Correct  &lt;dbl&gt; 1, 4, 0, 1, 2, 2, 3, 4, 3, 2, 2, 3, 1, 1, 1, 5, 4, 2, 3, 4, 4…\n$ Trials   &lt;dbl&gt; 4, 5, 3, 1, 4, 2, 3, 4, 3, 2, 4, 4, 4, 1, 2, 5, 4, 2, 3, 4, 6…\n\nprint(ome)\n\n# A tibble: 1,097 × 8\n   rownames    ID   Age OME    Loud Noise      Correct Trials\n      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;        &lt;dbl&gt;  &lt;dbl&gt;\n 1        1     1    30 low      35 coherent         1      4\n 2        2     1    30 low      35 incoherent       4      5\n 3        3     1    30 low      40 coherent         0      3\n 4        4     1    30 low      40 incoherent       1      1\n 5        5     1    30 low      45 coherent         2      4\n 6        6     1    30 low      45 incoherent       2      2\n 7        7     1    30 low      50 coherent         3      3\n 8        8     1    30 low      50 incoherent       4      4\n 9        9     1    30 low      55 coherent         3      3\n10       10     1    30 low      55 incoherent       2      2\n# ℹ 1,087 more rows\n\n\n\nskim(ome)\n\n\nData summary\n\n\nName\nome\n\n\nNumber of rows\n1097\n\n\nNumber of columns\n8\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nnumeric\n6\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nOME\n0\n1\n3\n4\n0\n3\n0\n\n\nNoise\n0\n1\n8\n10\n0\n2\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nrownames\n0\n1\n549.00\n316.82\n1\n275\n549\n823\n1097\n▇▇▇▇▇\n\n\nID\n0\n1\n53.44\n28.05\n1\n31\n59\n75\n100\n▅▆▆▇▆\n\n\nAge\n0\n1\n28.52\n15.41\n7\n18\n30\n30\n60\n▂▃▇▁▂\n\n\nLoud\n0\n1\n45.38\n7.29\n35\n40\n45\n50\n65\n▇▅▅▅▁\n\n\nCorrect\n0\n1\n2.96\n2.09\n0\n1\n3\n4\n13\n▇▆▁▁▁\n\n\nTrials\n0\n1\n3.82\n2.20\n1\n2\n3\n5\n14\n▇▆▁▁▁\n\n\n\n\n\n\ninspect(ome)\n\n\ncategorical variables:  \n   name     class levels    n missing\n1   OME character      3 1097       0\n2 Noise character      2 1097       0\n                                   distribution\n1 low (48.7%), N/A (35.1%), high (16.2%)       \n2 coherent (50.3%), incoherent (49.7%)         \n\nquantitative variables:  \n      name   class min  Q1 median  Q3  max       mean         sd    n missing\n1 rownames numeric   1 275    549 823 1097 549.000000 316.820927 1097       0\n2       ID numeric   1  31     59  75  100  53.443938  28.045173 1097       0\n3      Age numeric   7  18     30  30   60  28.519599  15.407359 1097       0\n4     Loud numeric  35  40     45  50   65  45.378304   7.285122 1097       0\n5  Correct numeric   0   1      3   4   13   2.963537   2.090241 1097       0\n6   Trials numeric   1   2      3   5   14   3.824977   2.199949 1097       0"
  },
  {
    "objectID": "posts/children-hearingloss/index.html#hearing-loss-in-children",
    "href": "posts/children-hearingloss/index.html#hearing-loss-in-children",
    "title": "Dataset-3: Hearing loss in children",
    "section": "",
    "text": "Let’s set up our document with libraries.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(skimr)\n\n\nAttaching package: 'skimr'\n\nThe following object is masked from 'package:mosaic':\n\n    n_missing\n\nlibrary(ggformula)\n\nwe shall now import our dataset.\n\nome &lt;- read_csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/OME.csv\")\n\nRows: 1097 Columns: 8\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): OME, Noise\ndbl (6): rownames, ID, Age, Loud, Correct, Trials\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nglimpse(ome)\n\nRows: 1,097\nColumns: 8\n$ rownames &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18…\n$ ID       &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3…\n$ Age      &lt;dbl&gt; 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 60, 60, 60, 60, 60, 6…\n$ OME      &lt;chr&gt; \"low\", \"low\", \"low\", \"low\", \"low\", \"low\", \"low\", \"low\", \"low\"…\n$ Loud     &lt;dbl&gt; 35, 35, 40, 40, 45, 45, 50, 50, 55, 55, 35, 35, 40, 40, 45, 4…\n$ Noise    &lt;chr&gt; \"coherent\", \"incoherent\", \"coherent\", \"incoherent\", \"coherent…\n$ Correct  &lt;dbl&gt; 1, 4, 0, 1, 2, 2, 3, 4, 3, 2, 2, 3, 1, 1, 1, 5, 4, 2, 3, 4, 4…\n$ Trials   &lt;dbl&gt; 4, 5, 3, 1, 4, 2, 3, 4, 3, 2, 4, 4, 4, 1, 2, 5, 4, 2, 3, 4, 6…\n\nprint(ome)\n\n# A tibble: 1,097 × 8\n   rownames    ID   Age OME    Loud Noise      Correct Trials\n      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;        &lt;dbl&gt;  &lt;dbl&gt;\n 1        1     1    30 low      35 coherent         1      4\n 2        2     1    30 low      35 incoherent       4      5\n 3        3     1    30 low      40 coherent         0      3\n 4        4     1    30 low      40 incoherent       1      1\n 5        5     1    30 low      45 coherent         2      4\n 6        6     1    30 low      45 incoherent       2      2\n 7        7     1    30 low      50 coherent         3      3\n 8        8     1    30 low      50 incoherent       4      4\n 9        9     1    30 low      55 coherent         3      3\n10       10     1    30 low      55 incoherent       2      2\n# ℹ 1,087 more rows\n\n\n\nskim(ome)\n\n\nData summary\n\n\nName\nome\n\n\nNumber of rows\n1097\n\n\nNumber of columns\n8\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nnumeric\n6\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nOME\n0\n1\n3\n4\n0\n3\n0\n\n\nNoise\n0\n1\n8\n10\n0\n2\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nrownames\n0\n1\n549.00\n316.82\n1\n275\n549\n823\n1097\n▇▇▇▇▇\n\n\nID\n0\n1\n53.44\n28.05\n1\n31\n59\n75\n100\n▅▆▆▇▆\n\n\nAge\n0\n1\n28.52\n15.41\n7\n18\n30\n30\n60\n▂▃▇▁▂\n\n\nLoud\n0\n1\n45.38\n7.29\n35\n40\n45\n50\n65\n▇▅▅▅▁\n\n\nCorrect\n0\n1\n2.96\n2.09\n0\n1\n3\n4\n13\n▇▆▁▁▁\n\n\nTrials\n0\n1\n3.82\n2.20\n1\n2\n3\n5\n14\n▇▆▁▁▁\n\n\n\n\n\n\ninspect(ome)\n\n\ncategorical variables:  \n   name     class levels    n missing\n1   OME character      3 1097       0\n2 Noise character      2 1097       0\n                                   distribution\n1 low (48.7%), N/A (35.1%), high (16.2%)       \n2 coherent (50.3%), incoherent (49.7%)         \n\nquantitative variables:  \n      name   class min  Q1 median  Q3  max       mean         sd    n missing\n1 rownames numeric   1 275    549 823 1097 549.000000 316.820927 1097       0\n2       ID numeric   1  31     59  75  100  53.443938  28.045173 1097       0\n3      Age numeric   7  18     30  30   60  28.519599  15.407359 1097       0\n4     Loud numeric  35  40     45  50   65  45.378304   7.285122 1097       0\n5  Correct numeric   0   1      3   4   13   2.963537   2.090241 1097       0\n6   Trials numeric   1   2      3   5   14   3.824977   2.199949 1097       0"
  },
  {
    "objectID": "posts/children-hearingloss/index.html#data-dictionary",
    "href": "posts/children-hearingloss/index.html#data-dictionary",
    "title": "Dataset-3: Hearing loss in children",
    "section": "Data Dictionary",
    "text": "Data Dictionary\n\nQualitative Variables\n\nOME (chr): Otitis Media with Effusion, i.e. fluid in the middle ear\nNoise(chr): condition of noise present during the trials.\n\n\n\nQuantitative Variables\n\nrownames (dbl): serial number of the row.\nID (dbl): ? [identifier I suppose]\nAge (dbl): age of the individual.\nLoud (dbl): loudness level.\nCorrect (dbl): number of correct responses.\nTrials (dbl): number of trials.\n\nTarget Variable -\nPredictor variable -\nNow, I will mutate some variables and turn them into factors.\n\nome_modified &lt;- ome %&gt;% \n  mutate(\n    ID = as.factor(ID),\n    OME = as.factor(OME),\n    Noise = as.factor(Noise),\n    Loud = as.factor(Loud)\n  )\n\nglimpse(ome_modified)\n\nRows: 1,097\nColumns: 8\n$ rownames &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18…\n$ ID       &lt;fct&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3…\n$ Age      &lt;dbl&gt; 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 60, 60, 60, 60, 60, 6…\n$ OME      &lt;fct&gt; low, low, low, low, low, low, low, low, low, low, low, low, l…\n$ Loud     &lt;fct&gt; 35, 35, 40, 40, 45, 45, 50, 50, 55, 55, 35, 35, 40, 40, 45, 4…\n$ Noise    &lt;fct&gt; coherent, incoherent, coherent, incoherent, coherent, incoher…\n$ Correct  &lt;dbl&gt; 1, 4, 0, 1, 2, 2, 3, 4, 3, 2, 2, 3, 1, 1, 1, 5, 4, 2, 3, 4, 4…\n$ Trials   &lt;dbl&gt; 4, 5, 3, 1, 4, 2, 3, 4, 3, 2, 4, 4, 4, 1, 2, 5, 4, 2, 3, 4, 6…\n\nprint(ome_modified)\n\n# A tibble: 1,097 × 8\n   rownames ID      Age OME   Loud  Noise      Correct Trials\n      &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt;        &lt;dbl&gt;  &lt;dbl&gt;\n 1        1 1        30 low   35    coherent         1      4\n 2        2 1        30 low   35    incoherent       4      5\n 3        3 1        30 low   40    coherent         0      3\n 4        4 1        30 low   40    incoherent       1      1\n 5        5 1        30 low   45    coherent         2      4\n 6        6 1        30 low   45    incoherent       2      2\n 7        7 1        30 low   50    coherent         3      3\n 8        8 1        30 low   50    incoherent       4      4\n 9        9 1        30 low   55    coherent         3      3\n10       10 1        30 low   55    incoherent       2      2\n# ℹ 1,087 more rows\n\n\nGreat, now we shall move on to our questions.\n\n\nWhat research activity might have been carried out to obtain the data graphed here?\n\nLet’s say that maybe as a fun activity, hearing test might have been conducted in one of the classrooms in a school. Children were asked to raise their hands upon hearing the test signal. While many children did raise their hands, some did not. This is where the data collection began.\nin a playground, music starts to play on the loudspeaker, expecting all children to react and turn towards it. However, some of our outliers do not react to the sudden noise.\nChildren are being taught to cross the road and are asked to be aware of the honking of the cars. Again, there are some who do not react to the honks.\n\n\nThe graph is a box plot!\nI was unable to plot the graph.\n\n\n\nQuestions that the Graph seeks to answer\n\nis there any difference in the successful detection score between children with low, high and N/A incidence of OME?\nHow does the incidence of OME during childhood affect the successful detection score for noise-like and distinct test signals?\n\n\n\nWhat pre-processing of the data was required to create the chart?\nmutating variables into factors.\n\n\nInference\n\nHigh Incidence: Children with a high incidence of OME generally have higher detection scores compared to those with a low incidence.\n\n\n\nLow Incidence: The detection scores for children with a low incidence are more spread out, with a wider range of scores.\nDistinct Signal: Children with a distinct test signal tend to have higher detection scores than those with a noise-like signal. This indicates that a clearer test signal is easier to detect.\n\n\n\nNoise-Like Signal: Detection scores for noise-like signals are more variable, suggesting that distinguishing the signal from background noise is more challenging."
  }
]